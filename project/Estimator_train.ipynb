{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0464c96a125447a596ee1f9ac9cb6cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3b9e9a6ffb046c0a4a5ac4112e6f4ec",
              "IPY_MODEL_f6ce28e289c543c48e8048aa15edc755",
              "IPY_MODEL_ac183ee3033141f79fa91a06f5554b82"
            ],
            "layout": "IPY_MODEL_6d2942f781204da5b845acb8b11155e5"
          }
        },
        "a3b9e9a6ffb046c0a4a5ac4112e6f4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8fbd43bc2f4619a267b464d5eaf588",
            "placeholder": "​",
            "style": "IPY_MODEL_5b8174de16134608809e2a430085b59f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f6ce28e289c543c48e8048aa15edc755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e72b58160284a6ab31f98bd2895a368",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46105ef6f97549f18f9b25b56e54f18c",
            "value": 29
          }
        },
        "ac183ee3033141f79fa91a06f5554b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64200f5e577e44c0a40f46f0ab803657",
            "placeholder": "​",
            "style": "IPY_MODEL_60b76c6c83db42d6b7b9db889c6860ef",
            "value": " 29.0/29.0 [00:00&lt;00:00, 2.25kB/s]"
          }
        },
        "6d2942f781204da5b845acb8b11155e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8fbd43bc2f4619a267b464d5eaf588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b8174de16134608809e2a430085b59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e72b58160284a6ab31f98bd2895a368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46105ef6f97549f18f9b25b56e54f18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64200f5e577e44c0a40f46f0ab803657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b76c6c83db42d6b7b9db889c6860ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "759a9dcc2c1d413a913d141b40c21453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69c8fa2df3f549bd95b6705187ac891a",
              "IPY_MODEL_534c2739d2b842acae3ce50aada3cdcf",
              "IPY_MODEL_c1fc611f41a745d093d98618b7008de0"
            ],
            "layout": "IPY_MODEL_eb9e48ead1c748f9a975f09eb4dc85ab"
          }
        },
        "69c8fa2df3f549bd95b6705187ac891a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc0c7163c114d1daf405988dfe80ad6",
            "placeholder": "​",
            "style": "IPY_MODEL_07597e5350e648878804c8c8b5b65f22",
            "value": "vocab.txt: 100%"
          }
        },
        "534c2739d2b842acae3ce50aada3cdcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89f5f19105b4ac6acc754aead481995",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d52990d65acc4f7d82b725842561e79a",
            "value": 995526
          }
        },
        "c1fc611f41a745d093d98618b7008de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e12853ee5941c0b048314917845f93",
            "placeholder": "​",
            "style": "IPY_MODEL_1b67e46a52d34c4882e12a95e649db90",
            "value": " 996k/996k [00:00&lt;00:00, 2.11MB/s]"
          }
        },
        "eb9e48ead1c748f9a975f09eb4dc85ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc0c7163c114d1daf405988dfe80ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07597e5350e648878804c8c8b5b65f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a89f5f19105b4ac6acc754aead481995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52990d65acc4f7d82b725842561e79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2e12853ee5941c0b048314917845f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b67e46a52d34c4882e12a95e649db90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82e0cca951ae44dfbc31ec8d10dc9a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_813e8a74c35c4b9d81fa28774b03e6e9",
              "IPY_MODEL_eebef16c32234e69aeda865a67334ca5",
              "IPY_MODEL_f06ccdf517ce401a9b38a41b854b957e"
            ],
            "layout": "IPY_MODEL_98f140696c204b458fa49ec7653c8824"
          }
        },
        "813e8a74c35c4b9d81fa28774b03e6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0fb235a41eb412dadd7fc8c8859b406",
            "placeholder": "​",
            "style": "IPY_MODEL_861989fa75fe41dea11d62798a5b01d7",
            "value": "tokenizer.json: 100%"
          }
        },
        "eebef16c32234e69aeda865a67334ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c9b6474935044e2ab8c062eb73c6f78",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c88209d9bb3b40a59309f22ebcf26aeb",
            "value": 1961828
          }
        },
        "f06ccdf517ce401a9b38a41b854b957e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e3db37f9f05426289860c98a9c13bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_58925b8664044e8786077747f2178980",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 4.12MB/s]"
          }
        },
        "98f140696c204b458fa49ec7653c8824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fb235a41eb412dadd7fc8c8859b406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861989fa75fe41dea11d62798a5b01d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9b6474935044e2ab8c062eb73c6f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88209d9bb3b40a59309f22ebcf26aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e3db37f9f05426289860c98a9c13bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58925b8664044e8786077747f2178980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e1a5c8086534994ba9bbe3f9405bdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b71c6e6fa8784a9e92bd14ef7df28961",
              "IPY_MODEL_0b44e693ef84444d9b649c2b52f2ce4a",
              "IPY_MODEL_b9de9406780443ca8d50c413e72bcbef"
            ],
            "layout": "IPY_MODEL_351a02f8484c4056b9a9abb10a03a790"
          }
        },
        "b71c6e6fa8784a9e92bd14ef7df28961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5bf2b531931435da3aee03c0702b201",
            "placeholder": "​",
            "style": "IPY_MODEL_3c9d9f6081bf4677b5dd55fa2467aa93",
            "value": "config.json: 100%"
          }
        },
        "0b44e693ef84444d9b649c2b52f2ce4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_832730e15ca846aa8f3c9b6ee390a0e9",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c114054f41d94a358d9d3e5935041405",
            "value": 625
          }
        },
        "b9de9406780443ca8d50c413e72bcbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df2bdf1168b54f9bb7dc69bbd70080dc",
            "placeholder": "​",
            "style": "IPY_MODEL_15c9a590cba44a54af59272b04307d64",
            "value": " 625/625 [00:00&lt;00:00, 56.6kB/s]"
          }
        },
        "351a02f8484c4056b9a9abb10a03a790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5bf2b531931435da3aee03c0702b201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9d9f6081bf4677b5dd55fa2467aa93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "832730e15ca846aa8f3c9b6ee390a0e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c114054f41d94a358d9d3e5935041405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df2bdf1168b54f9bb7dc69bbd70080dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c9a590cba44a54af59272b04307d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cbbb5e230f547869cafbda215fcc0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9245af5e8c4e45fd9dfd2da0beb2e69e",
              "IPY_MODEL_08e16fe80eef4eff91b811a28dae3448",
              "IPY_MODEL_7c37e9b7bdab4a22984eccb5357fce6c"
            ],
            "layout": "IPY_MODEL_20f231d7dec74facb67a7b08a7274930"
          }
        },
        "9245af5e8c4e45fd9dfd2da0beb2e69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de4dbdd6b4443e69f062677d7e814a3",
            "placeholder": "​",
            "style": "IPY_MODEL_170e2e6a5a504ca5995c6c5d4d393315",
            "value": "model.safetensors: 100%"
          }
        },
        "08e16fe80eef4eff91b811a28dae3448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46dbc9e33fa548ccb9d7f6e087c260f2",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2ab3503ee2a4f81828aa39be182af25",
            "value": 714290682
          }
        },
        "7c37e9b7bdab4a22984eccb5357fce6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b38b79572c94ec081072ef5bd8b5674",
            "placeholder": "​",
            "style": "IPY_MODEL_98850a8992e345ec85788cd566168726",
            "value": " 714M/714M [00:49&lt;00:00, 11.3MB/s]"
          }
        },
        "20f231d7dec74facb67a7b08a7274930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de4dbdd6b4443e69f062677d7e814a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170e2e6a5a504ca5995c6c5d4d393315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46dbc9e33fa548ccb9d7f6e087c260f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ab3503ee2a4f81828aa39be182af25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b38b79572c94ec081072ef5bd8b5674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98850a8992e345ec85788cd566168726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DQFMSoS3mxrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d46210-5a09-4965-c884-a248a40ec0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/work/korean-hate-speech-detection\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLr07DEUnUEx",
        "outputId": "4b5b8a50-6a06-4297-d6bd-ff8fd8e1954f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/work/korean-hate-speech-detection\n",
            "'=0.20.1'               epoch_24_results.csv   \u001b[0m\u001b[01;34mmodelsave7\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/                  epoch_2_results.csv    \u001b[01;34mmy_autotrain_llm\u001b[0m/\n",
            " dev.hate1.csv          epoch_3_results.csv    offensive.csv\n",
            " dev.hate.csv           epoch_4_results.csv    offensive_data_set.csv\n",
            " dev.news_title.txt     epoch_5_results.csv    \u001b[01;34moffensive_directory\u001b[0m/\n",
            " epoch_10_results.csv   epoch_6_results.csv    \u001b[01;34moffensivetest\u001b[0m/\n",
            " epoch_11_results.csv   epoch_7_results.csv    \u001b[01;34mourfuckingmodel\u001b[0m/\n",
            " epoch_12_results.csv   epoch_8_results.csv    \u001b[01;34mpretrained_model_directory\u001b[0m/\n",
            " epoch_13_results.csv   epoch_9_results.csv    printprob.py\n",
            " epoch_14_results.csv   \u001b[01;34minferenced\u001b[0m/            \u001b[01;34mreal_final\u001b[0m/\n",
            " epoch_15_results.csv   install_logs.txt       \u001b[01;34mresults\u001b[0m/\n",
            " epoch_16_results.csv   \u001b[01;34mllama\u001b[0m/                 setup_logs.txt\n",
            " epoch_17_results.csv   \u001b[01;34mllama2-hoxy\u001b[0m/           test.hate.no_label.csv\n",
            " epoch_18_results.csv   llamatest.py           test.news_title.txt\n",
            " epoch_19_results.csv   \u001b[01;34mmodelsave1\u001b[0m/            \u001b[01;34mthdmodel\u001b[0m/\n",
            " epoch_1_results.csv    \u001b[01;34mmodelsave2\u001b[0m/            \u001b[01;34mtmp_trainer\u001b[0m/\n",
            " epoch_20_results.csv   \u001b[01;34mmodelsave3\u001b[0m/            train.hate.csv\n",
            " epoch_21_results.csv   \u001b[01;34mmodelsave4\u001b[0m/            train.news_title.txt\n",
            " epoch_22_results.csv   \u001b[01;34mmodelsave5\u001b[0m/            unlabeled_comments.news_title.txt\n",
            " epoch_23_results.csv   \u001b[01;34mmodelsave6\u001b[0m/            unlabeled_comments.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvdzXHwgnb_u",
        "outputId": "ee5e0313-8add-4171-ab1c-9b03df26fb4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "import pandas as pd\n",
        "from torch import sigmoid\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "xlvuV03bnmRC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "#hate_data_dev_set_path = (\n",
        " #   \"hate_data_set.csv\"\n",
        "#)\n",
        "#hate_data_train_set_path = (\n",
        "#    \"train.hate.csv\"\n",
        "#)"
      ],
      "metadata": {
        "id": "0h838USsnq-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"train.hate.csv\")\n",
        "dev_data = pd.read_csv(\"dev.hate.csv\")\n",
        "train_data['label'].replace(\"hate\", 1, inplace=True)\n",
        "train_data['label'].replace(\"none\", 0, inplace=True)\n",
        "train_data['label'].replace(\"offensive\", 0.5, inplace=True)\n",
        "train_data = train_data[train_data['label'] != 0.5]\n",
        "dev_data['label'].replace(\"hate\", 1, inplace=True)\n",
        "dev_data['label'].replace(\"none\", 0, inplace=True)\n",
        "dev_data['label'].replace(\"offensive\", 0.5, inplace=True)\n",
        "dev_data = dev_data[dev_data['label'] != 0.5]"
      ],
      "metadata": {
        "id": "9KGPkg-Enwv3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT 다국어 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# 문장을 토큰화하고 패딩 적용\n",
        "tokenized_texts = [\n",
        "    tokenizer.encode(text, add_special_tokens=True) for text in train_data[\"comments\"]\n",
        "]\n",
        "\n",
        "max_length = max(len(tokens) for tokens in tokenized_texts)\n",
        "padded_texts = [tokens + [0] * (max_length - len(tokens)) for tokens in tokenized_texts]\n",
        "\n",
        "# 텐서로 변환\n",
        "input_ids = (torch.tensor(padded_texts)).to(device)\n",
        "labels = (torch.tensor(train_data[\"label\"].tolist())).to(device)\n",
        "\n",
        "val_tokenized_texts = [\n",
        "    tokenizer.encode(text, add_special_tokens=True) for text in dev_data[\"comments\"]\n",
        "]\n",
        "max_length_val = max(len(tokens) for tokens in val_tokenized_texts)\n",
        "val_padded_texts = [\n",
        "    tokens + [0] * (max_length_val - len(tokens)) for tokens in val_tokenized_texts\n",
        "]\n",
        "val_input_ids = (torch.tensor(val_padded_texts)).to(device)\n",
        "val_labels = (torch.tensor(dev_data[\"label\"].tolist())).to(device)\n",
        "\n",
        "\n",
        "# DataLoader 생성\n",
        "dataset = TensorDataset(input_ids, labels)\n",
        "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "val_dataset = TensorDataset(val_input_ids, val_labels)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "A8470EkVoyHQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "0464c96a125447a596ee1f9ac9cb6cb3",
            "a3b9e9a6ffb046c0a4a5ac4112e6f4ec",
            "f6ce28e289c543c48e8048aa15edc755",
            "ac183ee3033141f79fa91a06f5554b82",
            "6d2942f781204da5b845acb8b11155e5",
            "2c8fbd43bc2f4619a267b464d5eaf588",
            "5b8174de16134608809e2a430085b59f",
            "4e72b58160284a6ab31f98bd2895a368",
            "46105ef6f97549f18f9b25b56e54f18c",
            "64200f5e577e44c0a40f46f0ab803657",
            "60b76c6c83db42d6b7b9db889c6860ef",
            "759a9dcc2c1d413a913d141b40c21453",
            "69c8fa2df3f549bd95b6705187ac891a",
            "534c2739d2b842acae3ce50aada3cdcf",
            "c1fc611f41a745d093d98618b7008de0",
            "eb9e48ead1c748f9a975f09eb4dc85ab",
            "efc0c7163c114d1daf405988dfe80ad6",
            "07597e5350e648878804c8c8b5b65f22",
            "a89f5f19105b4ac6acc754aead481995",
            "d52990d65acc4f7d82b725842561e79a",
            "b2e12853ee5941c0b048314917845f93",
            "1b67e46a52d34c4882e12a95e649db90",
            "82e0cca951ae44dfbc31ec8d10dc9a72",
            "813e8a74c35c4b9d81fa28774b03e6e9",
            "eebef16c32234e69aeda865a67334ca5",
            "f06ccdf517ce401a9b38a41b854b957e",
            "98f140696c204b458fa49ec7653c8824",
            "b0fb235a41eb412dadd7fc8c8859b406",
            "861989fa75fe41dea11d62798a5b01d7",
            "2c9b6474935044e2ab8c062eb73c6f78",
            "c88209d9bb3b40a59309f22ebcf26aeb",
            "0e3db37f9f05426289860c98a9c13bd3",
            "58925b8664044e8786077747f2178980",
            "7e1a5c8086534994ba9bbe3f9405bdbf",
            "b71c6e6fa8784a9e92bd14ef7df28961",
            "0b44e693ef84444d9b649c2b52f2ce4a",
            "b9de9406780443ca8d50c413e72bcbef",
            "351a02f8484c4056b9a9abb10a03a790",
            "a5bf2b531931435da3aee03c0702b201",
            "3c9d9f6081bf4677b5dd55fa2467aa93",
            "832730e15ca846aa8f3c9b6ee390a0e9",
            "c114054f41d94a358d9d3e5935041405",
            "df2bdf1168b54f9bb7dc69bbd70080dc",
            "15c9a590cba44a54af59272b04307d64"
          ]
        },
        "outputId": "4c901ee5-49e5-491a-d0bb-ddcac98673f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0464c96a125447a596ee1f9ac9cb6cb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "759a9dcc2c1d413a913d141b40c21453"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82e0cca951ae44dfbc31ec8d10dc9a72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e1a5c8086534994ba9bbe3f9405bdbf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", num_labels=1\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# 옵티마이저 및 손실 함수 초기화\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "7cbbb5e230f547869cafbda215fcc0d3",
            "9245af5e8c4e45fd9dfd2da0beb2e69e",
            "08e16fe80eef4eff91b811a28dae3448",
            "7c37e9b7bdab4a22984eccb5357fce6c",
            "20f231d7dec74facb67a7b08a7274930",
            "5de4dbdd6b4443e69f062677d7e814a3",
            "170e2e6a5a504ca5995c6c5d4d393315",
            "46dbc9e33fa548ccb9d7f6e087c260f2",
            "e2ab3503ee2a4f81828aa39be182af25",
            "3b38b79572c94ec081072ef5bd8b5674",
            "98850a8992e345ec85788cd566168726"
          ]
        },
        "id": "HHlH2ftz82AA",
        "outputId": "f07f37c2-be5b-4c29-a25f-a024e415ee18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cbbb5e230f547869cafbda215fcc0d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 평가\n",
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_batches = len(data_loader)\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "        input_ids, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids)\n",
        "        logits = outputs.logits.squeeze(1)\n",
        "        loss = criterion(logits, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # 출력 형식: Epoch [현재 에폭], Batch [현재 배치 / 전체 배치 수], Loss: [현재 배치 손실]\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}, Batch {batch_idx + 1} / {total_batches}, Loss: {loss.item()}\"\n",
        "        )\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "        probabilities_hate = []\n",
        "        probabilities_clean = []\n",
        "        probabilities_offensive = []\n",
        "\n",
        "        for batch in data_loader:\n",
        "            input_ids, labels = batch\n",
        "            outputs = model(input_ids)\n",
        "            logits = outputs.logits.squeeze(1)\n",
        "            prob_hate = sigmoid(logits)\n",
        "            prob_clean = 1 - prob_hate\n",
        "            prob_offensive = prob_hate\n",
        "            predictions.extend((prob_hate > 0.5).float().tolist())  # 0.5를 기준으로 이진 분류\n",
        "            true_labels.extend(labels.tolist())\n",
        "            probabilities_hate.extend(prob_hate.tolist())\n",
        "            probabilities_clean.extend(prob_clean.tolist())\n",
        "            probabilities_offensive.extend(prob_offensive.tolist())\n",
        "\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    auc_roc = roc_auc_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}, Loss: {total_loss / len(data_loader)}, Accuracy: {accuracy}, Auc: {auc_roc}, f1: {f1}\"\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_predictions = []\n",
        "        val_true_labels = []\n",
        "        for val_batch in val_loader:\n",
        "            val_input_ids, val_labels = val_batch\n",
        "            val_outputs = model(val_input_ids)\n",
        "            val_logits = val_outputs.logits.squeeze(1)\n",
        "            val_predictions.extend(torch.sigmoid(val_logits).round().tolist())\n",
        "            val_true_labels.extend(val_labels.tolist())\n",
        "\n",
        "        val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}, Train Loss: {total_loss / len(val_loader)}, Validation Accuracy: {val_accuracy}\"\n",
        "        )\n",
        "\n",
        "    # # 각 문장에 대한 확률값 및 실제 라벨 출력\n",
        "    # for text, prob_hate, prob_clean, prob_offensive, true_label in zip(\n",
        "    #     dev_data[\"comments\"],\n",
        "    #     probabilities_hate,\n",
        "    #     probabilities_clean,\n",
        "    #     probabilities_offensive,\n",
        "    #     dev_data[\"Value\"],\n",
        "    # ):\n",
        "    #     if true_label == 1:\n",
        "    #         print(f\"Text: {text}, True Label: Hate, Probability for Hate: {prob_hate}\")\n",
        "    #     elif true_label == 0:\n",
        "    #         print(\n",
        "    #             f\"Text: {text}, True Label: Clean, Probability for Clean: {prob_clean}\"\n",
        "    #         )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqNDMVOWpL52",
        "outputId": "d22c2835-0c52-40df-d428-ce0f5123e91b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 2, Batch 409 / 1350, Loss: 0.2412426769733429\n",
            "Epoch 2, Batch 410 / 1350, Loss: 0.4944400191307068\n",
            "Epoch 2, Batch 411 / 1350, Loss: 0.1728072166442871\n",
            "Epoch 2, Batch 412 / 1350, Loss: 0.2151697874069214\n",
            "Epoch 2, Batch 413 / 1350, Loss: 0.6543656587600708\n",
            "Epoch 2, Batch 414 / 1350, Loss: 0.35471153259277344\n",
            "Epoch 2, Batch 415 / 1350, Loss: 0.3402089476585388\n",
            "Epoch 2, Batch 416 / 1350, Loss: 0.1543782353401184\n",
            "Epoch 2, Batch 417 / 1350, Loss: 0.20169471204280853\n",
            "Epoch 2, Batch 418 / 1350, Loss: 0.3105595111846924\n",
            "Epoch 2, Batch 419 / 1350, Loss: 0.27242714166641235\n",
            "Epoch 2, Batch 420 / 1350, Loss: 0.15257857739925385\n",
            "Epoch 2, Batch 421 / 1350, Loss: 0.6416348814964294\n",
            "Epoch 2, Batch 422 / 1350, Loss: 0.14445023238658905\n",
            "Epoch 2, Batch 423 / 1350, Loss: 0.16020822525024414\n",
            "Epoch 2, Batch 424 / 1350, Loss: 0.1191558763384819\n",
            "Epoch 2, Batch 425 / 1350, Loss: 0.09626886248588562\n",
            "Epoch 2, Batch 426 / 1350, Loss: 0.2684706151485443\n",
            "Epoch 2, Batch 427 / 1350, Loss: 0.19882145524024963\n",
            "Epoch 2, Batch 428 / 1350, Loss: 0.3371882438659668\n",
            "Epoch 2, Batch 429 / 1350, Loss: 0.30429166555404663\n",
            "Epoch 2, Batch 430 / 1350, Loss: 0.17634108662605286\n",
            "Epoch 2, Batch 431 / 1350, Loss: 0.1956643909215927\n",
            "Epoch 2, Batch 432 / 1350, Loss: 0.22980523109436035\n",
            "Epoch 2, Batch 433 / 1350, Loss: 1.0386457443237305\n",
            "Epoch 2, Batch 434 / 1350, Loss: 0.33364689350128174\n",
            "Epoch 2, Batch 435 / 1350, Loss: 0.23174335062503815\n",
            "Epoch 2, Batch 436 / 1350, Loss: 0.1601802408695221\n",
            "Epoch 2, Batch 437 / 1350, Loss: 0.11124783009290695\n",
            "Epoch 2, Batch 438 / 1350, Loss: 0.7162511348724365\n",
            "Epoch 2, Batch 439 / 1350, Loss: 0.8536202907562256\n",
            "Epoch 2, Batch 440 / 1350, Loss: 0.10418608784675598\n",
            "Epoch 2, Batch 441 / 1350, Loss: 0.1752721071243286\n",
            "Epoch 2, Batch 442 / 1350, Loss: 1.2391411066055298\n",
            "Epoch 2, Batch 443 / 1350, Loss: 0.8548946380615234\n",
            "Epoch 2, Batch 444 / 1350, Loss: 0.7338220477104187\n",
            "Epoch 2, Batch 445 / 1350, Loss: 0.07908120006322861\n",
            "Epoch 2, Batch 446 / 1350, Loss: 0.2773028612136841\n",
            "Epoch 2, Batch 447 / 1350, Loss: 0.08266783505678177\n",
            "Epoch 2, Batch 448 / 1350, Loss: 0.18770065903663635\n",
            "Epoch 2, Batch 449 / 1350, Loss: 0.12222598493099213\n",
            "Epoch 2, Batch 450 / 1350, Loss: 0.2577778697013855\n",
            "Epoch 2, Batch 451 / 1350, Loss: 0.10578201711177826\n",
            "Epoch 2, Batch 452 / 1350, Loss: 0.4837871193885803\n",
            "Epoch 2, Batch 453 / 1350, Loss: 0.12628041207790375\n",
            "Epoch 2, Batch 454 / 1350, Loss: 0.2536427974700928\n",
            "Epoch 2, Batch 455 / 1350, Loss: 0.5488483309745789\n",
            "Epoch 2, Batch 456 / 1350, Loss: 0.20632201433181763\n",
            "Epoch 2, Batch 457 / 1350, Loss: 0.41429516673088074\n",
            "Epoch 2, Batch 458 / 1350, Loss: 0.40198057889938354\n",
            "Epoch 2, Batch 459 / 1350, Loss: 0.17874476313591003\n",
            "Epoch 2, Batch 460 / 1350, Loss: 1.0232617855072021\n",
            "Epoch 2, Batch 461 / 1350, Loss: 0.2297879308462143\n",
            "Epoch 2, Batch 462 / 1350, Loss: 0.2838026285171509\n",
            "Epoch 2, Batch 463 / 1350, Loss: 0.3224932849407196\n",
            "Epoch 2, Batch 464 / 1350, Loss: 0.30191269516944885\n",
            "Epoch 2, Batch 465 / 1350, Loss: 0.07592698186635971\n",
            "Epoch 2, Batch 466 / 1350, Loss: 0.5378488302230835\n",
            "Epoch 2, Batch 467 / 1350, Loss: 0.13685312867164612\n",
            "Epoch 2, Batch 468 / 1350, Loss: 0.054933130741119385\n",
            "Epoch 2, Batch 469 / 1350, Loss: 0.48250409960746765\n",
            "Epoch 2, Batch 470 / 1350, Loss: 0.791678249835968\n",
            "Epoch 2, Batch 471 / 1350, Loss: 0.8698408007621765\n",
            "Epoch 2, Batch 472 / 1350, Loss: 0.21027123928070068\n",
            "Epoch 2, Batch 473 / 1350, Loss: 0.27848368883132935\n",
            "Epoch 2, Batch 474 / 1350, Loss: 0.20769724249839783\n",
            "Epoch 2, Batch 475 / 1350, Loss: 0.16476109623908997\n",
            "Epoch 2, Batch 476 / 1350, Loss: 0.23704195022583008\n",
            "Epoch 2, Batch 477 / 1350, Loss: 0.29406124353408813\n",
            "Epoch 2, Batch 478 / 1350, Loss: 0.8076974153518677\n",
            "Epoch 2, Batch 479 / 1350, Loss: 0.47878676652908325\n",
            "Epoch 2, Batch 480 / 1350, Loss: 0.10087315738201141\n",
            "Epoch 2, Batch 481 / 1350, Loss: 0.04378189891576767\n",
            "Epoch 2, Batch 482 / 1350, Loss: 0.13754446804523468\n",
            "Epoch 2, Batch 483 / 1350, Loss: 0.1358107179403305\n",
            "Epoch 2, Batch 484 / 1350, Loss: 0.3166447579860687\n",
            "Epoch 2, Batch 485 / 1350, Loss: 0.582938015460968\n",
            "Epoch 2, Batch 486 / 1350, Loss: 0.6490123867988586\n",
            "Epoch 2, Batch 487 / 1350, Loss: 0.21760952472686768\n",
            "Epoch 2, Batch 488 / 1350, Loss: 0.22787198424339294\n",
            "Epoch 2, Batch 489 / 1350, Loss: 0.24725079536437988\n",
            "Epoch 2, Batch 490 / 1350, Loss: 0.5576034188270569\n",
            "Epoch 2, Batch 491 / 1350, Loss: 0.8852482438087463\n",
            "Epoch 2, Batch 492 / 1350, Loss: 0.5067095160484314\n",
            "Epoch 2, Batch 493 / 1350, Loss: 0.7798397541046143\n",
            "Epoch 2, Batch 494 / 1350, Loss: 0.14635814726352692\n",
            "Epoch 2, Batch 495 / 1350, Loss: 0.39086416363716125\n",
            "Epoch 2, Batch 496 / 1350, Loss: 0.23511207103729248\n",
            "Epoch 2, Batch 497 / 1350, Loss: 0.03450693190097809\n",
            "Epoch 2, Batch 498 / 1350, Loss: 0.5889185070991516\n",
            "Epoch 2, Batch 499 / 1350, Loss: 0.1631089150905609\n",
            "Epoch 2, Batch 500 / 1350, Loss: 0.5036031603813171\n",
            "Epoch 2, Batch 501 / 1350, Loss: 1.0531810522079468\n",
            "Epoch 2, Batch 502 / 1350, Loss: 0.10281805694103241\n",
            "Epoch 2, Batch 503 / 1350, Loss: 0.263367235660553\n",
            "Epoch 2, Batch 504 / 1350, Loss: 0.33620017766952515\n",
            "Epoch 2, Batch 505 / 1350, Loss: 0.07295083999633789\n",
            "Epoch 2, Batch 506 / 1350, Loss: 0.7168639898300171\n",
            "Epoch 2, Batch 507 / 1350, Loss: 0.5535832047462463\n",
            "Epoch 2, Batch 508 / 1350, Loss: 0.22968406975269318\n",
            "Epoch 2, Batch 509 / 1350, Loss: 0.30681565403938293\n",
            "Epoch 2, Batch 510 / 1350, Loss: 0.41518744826316833\n",
            "Epoch 2, Batch 511 / 1350, Loss: 0.29513436555862427\n",
            "Epoch 2, Batch 512 / 1350, Loss: 0.5569550395011902\n",
            "Epoch 2, Batch 513 / 1350, Loss: 0.04937887564301491\n",
            "Epoch 2, Batch 514 / 1350, Loss: 0.4952479600906372\n",
            "Epoch 2, Batch 515 / 1350, Loss: 0.8133638501167297\n",
            "Epoch 2, Batch 516 / 1350, Loss: 0.46651697158813477\n",
            "Epoch 2, Batch 517 / 1350, Loss: 0.1635642945766449\n",
            "Epoch 2, Batch 518 / 1350, Loss: 0.09386742115020752\n",
            "Epoch 2, Batch 519 / 1350, Loss: 0.7315564751625061\n",
            "Epoch 2, Batch 520 / 1350, Loss: 0.6145205497741699\n",
            "Epoch 2, Batch 521 / 1350, Loss: 0.6032739877700806\n",
            "Epoch 2, Batch 522 / 1350, Loss: 0.44481974840164185\n",
            "Epoch 2, Batch 523 / 1350, Loss: 0.3469502329826355\n",
            "Epoch 2, Batch 524 / 1350, Loss: 0.4166569113731384\n",
            "Epoch 2, Batch 525 / 1350, Loss: 0.27457597851753235\n",
            "Epoch 2, Batch 526 / 1350, Loss: 0.09469044208526611\n",
            "Epoch 2, Batch 527 / 1350, Loss: 0.48082423210144043\n",
            "Epoch 2, Batch 528 / 1350, Loss: 0.5511147975921631\n",
            "Epoch 2, Batch 529 / 1350, Loss: 0.3939926326274872\n",
            "Epoch 2, Batch 530 / 1350, Loss: 0.24366429448127747\n",
            "Epoch 2, Batch 531 / 1350, Loss: 0.6272670030593872\n",
            "Epoch 2, Batch 532 / 1350, Loss: 0.18149986863136292\n",
            "Epoch 2, Batch 533 / 1350, Loss: 0.9816315770149231\n",
            "Epoch 2, Batch 534 / 1350, Loss: 0.05514758825302124\n",
            "Epoch 2, Batch 535 / 1350, Loss: 0.5065896511077881\n",
            "Epoch 2, Batch 536 / 1350, Loss: 0.0655793622136116\n",
            "Epoch 2, Batch 537 / 1350, Loss: 0.5799078941345215\n",
            "Epoch 2, Batch 538 / 1350, Loss: 0.4122955799102783\n",
            "Epoch 2, Batch 539 / 1350, Loss: 1.0935032367706299\n",
            "Epoch 2, Batch 540 / 1350, Loss: 0.2734284996986389\n",
            "Epoch 2, Batch 541 / 1350, Loss: 0.3988696038722992\n",
            "Epoch 2, Batch 542 / 1350, Loss: 0.7127760648727417\n",
            "Epoch 2, Batch 543 / 1350, Loss: 0.08161959797143936\n",
            "Epoch 2, Batch 544 / 1350, Loss: 0.570167601108551\n",
            "Epoch 2, Batch 545 / 1350, Loss: 0.4758895933628082\n",
            "Epoch 2, Batch 546 / 1350, Loss: 0.19177329540252686\n",
            "Epoch 2, Batch 547 / 1350, Loss: 0.13347604870796204\n",
            "Epoch 2, Batch 548 / 1350, Loss: 0.3703817129135132\n",
            "Epoch 2, Batch 549 / 1350, Loss: 0.3798530101776123\n",
            "Epoch 2, Batch 550 / 1350, Loss: 0.1406838744878769\n",
            "Epoch 2, Batch 551 / 1350, Loss: 0.3448132574558258\n",
            "Epoch 2, Batch 552 / 1350, Loss: 0.15478847920894623\n",
            "Epoch 2, Batch 553 / 1350, Loss: 0.2897622287273407\n",
            "Epoch 2, Batch 554 / 1350, Loss: 0.27242034673690796\n",
            "Epoch 2, Batch 555 / 1350, Loss: 1.2244435548782349\n",
            "Epoch 2, Batch 556 / 1350, Loss: 0.4509733021259308\n",
            "Epoch 2, Batch 557 / 1350, Loss: 0.530002236366272\n",
            "Epoch 2, Batch 558 / 1350, Loss: 0.30277273058891296\n",
            "Epoch 2, Batch 559 / 1350, Loss: 0.16530923545360565\n",
            "Epoch 2, Batch 560 / 1350, Loss: 0.663373589515686\n",
            "Epoch 2, Batch 561 / 1350, Loss: 0.3396127223968506\n",
            "Epoch 2, Batch 562 / 1350, Loss: 0.5314972400665283\n",
            "Epoch 2, Batch 563 / 1350, Loss: 0.8946524858474731\n",
            "Epoch 2, Batch 564 / 1350, Loss: 0.5658769607543945\n",
            "Epoch 2, Batch 565 / 1350, Loss: 0.31585052609443665\n",
            "Epoch 2, Batch 566 / 1350, Loss: 0.8703956604003906\n",
            "Epoch 2, Batch 567 / 1350, Loss: 1.9127732515335083\n",
            "Epoch 2, Batch 568 / 1350, Loss: 0.1704588532447815\n",
            "Epoch 2, Batch 569 / 1350, Loss: 0.2782342731952667\n",
            "Epoch 2, Batch 570 / 1350, Loss: 0.3322034478187561\n",
            "Epoch 2, Batch 571 / 1350, Loss: 0.8986169695854187\n",
            "Epoch 2, Batch 572 / 1350, Loss: 0.25556501746177673\n",
            "Epoch 2, Batch 573 / 1350, Loss: 0.4226016402244568\n",
            "Epoch 2, Batch 574 / 1350, Loss: 0.39775797724723816\n",
            "Epoch 2, Batch 575 / 1350, Loss: 1.159336805343628\n",
            "Epoch 2, Batch 576 / 1350, Loss: 0.2624414265155792\n",
            "Epoch 2, Batch 577 / 1350, Loss: 0.31046730279922485\n",
            "Epoch 2, Batch 578 / 1350, Loss: 0.3501582443714142\n",
            "Epoch 2, Batch 579 / 1350, Loss: 0.05532202124595642\n",
            "Epoch 2, Batch 580 / 1350, Loss: 0.17024844884872437\n",
            "Epoch 2, Batch 581 / 1350, Loss: 0.3029536008834839\n",
            "Epoch 2, Batch 582 / 1350, Loss: 0.24121809005737305\n",
            "Epoch 2, Batch 583 / 1350, Loss: 0.24261240661144257\n",
            "Epoch 2, Batch 584 / 1350, Loss: 0.6412076354026794\n",
            "Epoch 2, Batch 585 / 1350, Loss: 0.5588133335113525\n",
            "Epoch 2, Batch 586 / 1350, Loss: 0.703354001045227\n",
            "Epoch 2, Batch 587 / 1350, Loss: 0.24779389798641205\n",
            "Epoch 2, Batch 588 / 1350, Loss: 0.4459865093231201\n",
            "Epoch 2, Batch 589 / 1350, Loss: 0.3229782283306122\n",
            "Epoch 2, Batch 590 / 1350, Loss: 0.16166898608207703\n",
            "Epoch 2, Batch 591 / 1350, Loss: 0.4872852563858032\n",
            "Epoch 2, Batch 592 / 1350, Loss: 0.4039299488067627\n",
            "Epoch 2, Batch 593 / 1350, Loss: 0.07488380372524261\n",
            "Epoch 2, Batch 594 / 1350, Loss: 0.6263289451599121\n",
            "Epoch 2, Batch 595 / 1350, Loss: 0.18551775813102722\n",
            "Epoch 2, Batch 596 / 1350, Loss: 0.5161622762680054\n",
            "Epoch 2, Batch 597 / 1350, Loss: 0.2955068349838257\n",
            "Epoch 2, Batch 598 / 1350, Loss: 0.3494722247123718\n",
            "Epoch 2, Batch 599 / 1350, Loss: 0.16592594981193542\n",
            "Epoch 2, Batch 600 / 1350, Loss: 0.21914324164390564\n",
            "Epoch 2, Batch 601 / 1350, Loss: 0.09220746159553528\n",
            "Epoch 2, Batch 602 / 1350, Loss: 0.3018176555633545\n",
            "Epoch 2, Batch 603 / 1350, Loss: 0.14022356271743774\n",
            "Epoch 2, Batch 604 / 1350, Loss: 0.24687078595161438\n",
            "Epoch 2, Batch 605 / 1350, Loss: 0.14629435539245605\n",
            "Epoch 2, Batch 606 / 1350, Loss: 0.5933922529220581\n",
            "Epoch 2, Batch 607 / 1350, Loss: 0.025768417865037918\n",
            "Epoch 2, Batch 608 / 1350, Loss: 0.8843941688537598\n",
            "Epoch 2, Batch 609 / 1350, Loss: 0.49840497970581055\n",
            "Epoch 2, Batch 610 / 1350, Loss: 0.38373619318008423\n",
            "Epoch 2, Batch 611 / 1350, Loss: 0.09691719710826874\n",
            "Epoch 2, Batch 612 / 1350, Loss: 0.4484240710735321\n",
            "Epoch 2, Batch 613 / 1350, Loss: 0.05633443221449852\n",
            "Epoch 2, Batch 614 / 1350, Loss: 0.2637541890144348\n",
            "Epoch 2, Batch 615 / 1350, Loss: 0.4114604592323303\n",
            "Epoch 2, Batch 616 / 1350, Loss: 0.670904278755188\n",
            "Epoch 2, Batch 617 / 1350, Loss: 0.5614629983901978\n",
            "Epoch 2, Batch 618 / 1350, Loss: 0.33457815647125244\n",
            "Epoch 2, Batch 619 / 1350, Loss: 0.4916105568408966\n",
            "Epoch 2, Batch 620 / 1350, Loss: 0.32573509216308594\n",
            "Epoch 2, Batch 621 / 1350, Loss: 0.22161391377449036\n",
            "Epoch 2, Batch 622 / 1350, Loss: 0.2611525356769562\n",
            "Epoch 2, Batch 623 / 1350, Loss: 0.26891881227493286\n",
            "Epoch 2, Batch 624 / 1350, Loss: 0.21497225761413574\n",
            "Epoch 2, Batch 625 / 1350, Loss: 0.24965634942054749\n",
            "Epoch 2, Batch 626 / 1350, Loss: 0.044582292437553406\n",
            "Epoch 2, Batch 627 / 1350, Loss: 0.4212920069694519\n",
            "Epoch 2, Batch 628 / 1350, Loss: 0.6814612150192261\n",
            "Epoch 2, Batch 629 / 1350, Loss: 0.1429346203804016\n",
            "Epoch 2, Batch 630 / 1350, Loss: 0.17157991230487823\n",
            "Epoch 2, Batch 631 / 1350, Loss: 0.13236701488494873\n",
            "Epoch 2, Batch 632 / 1350, Loss: 0.6759912967681885\n",
            "Epoch 2, Batch 633 / 1350, Loss: 0.49417614936828613\n",
            "Epoch 2, Batch 634 / 1350, Loss: 0.048834845423698425\n",
            "Epoch 2, Batch 635 / 1350, Loss: 0.5150211453437805\n",
            "Epoch 2, Batch 636 / 1350, Loss: 0.18307314813137054\n",
            "Epoch 2, Batch 637 / 1350, Loss: 0.14794272184371948\n",
            "Epoch 2, Batch 638 / 1350, Loss: 0.25362828373908997\n",
            "Epoch 2, Batch 639 / 1350, Loss: 0.29863864183425903\n",
            "Epoch 2, Batch 640 / 1350, Loss: 0.22341355681419373\n",
            "Epoch 2, Batch 641 / 1350, Loss: 0.0493948832154274\n",
            "Epoch 2, Batch 642 / 1350, Loss: 1.005795955657959\n",
            "Epoch 2, Batch 643 / 1350, Loss: 0.3765736222267151\n",
            "Epoch 2, Batch 644 / 1350, Loss: 0.05038787052035332\n",
            "Epoch 2, Batch 645 / 1350, Loss: 0.2657625377178192\n",
            "Epoch 2, Batch 646 / 1350, Loss: 0.9530013799667358\n",
            "Epoch 2, Batch 647 / 1350, Loss: 0.0477055199444294\n",
            "Epoch 2, Batch 648 / 1350, Loss: 0.3797346353530884\n",
            "Epoch 2, Batch 649 / 1350, Loss: 0.5782456994056702\n",
            "Epoch 2, Batch 650 / 1350, Loss: 0.11892728507518768\n",
            "Epoch 2, Batch 651 / 1350, Loss: 0.07184788584709167\n",
            "Epoch 2, Batch 652 / 1350, Loss: 0.08374956250190735\n",
            "Epoch 2, Batch 653 / 1350, Loss: 0.1646905094385147\n",
            "Epoch 2, Batch 654 / 1350, Loss: 0.11212919652462006\n",
            "Epoch 2, Batch 655 / 1350, Loss: 0.3600405156612396\n",
            "Epoch 2, Batch 656 / 1350, Loss: 0.6427494287490845\n",
            "Epoch 2, Batch 657 / 1350, Loss: 0.2161705195903778\n",
            "Epoch 2, Batch 658 / 1350, Loss: 0.1700046956539154\n",
            "Epoch 2, Batch 659 / 1350, Loss: 0.38147100806236267\n",
            "Epoch 2, Batch 660 / 1350, Loss: 0.0660153180360794\n",
            "Epoch 2, Batch 661 / 1350, Loss: 0.18018220365047455\n",
            "Epoch 2, Batch 662 / 1350, Loss: 0.27441200613975525\n",
            "Epoch 2, Batch 663 / 1350, Loss: 0.8367649912834167\n",
            "Epoch 2, Batch 664 / 1350, Loss: 0.33358559012413025\n",
            "Epoch 2, Batch 665 / 1350, Loss: 0.23492994904518127\n",
            "Epoch 2, Batch 666 / 1350, Loss: 0.6675601005554199\n",
            "Epoch 2, Batch 667 / 1350, Loss: 0.3702281713485718\n",
            "Epoch 2, Batch 668 / 1350, Loss: 0.0928705632686615\n",
            "Epoch 2, Batch 669 / 1350, Loss: 0.15694130957126617\n",
            "Epoch 2, Batch 670 / 1350, Loss: 0.2852581739425659\n",
            "Epoch 2, Batch 671 / 1350, Loss: 0.10669932514429092\n",
            "Epoch 2, Batch 672 / 1350, Loss: 0.1668674200773239\n",
            "Epoch 2, Batch 673 / 1350, Loss: 0.928658127784729\n",
            "Epoch 2, Batch 674 / 1350, Loss: 0.18451158702373505\n",
            "Epoch 2, Batch 675 / 1350, Loss: 0.3672511577606201\n",
            "Epoch 2, Batch 676 / 1350, Loss: 0.036753736436367035\n",
            "Epoch 2, Batch 677 / 1350, Loss: 0.21348842978477478\n",
            "Epoch 2, Batch 678 / 1350, Loss: 0.5853430032730103\n",
            "Epoch 2, Batch 679 / 1350, Loss: 0.1475246101617813\n",
            "Epoch 2, Batch 680 / 1350, Loss: 0.03612123429775238\n",
            "Epoch 2, Batch 681 / 1350, Loss: 1.0694248676300049\n",
            "Epoch 2, Batch 682 / 1350, Loss: 0.5547406673431396\n",
            "Epoch 2, Batch 683 / 1350, Loss: 0.2363775074481964\n",
            "Epoch 2, Batch 684 / 1350, Loss: 1.1167784929275513\n",
            "Epoch 2, Batch 685 / 1350, Loss: 0.1999187469482422\n",
            "Epoch 2, Batch 686 / 1350, Loss: 0.031026247888803482\n",
            "Epoch 2, Batch 687 / 1350, Loss: 2.432335138320923\n",
            "Epoch 2, Batch 688 / 1350, Loss: 1.7074062824249268\n",
            "Epoch 2, Batch 689 / 1350, Loss: 0.06055310368537903\n",
            "Epoch 2, Batch 690 / 1350, Loss: 0.754637598991394\n",
            "Epoch 2, Batch 691 / 1350, Loss: 1.0861668586730957\n",
            "Epoch 2, Batch 692 / 1350, Loss: 0.6423541307449341\n",
            "Epoch 2, Batch 693 / 1350, Loss: 0.25072556734085083\n",
            "Epoch 2, Batch 694 / 1350, Loss: 0.25097429752349854\n",
            "Epoch 2, Batch 695 / 1350, Loss: 0.30669519305229187\n",
            "Epoch 2, Batch 696 / 1350, Loss: 0.5284165143966675\n",
            "Epoch 2, Batch 697 / 1350, Loss: 0.2172955870628357\n",
            "Epoch 2, Batch 698 / 1350, Loss: 0.9159846901893616\n",
            "Epoch 2, Batch 699 / 1350, Loss: 0.7753376960754395\n",
            "Epoch 2, Batch 700 / 1350, Loss: 0.6228303909301758\n",
            "Epoch 2, Batch 701 / 1350, Loss: 0.4298155605792999\n",
            "Epoch 2, Batch 702 / 1350, Loss: 0.3490656018257141\n",
            "Epoch 2, Batch 703 / 1350, Loss: 0.2703207731246948\n",
            "Epoch 2, Batch 704 / 1350, Loss: 0.29863154888153076\n",
            "Epoch 2, Batch 705 / 1350, Loss: 0.22328107059001923\n",
            "Epoch 2, Batch 706 / 1350, Loss: 0.26051241159439087\n",
            "Epoch 2, Batch 707 / 1350, Loss: 0.1979653686285019\n",
            "Epoch 2, Batch 708 / 1350, Loss: 0.27749666571617126\n",
            "Epoch 2, Batch 709 / 1350, Loss: 0.666592538356781\n",
            "Epoch 2, Batch 710 / 1350, Loss: 0.44624441862106323\n",
            "Epoch 2, Batch 711 / 1350, Loss: 0.25143003463745117\n",
            "Epoch 2, Batch 712 / 1350, Loss: 0.18585988879203796\n",
            "Epoch 2, Batch 713 / 1350, Loss: 0.2775457799434662\n",
            "Epoch 2, Batch 714 / 1350, Loss: 0.2860773801803589\n",
            "Epoch 2, Batch 715 / 1350, Loss: 0.6705322265625\n",
            "Epoch 2, Batch 716 / 1350, Loss: 0.5738265514373779\n",
            "Epoch 2, Batch 717 / 1350, Loss: 0.17844580113887787\n",
            "Epoch 2, Batch 718 / 1350, Loss: 0.31416958570480347\n",
            "Epoch 2, Batch 719 / 1350, Loss: 0.37301164865493774\n",
            "Epoch 2, Batch 720 / 1350, Loss: 0.5413768291473389\n",
            "Epoch 2, Batch 721 / 1350, Loss: 0.21974420547485352\n",
            "Epoch 2, Batch 722 / 1350, Loss: 0.5879490971565247\n",
            "Epoch 2, Batch 723 / 1350, Loss: 0.4481052756309509\n",
            "Epoch 2, Batch 724 / 1350, Loss: 0.3574073314666748\n",
            "Epoch 2, Batch 725 / 1350, Loss: 0.4797932803630829\n",
            "Epoch 2, Batch 726 / 1350, Loss: 0.14613056182861328\n",
            "Epoch 2, Batch 727 / 1350, Loss: 0.20375607907772064\n",
            "Epoch 2, Batch 728 / 1350, Loss: 0.17832010984420776\n",
            "Epoch 2, Batch 729 / 1350, Loss: 0.8282622694969177\n",
            "Epoch 2, Batch 730 / 1350, Loss: 0.6608333587646484\n",
            "Epoch 2, Batch 731 / 1350, Loss: 0.2932770252227783\n",
            "Epoch 2, Batch 732 / 1350, Loss: 0.8926529884338379\n",
            "Epoch 2, Batch 733 / 1350, Loss: 0.1670922338962555\n",
            "Epoch 2, Batch 734 / 1350, Loss: 0.20249967277050018\n",
            "Epoch 2, Batch 735 / 1350, Loss: 0.4693903923034668\n",
            "Epoch 2, Batch 736 / 1350, Loss: 0.5247821807861328\n",
            "Epoch 2, Batch 737 / 1350, Loss: 0.2951275110244751\n",
            "Epoch 2, Batch 738 / 1350, Loss: 1.1185660362243652\n",
            "Epoch 2, Batch 739 / 1350, Loss: 0.2486569583415985\n",
            "Epoch 2, Batch 740 / 1350, Loss: 0.36479073762893677\n",
            "Epoch 2, Batch 741 / 1350, Loss: 0.1058875322341919\n",
            "Epoch 2, Batch 742 / 1350, Loss: 0.37063801288604736\n",
            "Epoch 2, Batch 743 / 1350, Loss: 0.3885519802570343\n",
            "Epoch 2, Batch 744 / 1350, Loss: 0.23716682195663452\n",
            "Epoch 2, Batch 745 / 1350, Loss: 0.5751992464065552\n",
            "Epoch 2, Batch 746 / 1350, Loss: 0.08371412754058838\n",
            "Epoch 2, Batch 747 / 1350, Loss: 0.552794873714447\n",
            "Epoch 2, Batch 748 / 1350, Loss: 0.6335275769233704\n",
            "Epoch 2, Batch 749 / 1350, Loss: 0.6760866641998291\n",
            "Epoch 2, Batch 750 / 1350, Loss: 0.17815972864627838\n",
            "Epoch 2, Batch 751 / 1350, Loss: 0.2587183117866516\n",
            "Epoch 2, Batch 752 / 1350, Loss: 0.34577682614326477\n",
            "Epoch 2, Batch 753 / 1350, Loss: 0.11987242102622986\n",
            "Epoch 2, Batch 754 / 1350, Loss: 0.5497512817382812\n",
            "Epoch 2, Batch 755 / 1350, Loss: 0.23110821843147278\n",
            "Epoch 2, Batch 756 / 1350, Loss: 0.1952729970216751\n",
            "Epoch 2, Batch 757 / 1350, Loss: 0.44612452387809753\n",
            "Epoch 2, Batch 758 / 1350, Loss: 0.1742272675037384\n",
            "Epoch 2, Batch 759 / 1350, Loss: 0.08186055719852448\n",
            "Epoch 2, Batch 760 / 1350, Loss: 0.0892329216003418\n",
            "Epoch 2, Batch 761 / 1350, Loss: 0.09840478003025055\n",
            "Epoch 2, Batch 762 / 1350, Loss: 0.04963543266057968\n",
            "Epoch 2, Batch 763 / 1350, Loss: 0.5122323036193848\n",
            "Epoch 2, Batch 764 / 1350, Loss: 0.1303066909313202\n",
            "Epoch 2, Batch 765 / 1350, Loss: 0.0789969339966774\n",
            "Epoch 2, Batch 766 / 1350, Loss: 1.0341013669967651\n",
            "Epoch 2, Batch 767 / 1350, Loss: 0.3471662104129791\n",
            "Epoch 2, Batch 768 / 1350, Loss: 0.08494873344898224\n",
            "Epoch 2, Batch 769 / 1350, Loss: 0.31188589334487915\n",
            "Epoch 2, Batch 770 / 1350, Loss: 0.18525010347366333\n",
            "Epoch 2, Batch 771 / 1350, Loss: 0.15886756777763367\n",
            "Epoch 2, Batch 772 / 1350, Loss: 0.13379952311515808\n",
            "Epoch 2, Batch 773 / 1350, Loss: 0.1392858475446701\n",
            "Epoch 2, Batch 774 / 1350, Loss: 0.13584277033805847\n",
            "Epoch 2, Batch 775 / 1350, Loss: 0.2861455976963043\n",
            "Epoch 2, Batch 776 / 1350, Loss: 0.8317276239395142\n",
            "Epoch 2, Batch 777 / 1350, Loss: 0.6218938827514648\n",
            "Epoch 2, Batch 778 / 1350, Loss: 0.3284594416618347\n",
            "Epoch 2, Batch 779 / 1350, Loss: 1.2666637897491455\n",
            "Epoch 2, Batch 780 / 1350, Loss: 0.6323791146278381\n",
            "Epoch 2, Batch 781 / 1350, Loss: 0.4366195797920227\n",
            "Epoch 2, Batch 782 / 1350, Loss: 0.06985911726951599\n",
            "Epoch 2, Batch 783 / 1350, Loss: 0.18311122059822083\n",
            "Epoch 2, Batch 784 / 1350, Loss: 0.43591922521591187\n",
            "Epoch 2, Batch 785 / 1350, Loss: 0.23467031121253967\n",
            "Epoch 2, Batch 786 / 1350, Loss: 0.9873762130737305\n",
            "Epoch 2, Batch 787 / 1350, Loss: 0.3476344347000122\n",
            "Epoch 2, Batch 788 / 1350, Loss: 0.8320484161376953\n",
            "Epoch 2, Batch 789 / 1350, Loss: 0.30810415744781494\n",
            "Epoch 2, Batch 790 / 1350, Loss: 0.4420664310455322\n",
            "Epoch 2, Batch 791 / 1350, Loss: 0.6562101244926453\n",
            "Epoch 2, Batch 792 / 1350, Loss: 0.3256722092628479\n",
            "Epoch 2, Batch 793 / 1350, Loss: 0.2878805100917816\n",
            "Epoch 2, Batch 794 / 1350, Loss: 0.8932121992111206\n",
            "Epoch 2, Batch 795 / 1350, Loss: 0.06666623055934906\n",
            "Epoch 2, Batch 796 / 1350, Loss: 0.25027361512184143\n",
            "Epoch 2, Batch 797 / 1350, Loss: 0.07537390291690826\n",
            "Epoch 2, Batch 798 / 1350, Loss: 0.37663722038269043\n",
            "Epoch 2, Batch 799 / 1350, Loss: 0.07893435657024384\n",
            "Epoch 2, Batch 800 / 1350, Loss: 0.07379256188869476\n",
            "Epoch 2, Batch 801 / 1350, Loss: 0.06455515325069427\n",
            "Epoch 2, Batch 802 / 1350, Loss: 0.060618266463279724\n",
            "Epoch 2, Batch 803 / 1350, Loss: 0.19966576993465424\n",
            "Epoch 2, Batch 804 / 1350, Loss: 0.23468336462974548\n",
            "Epoch 2, Batch 805 / 1350, Loss: 0.07520510256290436\n",
            "Epoch 2, Batch 806 / 1350, Loss: 0.6065504550933838\n",
            "Epoch 2, Batch 807 / 1350, Loss: 0.19799628853797913\n",
            "Epoch 2, Batch 808 / 1350, Loss: 0.3733099699020386\n",
            "Epoch 2, Batch 809 / 1350, Loss: 0.6058208346366882\n",
            "Epoch 2, Batch 810 / 1350, Loss: 0.6084427237510681\n",
            "Epoch 2, Batch 811 / 1350, Loss: 0.05397070199251175\n",
            "Epoch 2, Batch 812 / 1350, Loss: 0.049070000648498535\n",
            "Epoch 2, Batch 813 / 1350, Loss: 0.12579336762428284\n",
            "Epoch 2, Batch 814 / 1350, Loss: 0.2626444101333618\n",
            "Epoch 2, Batch 815 / 1350, Loss: 0.3226320147514343\n",
            "Epoch 2, Batch 816 / 1350, Loss: 0.3727146089076996\n",
            "Epoch 2, Batch 817 / 1350, Loss: 0.19021686911582947\n",
            "Epoch 2, Batch 818 / 1350, Loss: 0.08451612293720245\n",
            "Epoch 2, Batch 819 / 1350, Loss: 0.3919604420661926\n",
            "Epoch 2, Batch 820 / 1350, Loss: 0.11726130545139313\n",
            "Epoch 2, Batch 821 / 1350, Loss: 1.071317195892334\n",
            "Epoch 2, Batch 822 / 1350, Loss: 0.7845136523246765\n",
            "Epoch 2, Batch 823 / 1350, Loss: 0.31817808747291565\n",
            "Epoch 2, Batch 824 / 1350, Loss: 0.8802815675735474\n",
            "Epoch 2, Batch 825 / 1350, Loss: 0.2679499387741089\n",
            "Epoch 2, Batch 826 / 1350, Loss: 0.03998556733131409\n",
            "Epoch 2, Batch 827 / 1350, Loss: 0.17462341487407684\n",
            "Epoch 2, Batch 828 / 1350, Loss: 0.942595362663269\n",
            "Epoch 2, Batch 829 / 1350, Loss: 0.21033023297786713\n",
            "Epoch 2, Batch 830 / 1350, Loss: 0.08922283351421356\n",
            "Epoch 2, Batch 831 / 1350, Loss: 0.08115900307893753\n",
            "Epoch 2, Batch 832 / 1350, Loss: 0.43397751450538635\n",
            "Epoch 2, Batch 833 / 1350, Loss: 0.739605188369751\n",
            "Epoch 2, Batch 834 / 1350, Loss: 1.3712506294250488\n",
            "Epoch 2, Batch 835 / 1350, Loss: 0.031857930123806\n",
            "Epoch 2, Batch 836 / 1350, Loss: 0.22694651782512665\n",
            "Epoch 2, Batch 837 / 1350, Loss: 1.0006599426269531\n",
            "Epoch 2, Batch 838 / 1350, Loss: 0.4711466133594513\n",
            "Epoch 2, Batch 839 / 1350, Loss: 0.2847707271575928\n",
            "Epoch 2, Batch 840 / 1350, Loss: 0.05332124978303909\n",
            "Epoch 2, Batch 841 / 1350, Loss: 0.5178819298744202\n",
            "Epoch 2, Batch 842 / 1350, Loss: 1.0915861129760742\n",
            "Epoch 2, Batch 843 / 1350, Loss: 0.8227951526641846\n",
            "Epoch 2, Batch 844 / 1350, Loss: 0.48029714822769165\n",
            "Epoch 2, Batch 845 / 1350, Loss: 1.1052532196044922\n",
            "Epoch 2, Batch 846 / 1350, Loss: 0.14838863909244537\n",
            "Epoch 2, Batch 847 / 1350, Loss: 0.32318902015686035\n",
            "Epoch 2, Batch 848 / 1350, Loss: 0.6423999667167664\n",
            "Epoch 2, Batch 849 / 1350, Loss: 1.075304388999939\n",
            "Epoch 2, Batch 850 / 1350, Loss: 0.5457143187522888\n",
            "Epoch 2, Batch 851 / 1350, Loss: 0.35408487915992737\n",
            "Epoch 2, Batch 852 / 1350, Loss: 0.5307133197784424\n",
            "Epoch 2, Batch 853 / 1350, Loss: 0.382027804851532\n",
            "Epoch 2, Batch 854 / 1350, Loss: 0.38634294271469116\n",
            "Epoch 2, Batch 855 / 1350, Loss: 0.2305738627910614\n",
            "Epoch 2, Batch 856 / 1350, Loss: 0.2741957902908325\n",
            "Epoch 2, Batch 857 / 1350, Loss: 0.4946267604827881\n",
            "Epoch 2, Batch 858 / 1350, Loss: 0.6434775590896606\n",
            "Epoch 2, Batch 859 / 1350, Loss: 0.4188438057899475\n",
            "Epoch 2, Batch 860 / 1350, Loss: 0.6196575164794922\n",
            "Epoch 2, Batch 861 / 1350, Loss: 0.10022273659706116\n",
            "Epoch 2, Batch 862 / 1350, Loss: 0.4173212945461273\n",
            "Epoch 2, Batch 863 / 1350, Loss: 0.5812697410583496\n",
            "Epoch 2, Batch 864 / 1350, Loss: 0.3422788381576538\n",
            "Epoch 2, Batch 865 / 1350, Loss: 0.24269676208496094\n",
            "Epoch 2, Batch 866 / 1350, Loss: 0.202948659658432\n",
            "Epoch 2, Batch 867 / 1350, Loss: 0.6827786564826965\n",
            "Epoch 2, Batch 868 / 1350, Loss: 0.23261834681034088\n",
            "Epoch 2, Batch 869 / 1350, Loss: 0.29070085287094116\n",
            "Epoch 2, Batch 870 / 1350, Loss: 0.5032359957695007\n",
            "Epoch 2, Batch 871 / 1350, Loss: 0.40601861476898193\n",
            "Epoch 2, Batch 872 / 1350, Loss: 0.18964779376983643\n",
            "Epoch 2, Batch 873 / 1350, Loss: 0.35122090578079224\n",
            "Epoch 2, Batch 874 / 1350, Loss: 0.12347103655338287\n",
            "Epoch 2, Batch 875 / 1350, Loss: 0.06788615882396698\n",
            "Epoch 2, Batch 876 / 1350, Loss: 0.6530822515487671\n",
            "Epoch 2, Batch 877 / 1350, Loss: 0.188001811504364\n",
            "Epoch 2, Batch 878 / 1350, Loss: 0.13805662095546722\n",
            "Epoch 2, Batch 879 / 1350, Loss: 0.26281148195266724\n",
            "Epoch 2, Batch 880 / 1350, Loss: 0.3682052493095398\n",
            "Epoch 2, Batch 881 / 1350, Loss: 0.10483220219612122\n",
            "Epoch 2, Batch 882 / 1350, Loss: 0.19759292900562286\n",
            "Epoch 2, Batch 883 / 1350, Loss: 0.12129104137420654\n",
            "Epoch 2, Batch 884 / 1350, Loss: 0.6299039721488953\n",
            "Epoch 2, Batch 885 / 1350, Loss: 0.13031643629074097\n",
            "Epoch 2, Batch 886 / 1350, Loss: 0.3720262050628662\n",
            "Epoch 2, Batch 887 / 1350, Loss: 0.044894762337207794\n",
            "Epoch 2, Batch 888 / 1350, Loss: 0.5941905975341797\n",
            "Epoch 2, Batch 889 / 1350, Loss: 0.5293522477149963\n",
            "Epoch 2, Batch 890 / 1350, Loss: 0.29798537492752075\n",
            "Epoch 2, Batch 891 / 1350, Loss: 0.6366168856620789\n",
            "Epoch 2, Batch 892 / 1350, Loss: 0.29278743267059326\n",
            "Epoch 2, Batch 893 / 1350, Loss: 0.7577856779098511\n",
            "Epoch 2, Batch 894 / 1350, Loss: 0.7838813066482544\n",
            "Epoch 2, Batch 895 / 1350, Loss: 0.2914505898952484\n",
            "Epoch 2, Batch 896 / 1350, Loss: 0.19951295852661133\n",
            "Epoch 2, Batch 897 / 1350, Loss: 0.07307258248329163\n",
            "Epoch 2, Batch 898 / 1350, Loss: 0.10145123302936554\n",
            "Epoch 2, Batch 899 / 1350, Loss: 0.08280318975448608\n",
            "Epoch 2, Batch 900 / 1350, Loss: 0.1828852742910385\n",
            "Epoch 2, Batch 901 / 1350, Loss: 0.05800515413284302\n",
            "Epoch 2, Batch 902 / 1350, Loss: 0.36301565170288086\n",
            "Epoch 2, Batch 903 / 1350, Loss: 0.20103749632835388\n",
            "Epoch 2, Batch 904 / 1350, Loss: 0.37572237849235535\n",
            "Epoch 2, Batch 905 / 1350, Loss: 0.03565352410078049\n",
            "Epoch 2, Batch 906 / 1350, Loss: 0.06776737421751022\n",
            "Epoch 2, Batch 907 / 1350, Loss: 0.3360489010810852\n",
            "Epoch 2, Batch 908 / 1350, Loss: 0.554014265537262\n",
            "Epoch 2, Batch 909 / 1350, Loss: 0.05907423794269562\n",
            "Epoch 2, Batch 910 / 1350, Loss: 0.09818725287914276\n",
            "Epoch 2, Batch 911 / 1350, Loss: 0.1440160572528839\n",
            "Epoch 2, Batch 912 / 1350, Loss: 0.09783986210823059\n",
            "Epoch 2, Batch 913 / 1350, Loss: 1.0715454816818237\n",
            "Epoch 2, Batch 914 / 1350, Loss: 0.17091554403305054\n",
            "Epoch 2, Batch 915 / 1350, Loss: 0.6799968481063843\n",
            "Epoch 2, Batch 916 / 1350, Loss: 0.04475895315408707\n",
            "Epoch 2, Batch 917 / 1350, Loss: 0.8242830634117126\n",
            "Epoch 2, Batch 918 / 1350, Loss: 0.6482319831848145\n",
            "Epoch 2, Batch 919 / 1350, Loss: 0.32428163290023804\n",
            "Epoch 2, Batch 920 / 1350, Loss: 0.6761723160743713\n",
            "Epoch 2, Batch 921 / 1350, Loss: 0.051126424223184586\n",
            "Epoch 2, Batch 922 / 1350, Loss: 1.1027464866638184\n",
            "Epoch 2, Batch 923 / 1350, Loss: 0.058297134935855865\n",
            "Epoch 2, Batch 924 / 1350, Loss: 0.03650923818349838\n",
            "Epoch 2, Batch 925 / 1350, Loss: 0.882197380065918\n",
            "Epoch 2, Batch 926 / 1350, Loss: 0.44381314516067505\n",
            "Epoch 2, Batch 927 / 1350, Loss: 0.1975904107093811\n",
            "Epoch 2, Batch 928 / 1350, Loss: 0.9839079976081848\n",
            "Epoch 2, Batch 929 / 1350, Loss: 1.838559627532959\n",
            "Epoch 2, Batch 930 / 1350, Loss: 0.30085185170173645\n",
            "Epoch 2, Batch 931 / 1350, Loss: 1.409665822982788\n",
            "Epoch 2, Batch 932 / 1350, Loss: 0.752183198928833\n",
            "Epoch 2, Batch 933 / 1350, Loss: 0.2768671214580536\n",
            "Epoch 2, Batch 934 / 1350, Loss: 0.11645481735467911\n",
            "Epoch 2, Batch 935 / 1350, Loss: 1.065090537071228\n",
            "Epoch 2, Batch 936 / 1350, Loss: 0.7033427357673645\n",
            "Epoch 2, Batch 937 / 1350, Loss: 0.2030608057975769\n",
            "Epoch 2, Batch 938 / 1350, Loss: 0.39508557319641113\n",
            "Epoch 2, Batch 939 / 1350, Loss: 0.779198169708252\n",
            "Epoch 2, Batch 940 / 1350, Loss: 0.41643980145454407\n",
            "Epoch 2, Batch 941 / 1350, Loss: 0.699073314666748\n",
            "Epoch 2, Batch 942 / 1350, Loss: 0.46276524662971497\n",
            "Epoch 2, Batch 943 / 1350, Loss: 0.36947545409202576\n",
            "Epoch 2, Batch 944 / 1350, Loss: 0.4214068055152893\n",
            "Epoch 2, Batch 945 / 1350, Loss: 0.5839837193489075\n",
            "Epoch 2, Batch 946 / 1350, Loss: 0.30912986397743225\n",
            "Epoch 2, Batch 947 / 1350, Loss: 0.5496052503585815\n",
            "Epoch 2, Batch 948 / 1350, Loss: 0.24890819191932678\n",
            "Epoch 2, Batch 949 / 1350, Loss: 0.16938352584838867\n",
            "Epoch 2, Batch 950 / 1350, Loss: 0.29570063948631287\n",
            "Epoch 2, Batch 951 / 1350, Loss: 0.2159430831670761\n",
            "Epoch 2, Batch 952 / 1350, Loss: 0.928239107131958\n",
            "Epoch 2, Batch 953 / 1350, Loss: 0.5676984786987305\n",
            "Epoch 2, Batch 954 / 1350, Loss: 0.2981931269168854\n",
            "Epoch 2, Batch 955 / 1350, Loss: 0.15520602464675903\n",
            "Epoch 2, Batch 956 / 1350, Loss: 0.18511365354061127\n",
            "Epoch 2, Batch 957 / 1350, Loss: 0.12912574410438538\n",
            "Epoch 2, Batch 958 / 1350, Loss: 0.21985967457294464\n",
            "Epoch 2, Batch 959 / 1350, Loss: 0.4265514016151428\n",
            "Epoch 2, Batch 960 / 1350, Loss: 0.5687600374221802\n",
            "Epoch 2, Batch 961 / 1350, Loss: 0.12952375411987305\n",
            "Epoch 2, Batch 962 / 1350, Loss: 0.1863442063331604\n",
            "Epoch 2, Batch 963 / 1350, Loss: 0.2024684101343155\n",
            "Epoch 2, Batch 964 / 1350, Loss: 0.14194878935813904\n",
            "Epoch 2, Batch 965 / 1350, Loss: 0.20877417922019958\n",
            "Epoch 2, Batch 966 / 1350, Loss: 0.46172308921813965\n",
            "Epoch 2, Batch 967 / 1350, Loss: 0.5611668825149536\n",
            "Epoch 2, Batch 968 / 1350, Loss: 0.1662808358669281\n",
            "Epoch 2, Batch 969 / 1350, Loss: 0.39809513092041016\n",
            "Epoch 2, Batch 970 / 1350, Loss: 0.42508578300476074\n",
            "Epoch 2, Batch 971 / 1350, Loss: 0.13606584072113037\n",
            "Epoch 2, Batch 972 / 1350, Loss: 0.291498064994812\n",
            "Epoch 2, Batch 973 / 1350, Loss: 0.8798397779464722\n",
            "Epoch 2, Batch 974 / 1350, Loss: 0.09235133230686188\n",
            "Epoch 2, Batch 975 / 1350, Loss: 0.6362172961235046\n",
            "Epoch 2, Batch 976 / 1350, Loss: 0.389403760433197\n",
            "Epoch 2, Batch 977 / 1350, Loss: 0.8539143800735474\n",
            "Epoch 2, Batch 978 / 1350, Loss: 0.23493888974189758\n",
            "Epoch 2, Batch 979 / 1350, Loss: 0.8606138825416565\n",
            "Epoch 2, Batch 980 / 1350, Loss: 0.6117337942123413\n",
            "Epoch 2, Batch 981 / 1350, Loss: 0.3333289623260498\n",
            "Epoch 2, Batch 982 / 1350, Loss: 0.27015939354896545\n",
            "Epoch 2, Batch 983 / 1350, Loss: 0.24814245104789734\n",
            "Epoch 2, Batch 984 / 1350, Loss: 0.4542933702468872\n",
            "Epoch 2, Batch 985 / 1350, Loss: 0.31603729724884033\n",
            "Epoch 2, Batch 986 / 1350, Loss: 0.19695203006267548\n",
            "Epoch 2, Batch 987 / 1350, Loss: 0.9343268871307373\n",
            "Epoch 2, Batch 988 / 1350, Loss: 0.13807031512260437\n",
            "Epoch 2, Batch 989 / 1350, Loss: 0.9773610830307007\n",
            "Epoch 2, Batch 990 / 1350, Loss: 0.07285584509372711\n",
            "Epoch 2, Batch 991 / 1350, Loss: 0.329795777797699\n",
            "Epoch 2, Batch 992 / 1350, Loss: 0.6857645511627197\n",
            "Epoch 2, Batch 993 / 1350, Loss: 0.3752076029777527\n",
            "Epoch 2, Batch 994 / 1350, Loss: 0.0680827721953392\n",
            "Epoch 2, Batch 995 / 1350, Loss: 0.08817284554243088\n",
            "Epoch 2, Batch 996 / 1350, Loss: 0.3252914249897003\n",
            "Epoch 2, Batch 997 / 1350, Loss: 0.16559362411499023\n",
            "Epoch 2, Batch 998 / 1350, Loss: 0.097136951982975\n",
            "Epoch 2, Batch 999 / 1350, Loss: 0.17772029340267181\n",
            "Epoch 2, Batch 1000 / 1350, Loss: 0.16301918029785156\n",
            "Epoch 2, Batch 1001 / 1350, Loss: 0.2556874454021454\n",
            "Epoch 2, Batch 1002 / 1350, Loss: 0.09011509269475937\n",
            "Epoch 2, Batch 1003 / 1350, Loss: 0.5806102156639099\n",
            "Epoch 2, Batch 1004 / 1350, Loss: 0.541236162185669\n",
            "Epoch 2, Batch 1005 / 1350, Loss: 0.25258535146713257\n",
            "Epoch 2, Batch 1006 / 1350, Loss: 0.5041517019271851\n",
            "Epoch 2, Batch 1007 / 1350, Loss: 0.8608944416046143\n",
            "Epoch 2, Batch 1008 / 1350, Loss: 0.0837988555431366\n",
            "Epoch 2, Batch 1009 / 1350, Loss: 0.25634464621543884\n",
            "Epoch 2, Batch 1010 / 1350, Loss: 0.22660323977470398\n",
            "Epoch 2, Batch 1011 / 1350, Loss: 0.2847329378128052\n",
            "Epoch 2, Batch 1012 / 1350, Loss: 0.14839909970760345\n",
            "Epoch 2, Batch 1013 / 1350, Loss: 0.6694045662879944\n",
            "Epoch 2, Batch 1014 / 1350, Loss: 0.4370276629924774\n",
            "Epoch 2, Batch 1015 / 1350, Loss: 0.559685468673706\n",
            "Epoch 2, Batch 1016 / 1350, Loss: 0.6309942007064819\n",
            "Epoch 2, Batch 1017 / 1350, Loss: 0.2709145247936249\n",
            "Epoch 2, Batch 1018 / 1350, Loss: 0.49779242277145386\n",
            "Epoch 2, Batch 1019 / 1350, Loss: 0.33323490619659424\n",
            "Epoch 2, Batch 1020 / 1350, Loss: 0.08456672728061676\n",
            "Epoch 2, Batch 1021 / 1350, Loss: 0.08686727285385132\n",
            "Epoch 2, Batch 1022 / 1350, Loss: 0.6081575155258179\n",
            "Epoch 2, Batch 1023 / 1350, Loss: 0.8107213973999023\n",
            "Epoch 2, Batch 1024 / 1350, Loss: 0.6307706832885742\n",
            "Epoch 2, Batch 1025 / 1350, Loss: 0.2115885317325592\n",
            "Epoch 2, Batch 1026 / 1350, Loss: 0.37466201186180115\n",
            "Epoch 2, Batch 1027 / 1350, Loss: 0.30037635564804077\n",
            "Epoch 2, Batch 1028 / 1350, Loss: 0.10318946838378906\n",
            "Epoch 2, Batch 1029 / 1350, Loss: 0.9493769407272339\n",
            "Epoch 2, Batch 1030 / 1350, Loss: 0.2148556262254715\n",
            "Epoch 2, Batch 1031 / 1350, Loss: 0.5609172582626343\n",
            "Epoch 2, Batch 1032 / 1350, Loss: 0.07016695290803909\n",
            "Epoch 2, Batch 1033 / 1350, Loss: 0.14956265687942505\n",
            "Epoch 2, Batch 1034 / 1350, Loss: 0.06754076480865479\n",
            "Epoch 2, Batch 1035 / 1350, Loss: 0.3984627425670624\n",
            "Epoch 2, Batch 1036 / 1350, Loss: 0.07692781090736389\n",
            "Epoch 2, Batch 1037 / 1350, Loss: 0.04803472012281418\n",
            "Epoch 2, Batch 1038 / 1350, Loss: 0.6688539385795593\n",
            "Epoch 2, Batch 1039 / 1350, Loss: 0.2717090845108032\n",
            "Epoch 2, Batch 1040 / 1350, Loss: 0.23257502913475037\n",
            "Epoch 2, Batch 1041 / 1350, Loss: 0.5622465014457703\n",
            "Epoch 2, Batch 1042 / 1350, Loss: 0.5453352332115173\n",
            "Epoch 2, Batch 1043 / 1350, Loss: 0.2758283019065857\n",
            "Epoch 2, Batch 1044 / 1350, Loss: 0.9253575205802917\n",
            "Epoch 2, Batch 1045 / 1350, Loss: 0.5668122172355652\n",
            "Epoch 2, Batch 1046 / 1350, Loss: 0.39540404081344604\n",
            "Epoch 2, Batch 1047 / 1350, Loss: 0.573840320110321\n",
            "Epoch 2, Batch 1048 / 1350, Loss: 0.77394038438797\n",
            "Epoch 2, Batch 1049 / 1350, Loss: 1.3966400623321533\n",
            "Epoch 2, Batch 1050 / 1350, Loss: 0.3915891945362091\n",
            "Epoch 2, Batch 1051 / 1350, Loss: 0.14657938480377197\n",
            "Epoch 2, Batch 1052 / 1350, Loss: 0.44894689321517944\n",
            "Epoch 2, Batch 1053 / 1350, Loss: 0.19925370812416077\n",
            "Epoch 2, Batch 1054 / 1350, Loss: 0.15093937516212463\n",
            "Epoch 2, Batch 1055 / 1350, Loss: 1.2278218269348145\n",
            "Epoch 2, Batch 1056 / 1350, Loss: 0.32521504163742065\n",
            "Epoch 2, Batch 1057 / 1350, Loss: 0.2822119891643524\n",
            "Epoch 2, Batch 1058 / 1350, Loss: 0.20735447108745575\n",
            "Epoch 2, Batch 1059 / 1350, Loss: 0.1651860475540161\n",
            "Epoch 2, Batch 1060 / 1350, Loss: 0.23331573605537415\n",
            "Epoch 2, Batch 1061 / 1350, Loss: 0.5711178183555603\n",
            "Epoch 2, Batch 1062 / 1350, Loss: 0.2807903289794922\n",
            "Epoch 2, Batch 1063 / 1350, Loss: 0.312212198972702\n",
            "Epoch 2, Batch 1064 / 1350, Loss: 0.2934456169605255\n",
            "Epoch 2, Batch 1065 / 1350, Loss: 0.26484760642051697\n",
            "Epoch 2, Batch 1066 / 1350, Loss: 0.3419469892978668\n",
            "Epoch 2, Batch 1067 / 1350, Loss: 0.09969151020050049\n",
            "Epoch 2, Batch 1068 / 1350, Loss: 0.4622527062892914\n",
            "Epoch 2, Batch 1069 / 1350, Loss: 0.4674599766731262\n",
            "Epoch 2, Batch 1070 / 1350, Loss: 0.08318870514631271\n",
            "Epoch 2, Batch 1071 / 1350, Loss: 0.33013916015625\n",
            "Epoch 2, Batch 1072 / 1350, Loss: 0.7397257685661316\n",
            "Epoch 2, Batch 1073 / 1350, Loss: 0.2082240879535675\n",
            "Epoch 2, Batch 1074 / 1350, Loss: 0.10939927399158478\n",
            "Epoch 2, Batch 1075 / 1350, Loss: 1.0055313110351562\n",
            "Epoch 2, Batch 1076 / 1350, Loss: 0.2126898318529129\n",
            "Epoch 2, Batch 1077 / 1350, Loss: 0.09471315145492554\n",
            "Epoch 2, Batch 1078 / 1350, Loss: 0.4755399525165558\n",
            "Epoch 2, Batch 1079 / 1350, Loss: 1.0562692880630493\n",
            "Epoch 2, Batch 1080 / 1350, Loss: 0.05021660029888153\n",
            "Epoch 2, Batch 1081 / 1350, Loss: 0.2853827178478241\n",
            "Epoch 2, Batch 1082 / 1350, Loss: 0.20814745128154755\n",
            "Epoch 2, Batch 1083 / 1350, Loss: 0.4735262095928192\n",
            "Epoch 2, Batch 1084 / 1350, Loss: 0.12622246146202087\n",
            "Epoch 2, Batch 1085 / 1350, Loss: 0.1461949646472931\n",
            "Epoch 2, Batch 1086 / 1350, Loss: 1.2322843074798584\n",
            "Epoch 2, Batch 1087 / 1350, Loss: 0.2171378880739212\n",
            "Epoch 2, Batch 1088 / 1350, Loss: 0.8148356080055237\n",
            "Epoch 2, Batch 1089 / 1350, Loss: 1.1549254655838013\n",
            "Epoch 2, Batch 1090 / 1350, Loss: 0.4104135036468506\n",
            "Epoch 2, Batch 1091 / 1350, Loss: 0.07911119610071182\n",
            "Epoch 2, Batch 1092 / 1350, Loss: 0.1307591050863266\n",
            "Epoch 2, Batch 1093 / 1350, Loss: 0.8546079397201538\n",
            "Epoch 2, Batch 1094 / 1350, Loss: 0.8780484795570374\n",
            "Epoch 2, Batch 1095 / 1350, Loss: 0.563636064529419\n",
            "Epoch 2, Batch 1096 / 1350, Loss: 0.2681118845939636\n",
            "Epoch 2, Batch 1097 / 1350, Loss: 0.14599308371543884\n",
            "Epoch 2, Batch 1098 / 1350, Loss: 0.38754117488861084\n",
            "Epoch 2, Batch 1099 / 1350, Loss: 0.37249696254730225\n",
            "Epoch 2, Batch 1100 / 1350, Loss: 0.11826333403587341\n",
            "Epoch 2, Batch 1101 / 1350, Loss: 0.21518203616142273\n",
            "Epoch 2, Batch 1102 / 1350, Loss: 0.12307026982307434\n",
            "Epoch 2, Batch 1103 / 1350, Loss: 0.27658891677856445\n",
            "Epoch 2, Batch 1104 / 1350, Loss: 0.14422836899757385\n",
            "Epoch 2, Batch 1105 / 1350, Loss: 0.39105647802352905\n",
            "Epoch 2, Batch 1106 / 1350, Loss: 0.13721135258674622\n",
            "Epoch 2, Batch 1107 / 1350, Loss: 0.1173991709947586\n",
            "Epoch 2, Batch 1108 / 1350, Loss: 0.21579575538635254\n",
            "Epoch 2, Batch 1109 / 1350, Loss: 0.48275226354599\n",
            "Epoch 2, Batch 1110 / 1350, Loss: 0.39746958017349243\n",
            "Epoch 2, Batch 1111 / 1350, Loss: 0.08909327536821365\n",
            "Epoch 2, Batch 1112 / 1350, Loss: 0.08894497156143188\n",
            "Epoch 2, Batch 1113 / 1350, Loss: 0.060404758900403976\n",
            "Epoch 2, Batch 1114 / 1350, Loss: 1.0442017316818237\n",
            "Epoch 2, Batch 1115 / 1350, Loss: 0.17640677094459534\n",
            "Epoch 2, Batch 1116 / 1350, Loss: 1.024179458618164\n",
            "Epoch 2, Batch 1117 / 1350, Loss: 0.6146879196166992\n",
            "Epoch 2, Batch 1118 / 1350, Loss: 0.17467056214809418\n",
            "Epoch 2, Batch 1119 / 1350, Loss: 0.32122644782066345\n",
            "Epoch 2, Batch 1120 / 1350, Loss: 0.14864298701286316\n",
            "Epoch 2, Batch 1121 / 1350, Loss: 0.721174955368042\n",
            "Epoch 2, Batch 1122 / 1350, Loss: 0.2708776593208313\n",
            "Epoch 2, Batch 1123 / 1350, Loss: 0.5264366269111633\n",
            "Epoch 2, Batch 1124 / 1350, Loss: 0.25949710607528687\n",
            "Epoch 2, Batch 1125 / 1350, Loss: 0.40859436988830566\n",
            "Epoch 2, Batch 1126 / 1350, Loss: 0.09020845592021942\n",
            "Epoch 2, Batch 1127 / 1350, Loss: 0.214542955160141\n",
            "Epoch 2, Batch 1128 / 1350, Loss: 0.8120613694190979\n",
            "Epoch 2, Batch 1129 / 1350, Loss: 0.6601654291152954\n",
            "Epoch 2, Batch 1130 / 1350, Loss: 0.5969143509864807\n",
            "Epoch 2, Batch 1131 / 1350, Loss: 0.18121543526649475\n",
            "Epoch 2, Batch 1132 / 1350, Loss: 0.2848895490169525\n",
            "Epoch 2, Batch 1133 / 1350, Loss: 0.9258517622947693\n",
            "Epoch 2, Batch 1134 / 1350, Loss: 0.08510366082191467\n",
            "Epoch 2, Batch 1135 / 1350, Loss: 0.3261176645755768\n",
            "Epoch 2, Batch 1136 / 1350, Loss: 0.07120691239833832\n",
            "Epoch 2, Batch 1137 / 1350, Loss: 0.1255210041999817\n",
            "Epoch 2, Batch 1138 / 1350, Loss: 0.29198890924453735\n",
            "Epoch 2, Batch 1139 / 1350, Loss: 0.1447184830904007\n",
            "Epoch 2, Batch 1140 / 1350, Loss: 0.1212897002696991\n",
            "Epoch 2, Batch 1141 / 1350, Loss: 0.6295508146286011\n",
            "Epoch 2, Batch 1142 / 1350, Loss: 0.6291064023971558\n",
            "Epoch 2, Batch 1143 / 1350, Loss: 0.45921337604522705\n",
            "Epoch 2, Batch 1144 / 1350, Loss: 0.5782649517059326\n",
            "Epoch 2, Batch 1145 / 1350, Loss: 0.23824705183506012\n",
            "Epoch 2, Batch 1146 / 1350, Loss: 0.4032733142375946\n",
            "Epoch 2, Batch 1147 / 1350, Loss: 0.6306952834129333\n",
            "Epoch 2, Batch 1148 / 1350, Loss: 0.41942501068115234\n",
            "Epoch 2, Batch 1149 / 1350, Loss: 0.14869892597198486\n",
            "Epoch 2, Batch 1150 / 1350, Loss: 0.24016007781028748\n",
            "Epoch 2, Batch 1151 / 1350, Loss: 0.20413580536842346\n",
            "Epoch 2, Batch 1152 / 1350, Loss: 0.06339830905199051\n",
            "Epoch 2, Batch 1153 / 1350, Loss: 0.08003422617912292\n",
            "Epoch 2, Batch 1154 / 1350, Loss: 0.4714462161064148\n",
            "Epoch 2, Batch 1155 / 1350, Loss: 0.20353670418262482\n",
            "Epoch 2, Batch 1156 / 1350, Loss: 0.14955629408359528\n",
            "Epoch 2, Batch 1157 / 1350, Loss: 0.4630579948425293\n",
            "Epoch 2, Batch 1158 / 1350, Loss: 0.5804647207260132\n",
            "Epoch 2, Batch 1159 / 1350, Loss: 0.1392175853252411\n",
            "Epoch 2, Batch 1160 / 1350, Loss: 0.2292536348104477\n",
            "Epoch 2, Batch 1161 / 1350, Loss: 0.1713504195213318\n",
            "Epoch 2, Batch 1162 / 1350, Loss: 0.09101410210132599\n",
            "Epoch 2, Batch 1163 / 1350, Loss: 0.6762371063232422\n",
            "Epoch 2, Batch 1164 / 1350, Loss: 0.44135943055152893\n",
            "Epoch 2, Batch 1165 / 1350, Loss: 0.14491194486618042\n",
            "Epoch 2, Batch 1166 / 1350, Loss: 0.23037227988243103\n",
            "Epoch 2, Batch 1167 / 1350, Loss: 0.1434943825006485\n",
            "Epoch 2, Batch 1168 / 1350, Loss: 0.14278855919837952\n",
            "Epoch 2, Batch 1169 / 1350, Loss: 0.48871445655822754\n",
            "Epoch 2, Batch 1170 / 1350, Loss: 0.5284951329231262\n",
            "Epoch 2, Batch 1171 / 1350, Loss: 0.6549822092056274\n",
            "Epoch 2, Batch 1172 / 1350, Loss: 0.2908545434474945\n",
            "Epoch 2, Batch 1173 / 1350, Loss: 0.32685333490371704\n",
            "Epoch 2, Batch 1174 / 1350, Loss: 1.0224369764328003\n",
            "Epoch 2, Batch 1175 / 1350, Loss: 0.2435234636068344\n",
            "Epoch 2, Batch 1176 / 1350, Loss: 0.11647529900074005\n",
            "Epoch 2, Batch 1177 / 1350, Loss: 0.29635220766067505\n",
            "Epoch 2, Batch 1178 / 1350, Loss: 0.15197330713272095\n",
            "Epoch 2, Batch 1179 / 1350, Loss: 0.3179718852043152\n",
            "Epoch 2, Batch 1180 / 1350, Loss: 0.19828884303569794\n",
            "Epoch 2, Batch 1181 / 1350, Loss: 0.04466039687395096\n",
            "Epoch 2, Batch 1182 / 1350, Loss: 0.5498172640800476\n",
            "Epoch 2, Batch 1183 / 1350, Loss: 0.08258461207151413\n",
            "Epoch 2, Batch 1184 / 1350, Loss: 1.0983521938323975\n",
            "Epoch 2, Batch 1185 / 1350, Loss: 0.6925433874130249\n",
            "Epoch 2, Batch 1186 / 1350, Loss: 0.5443508625030518\n",
            "Epoch 2, Batch 1187 / 1350, Loss: 0.06491938978433609\n",
            "Epoch 2, Batch 1188 / 1350, Loss: 0.26035967469215393\n",
            "Epoch 2, Batch 1189 / 1350, Loss: 0.7565534114837646\n",
            "Epoch 2, Batch 1190 / 1350, Loss: 0.8908213973045349\n",
            "Epoch 2, Batch 1191 / 1350, Loss: 0.5490719079971313\n",
            "Epoch 2, Batch 1192 / 1350, Loss: 0.024236418306827545\n",
            "Epoch 2, Batch 1193 / 1350, Loss: 0.17332787811756134\n",
            "Epoch 2, Batch 1194 / 1350, Loss: 0.8366131782531738\n",
            "Epoch 2, Batch 1195 / 1350, Loss: 0.5216103792190552\n",
            "Epoch 2, Batch 1196 / 1350, Loss: 0.27840423583984375\n",
            "Epoch 2, Batch 1197 / 1350, Loss: 0.29026859998703003\n",
            "Epoch 2, Batch 1198 / 1350, Loss: 0.4335194230079651\n",
            "Epoch 2, Batch 1199 / 1350, Loss: 0.4212157130241394\n",
            "Epoch 2, Batch 1200 / 1350, Loss: 0.09431053698062897\n",
            "Epoch 2, Batch 1201 / 1350, Loss: 0.44821447134017944\n",
            "Epoch 2, Batch 1202 / 1350, Loss: 1.0508742332458496\n",
            "Epoch 2, Batch 1203 / 1350, Loss: 0.4082794785499573\n",
            "Epoch 2, Batch 1204 / 1350, Loss: 0.2549603581428528\n",
            "Epoch 2, Batch 1205 / 1350, Loss: 0.29348838329315186\n",
            "Epoch 2, Batch 1206 / 1350, Loss: 0.37452539801597595\n",
            "Epoch 2, Batch 1207 / 1350, Loss: 0.6320213675498962\n",
            "Epoch 2, Batch 1208 / 1350, Loss: 0.20122140645980835\n",
            "Epoch 2, Batch 1209 / 1350, Loss: 0.417645126581192\n",
            "Epoch 2, Batch 1210 / 1350, Loss: 0.6428714394569397\n",
            "Epoch 2, Batch 1211 / 1350, Loss: 0.15541556477546692\n",
            "Epoch 2, Batch 1212 / 1350, Loss: 0.32066839933395386\n",
            "Epoch 2, Batch 1213 / 1350, Loss: 0.35247260332107544\n",
            "Epoch 2, Batch 1214 / 1350, Loss: 0.15062814950942993\n",
            "Epoch 2, Batch 1215 / 1350, Loss: 0.3230894207954407\n",
            "Epoch 2, Batch 1216 / 1350, Loss: 0.2564859986305237\n",
            "Epoch 2, Batch 1217 / 1350, Loss: 0.11416257917881012\n",
            "Epoch 2, Batch 1218 / 1350, Loss: 0.1549653261899948\n",
            "Epoch 2, Batch 1219 / 1350, Loss: 0.12396413087844849\n",
            "Epoch 2, Batch 1220 / 1350, Loss: 0.09103229641914368\n",
            "Epoch 2, Batch 1221 / 1350, Loss: 0.13214805722236633\n",
            "Epoch 2, Batch 1222 / 1350, Loss: 0.2523673474788666\n",
            "Epoch 2, Batch 1223 / 1350, Loss: 0.21566550433635712\n",
            "Epoch 2, Batch 1224 / 1350, Loss: 0.06755231320858002\n",
            "Epoch 2, Batch 1225 / 1350, Loss: 0.026848897337913513\n",
            "Epoch 2, Batch 1226 / 1350, Loss: 0.10311804711818695\n",
            "Epoch 2, Batch 1227 / 1350, Loss: 0.4816778898239136\n",
            "Epoch 2, Batch 1228 / 1350, Loss: 0.1958339959383011\n",
            "Epoch 2, Batch 1229 / 1350, Loss: 0.37234461307525635\n",
            "Epoch 2, Batch 1230 / 1350, Loss: 0.06346257030963898\n",
            "Epoch 2, Batch 1231 / 1350, Loss: 0.6184804439544678\n",
            "Epoch 2, Batch 1232 / 1350, Loss: 0.052014485001564026\n",
            "Epoch 2, Batch 1233 / 1350, Loss: 0.08332034945487976\n",
            "Epoch 2, Batch 1234 / 1350, Loss: 0.13021178543567657\n",
            "Epoch 2, Batch 1235 / 1350, Loss: 0.9870268702507019\n",
            "Epoch 2, Batch 1236 / 1350, Loss: 0.1030939593911171\n",
            "Epoch 2, Batch 1237 / 1350, Loss: 0.3434324562549591\n",
            "Epoch 2, Batch 1238 / 1350, Loss: 0.3551909923553467\n",
            "Epoch 2, Batch 1239 / 1350, Loss: 0.03436687961220741\n",
            "Epoch 2, Batch 1240 / 1350, Loss: 0.04767225682735443\n",
            "Epoch 2, Batch 1241 / 1350, Loss: 0.28445351123809814\n",
            "Epoch 2, Batch 1242 / 1350, Loss: 0.219774067401886\n",
            "Epoch 2, Batch 1243 / 1350, Loss: 0.029101742431521416\n",
            "Epoch 2, Batch 1244 / 1350, Loss: 0.14200226962566376\n",
            "Epoch 2, Batch 1245 / 1350, Loss: 0.397288978099823\n",
            "Epoch 2, Batch 1246 / 1350, Loss: 0.8881943225860596\n",
            "Epoch 2, Batch 1247 / 1350, Loss: 0.18920530378818512\n",
            "Epoch 2, Batch 1248 / 1350, Loss: 0.5207988023757935\n",
            "Epoch 2, Batch 1249 / 1350, Loss: 0.2251211404800415\n",
            "Epoch 2, Batch 1250 / 1350, Loss: 0.08374272286891937\n",
            "Epoch 2, Batch 1251 / 1350, Loss: 0.699779212474823\n",
            "Epoch 2, Batch 1252 / 1350, Loss: 0.6700148582458496\n",
            "Epoch 2, Batch 1253 / 1350, Loss: 0.3335915505886078\n",
            "Epoch 2, Batch 1254 / 1350, Loss: 0.42996078729629517\n",
            "Epoch 2, Batch 1255 / 1350, Loss: 0.18195655941963196\n",
            "Epoch 2, Batch 1256 / 1350, Loss: 0.28858470916748047\n",
            "Epoch 2, Batch 1257 / 1350, Loss: 0.5108599662780762\n",
            "Epoch 2, Batch 1258 / 1350, Loss: 0.16236868500709534\n",
            "Epoch 2, Batch 1259 / 1350, Loss: 0.32479894161224365\n",
            "Epoch 2, Batch 1260 / 1350, Loss: 0.10299763083457947\n",
            "Epoch 2, Batch 1261 / 1350, Loss: 0.9833430051803589\n",
            "Epoch 2, Batch 1262 / 1350, Loss: 0.06311026215553284\n",
            "Epoch 2, Batch 1263 / 1350, Loss: 0.17903998494148254\n",
            "Epoch 2, Batch 1264 / 1350, Loss: 1.2677748203277588\n",
            "Epoch 2, Batch 1265 / 1350, Loss: 0.08398322016000748\n",
            "Epoch 2, Batch 1266 / 1350, Loss: 0.12839192152023315\n",
            "Epoch 2, Batch 1267 / 1350, Loss: 0.19736333191394806\n",
            "Epoch 2, Batch 1268 / 1350, Loss: 0.046557024121284485\n",
            "Epoch 2, Batch 1269 / 1350, Loss: 0.11138860881328583\n",
            "Epoch 2, Batch 1270 / 1350, Loss: 0.43416693806648254\n",
            "Epoch 2, Batch 1271 / 1350, Loss: 0.1337769776582718\n",
            "Epoch 2, Batch 1272 / 1350, Loss: 0.540871262550354\n",
            "Epoch 2, Batch 1273 / 1350, Loss: 0.1779327690601349\n",
            "Epoch 2, Batch 1274 / 1350, Loss: 0.2710409164428711\n",
            "Epoch 2, Batch 1275 / 1350, Loss: 1.371971607208252\n",
            "Epoch 2, Batch 1276 / 1350, Loss: 0.23951846361160278\n",
            "Epoch 2, Batch 1277 / 1350, Loss: 0.6356788277626038\n",
            "Epoch 2, Batch 1278 / 1350, Loss: 0.6542151570320129\n",
            "Epoch 2, Batch 1279 / 1350, Loss: 1.2751200199127197\n",
            "Epoch 2, Batch 1280 / 1350, Loss: 0.5480027198791504\n",
            "Epoch 2, Batch 1281 / 1350, Loss: 0.7931802868843079\n",
            "Epoch 2, Batch 1282 / 1350, Loss: 0.1259724497795105\n",
            "Epoch 2, Batch 1283 / 1350, Loss: 1.0830323696136475\n",
            "Epoch 2, Batch 1284 / 1350, Loss: 0.8946187496185303\n",
            "Epoch 2, Batch 1285 / 1350, Loss: 0.3831990361213684\n",
            "Epoch 2, Batch 1286 / 1350, Loss: 0.3235440254211426\n",
            "Epoch 2, Batch 1287 / 1350, Loss: 0.23770347237586975\n",
            "Epoch 2, Batch 1288 / 1350, Loss: 0.9080145359039307\n",
            "Epoch 2, Batch 1289 / 1350, Loss: 0.4746477007865906\n",
            "Epoch 2, Batch 1290 / 1350, Loss: 0.11013953387737274\n",
            "Epoch 2, Batch 1291 / 1350, Loss: 0.06577910482883453\n",
            "Epoch 2, Batch 1292 / 1350, Loss: 0.7385332584381104\n",
            "Epoch 2, Batch 1293 / 1350, Loss: 0.712356448173523\n",
            "Epoch 2, Batch 1294 / 1350, Loss: 0.20558401942253113\n",
            "Epoch 2, Batch 1295 / 1350, Loss: 0.42844897508621216\n",
            "Epoch 2, Batch 1296 / 1350, Loss: 0.9207572340965271\n",
            "Epoch 2, Batch 1297 / 1350, Loss: 0.3776048421859741\n",
            "Epoch 2, Batch 1298 / 1350, Loss: 0.3952639102935791\n",
            "Epoch 2, Batch 1299 / 1350, Loss: 0.24102075397968292\n",
            "Epoch 2, Batch 1300 / 1350, Loss: 0.2934369444847107\n",
            "Epoch 2, Batch 1301 / 1350, Loss: 0.22666527330875397\n",
            "Epoch 2, Batch 1302 / 1350, Loss: 0.463469922542572\n",
            "Epoch 2, Batch 1303 / 1350, Loss: 0.39496082067489624\n",
            "Epoch 2, Batch 1304 / 1350, Loss: 0.4217436909675598\n",
            "Epoch 2, Batch 1305 / 1350, Loss: 0.1705423891544342\n",
            "Epoch 2, Batch 1306 / 1350, Loss: 0.5711648464202881\n",
            "Epoch 2, Batch 1307 / 1350, Loss: 0.21678291261196136\n",
            "Epoch 2, Batch 1308 / 1350, Loss: 0.3290431797504425\n",
            "Epoch 2, Batch 1309 / 1350, Loss: 0.18789488077163696\n",
            "Epoch 2, Batch 1310 / 1350, Loss: 0.3292480409145355\n",
            "Epoch 2, Batch 1311 / 1350, Loss: 0.35384267568588257\n",
            "Epoch 2, Batch 1312 / 1350, Loss: 0.2824592590332031\n",
            "Epoch 2, Batch 1313 / 1350, Loss: 0.41982489824295044\n",
            "Epoch 2, Batch 1314 / 1350, Loss: 0.22707445919513702\n",
            "Epoch 2, Batch 1315 / 1350, Loss: 0.529620349407196\n",
            "Epoch 2, Batch 1316 / 1350, Loss: 0.24845081567764282\n",
            "Epoch 2, Batch 1317 / 1350, Loss: 0.24326176941394806\n",
            "Epoch 2, Batch 1318 / 1350, Loss: 0.6807478666305542\n",
            "Epoch 2, Batch 1319 / 1350, Loss: 0.5061613917350769\n",
            "Epoch 2, Batch 1320 / 1350, Loss: 0.6234214305877686\n",
            "Epoch 2, Batch 1321 / 1350, Loss: 0.3355496823787689\n",
            "Epoch 2, Batch 1322 / 1350, Loss: 0.2242768257856369\n",
            "Epoch 2, Batch 1323 / 1350, Loss: 0.5046625137329102\n",
            "Epoch 2, Batch 1324 / 1350, Loss: 0.04266584292054176\n",
            "Epoch 2, Batch 1325 / 1350, Loss: 0.39139842987060547\n",
            "Epoch 2, Batch 1326 / 1350, Loss: 0.06169264391064644\n",
            "Epoch 2, Batch 1327 / 1350, Loss: 0.681317150592804\n",
            "Epoch 2, Batch 1328 / 1350, Loss: 0.3600640594959259\n",
            "Epoch 2, Batch 1329 / 1350, Loss: 0.46838220953941345\n",
            "Epoch 2, Batch 1330 / 1350, Loss: 0.4842946529388428\n",
            "Epoch 2, Batch 1331 / 1350, Loss: 0.6425279378890991\n",
            "Epoch 2, Batch 1332 / 1350, Loss: 0.4301312565803528\n",
            "Epoch 2, Batch 1333 / 1350, Loss: 0.1065392941236496\n",
            "Epoch 2, Batch 1334 / 1350, Loss: 0.7473911643028259\n",
            "Epoch 2, Batch 1335 / 1350, Loss: 0.9815925359725952\n",
            "Epoch 2, Batch 1336 / 1350, Loss: 0.27948281168937683\n",
            "Epoch 2, Batch 1337 / 1350, Loss: 0.42214059829711914\n",
            "Epoch 2, Batch 1338 / 1350, Loss: 0.4388183355331421\n",
            "Epoch 2, Batch 1339 / 1350, Loss: 0.1475645899772644\n",
            "Epoch 2, Batch 1340 / 1350, Loss: 0.4025789499282837\n",
            "Epoch 2, Batch 1341 / 1350, Loss: 0.40831077098846436\n",
            "Epoch 2, Batch 1342 / 1350, Loss: 0.26450154185295105\n",
            "Epoch 2, Batch 1343 / 1350, Loss: 0.6045581698417664\n",
            "Epoch 2, Batch 1344 / 1350, Loss: 0.2914871275424957\n",
            "Epoch 2, Batch 1345 / 1350, Loss: 0.28665465116500854\n",
            "Epoch 2, Batch 1346 / 1350, Loss: 0.4608226418495178\n",
            "Epoch 2, Batch 1347 / 1350, Loss: 1.106603741645813\n",
            "Epoch 2, Batch 1348 / 1350, Loss: 0.233251690864563\n",
            "Epoch 2, Batch 1349 / 1350, Loss: 0.1347794532775879\n",
            "Epoch 2, Batch 1350 / 1350, Loss: 0.06529835611581802\n",
            "Epoch 2, Loss: 0.3867132142006799, Accuracy: 0.9086529553455623, Auc: 0.8835404411996495, f1: 0.8607737927139226\n",
            "Epoch 2, Train Loss: 7.35299773480166, Validation Accuracy: 0.8014184397163121\n",
            "Epoch 3, Batch 1 / 1350, Loss: 0.03706975653767586\n",
            "Epoch 3, Batch 2 / 1350, Loss: 0.13394266366958618\n",
            "Epoch 3, Batch 3 / 1350, Loss: 0.09468559175729752\n",
            "Epoch 3, Batch 4 / 1350, Loss: 0.2557510435581207\n",
            "Epoch 3, Batch 5 / 1350, Loss: 0.46567195653915405\n",
            "Epoch 3, Batch 6 / 1350, Loss: 0.1748550832271576\n",
            "Epoch 3, Batch 7 / 1350, Loss: 0.07929141819477081\n",
            "Epoch 3, Batch 8 / 1350, Loss: 0.09675582498311996\n",
            "Epoch 3, Batch 9 / 1350, Loss: 0.18923568725585938\n",
            "Epoch 3, Batch 10 / 1350, Loss: 0.6755587458610535\n",
            "Epoch 3, Batch 11 / 1350, Loss: 0.17077499628067017\n",
            "Epoch 3, Batch 12 / 1350, Loss: 0.12180661410093307\n",
            "Epoch 3, Batch 13 / 1350, Loss: 0.2016768902540207\n",
            "Epoch 3, Batch 14 / 1350, Loss: 0.8245869278907776\n",
            "Epoch 3, Batch 15 / 1350, Loss: 0.37728315591812134\n",
            "Epoch 3, Batch 16 / 1350, Loss: 0.34410330653190613\n",
            "Epoch 3, Batch 17 / 1350, Loss: 0.47016364336013794\n",
            "Epoch 3, Batch 18 / 1350, Loss: 0.1259506642818451\n",
            "Epoch 3, Batch 19 / 1350, Loss: 0.03249268978834152\n",
            "Epoch 3, Batch 20 / 1350, Loss: 0.5288987159729004\n",
            "Epoch 3, Batch 21 / 1350, Loss: 0.029584990814328194\n",
            "Epoch 3, Batch 22 / 1350, Loss: 0.19810667634010315\n",
            "Epoch 3, Batch 23 / 1350, Loss: 0.459287166595459\n",
            "Epoch 3, Batch 24 / 1350, Loss: 0.09710299223661423\n",
            "Epoch 3, Batch 25 / 1350, Loss: 0.41120558977127075\n",
            "Epoch 3, Batch 26 / 1350, Loss: 0.7743897438049316\n",
            "Epoch 3, Batch 27 / 1350, Loss: 0.1004486232995987\n",
            "Epoch 3, Batch 28 / 1350, Loss: 0.14106886088848114\n",
            "Epoch 3, Batch 29 / 1350, Loss: 0.2751319110393524\n",
            "Epoch 3, Batch 30 / 1350, Loss: 0.0756891742348671\n",
            "Epoch 3, Batch 31 / 1350, Loss: 0.1134164035320282\n",
            "Epoch 3, Batch 32 / 1350, Loss: 0.10369331389665604\n",
            "Epoch 3, Batch 33 / 1350, Loss: 0.44292324781417847\n",
            "Epoch 3, Batch 34 / 1350, Loss: 0.05958876758813858\n",
            "Epoch 3, Batch 35 / 1350, Loss: 0.25774529576301575\n",
            "Epoch 3, Batch 36 / 1350, Loss: 0.3339036703109741\n",
            "Epoch 3, Batch 37 / 1350, Loss: 0.3101099729537964\n",
            "Epoch 3, Batch 38 / 1350, Loss: 0.13492286205291748\n",
            "Epoch 3, Batch 39 / 1350, Loss: 0.09175565838813782\n",
            "Epoch 3, Batch 40 / 1350, Loss: 0.02227560430765152\n",
            "Epoch 3, Batch 41 / 1350, Loss: 0.5350621938705444\n",
            "Epoch 3, Batch 42 / 1350, Loss: 0.1021512895822525\n",
            "Epoch 3, Batch 43 / 1350, Loss: 0.2921535074710846\n",
            "Epoch 3, Batch 44 / 1350, Loss: 0.20506075024604797\n",
            "Epoch 3, Batch 45 / 1350, Loss: 0.03321615606546402\n",
            "Epoch 3, Batch 46 / 1350, Loss: 0.13053910434246063\n",
            "Epoch 3, Batch 47 / 1350, Loss: 0.025933610275387764\n",
            "Epoch 3, Batch 48 / 1350, Loss: 0.015936002135276794\n",
            "Epoch 3, Batch 49 / 1350, Loss: 0.41516029834747314\n",
            "Epoch 3, Batch 50 / 1350, Loss: 0.023468971252441406\n",
            "Epoch 3, Batch 51 / 1350, Loss: 0.017017817124724388\n",
            "Epoch 3, Batch 52 / 1350, Loss: 0.2149432897567749\n",
            "Epoch 3, Batch 53 / 1350, Loss: 0.07677483558654785\n",
            "Epoch 3, Batch 54 / 1350, Loss: 0.062381431460380554\n",
            "Epoch 3, Batch 55 / 1350, Loss: 0.09226025640964508\n",
            "Epoch 3, Batch 56 / 1350, Loss: 0.03542144224047661\n",
            "Epoch 3, Batch 57 / 1350, Loss: 0.8734482526779175\n",
            "Epoch 3, Batch 58 / 1350, Loss: 0.14635759592056274\n",
            "Epoch 3, Batch 59 / 1350, Loss: 0.46417173743247986\n",
            "Epoch 3, Batch 60 / 1350, Loss: 0.46576252579689026\n",
            "Epoch 3, Batch 61 / 1350, Loss: 0.1253228336572647\n",
            "Epoch 3, Batch 62 / 1350, Loss: 0.015667341649532318\n",
            "Epoch 3, Batch 63 / 1350, Loss: 0.1623176485300064\n",
            "Epoch 3, Batch 64 / 1350, Loss: 0.023704905062913895\n",
            "Epoch 3, Batch 65 / 1350, Loss: 0.8436150550842285\n",
            "Epoch 3, Batch 66 / 1350, Loss: 0.44697505235671997\n",
            "Epoch 3, Batch 67 / 1350, Loss: 0.03744004666805267\n",
            "Epoch 3, Batch 68 / 1350, Loss: 0.20063114166259766\n",
            "Epoch 3, Batch 69 / 1350, Loss: 0.09825662523508072\n",
            "Epoch 3, Batch 70 / 1350, Loss: 0.03969494625926018\n",
            "Epoch 3, Batch 71 / 1350, Loss: 0.07556739449501038\n",
            "Epoch 3, Batch 72 / 1350, Loss: 0.22809600830078125\n",
            "Epoch 3, Batch 73 / 1350, Loss: 0.22449764609336853\n",
            "Epoch 3, Batch 74 / 1350, Loss: 0.09871417284011841\n",
            "Epoch 3, Batch 75 / 1350, Loss: 0.7484515905380249\n",
            "Epoch 3, Batch 76 / 1350, Loss: 0.3285486400127411\n",
            "Epoch 3, Batch 77 / 1350, Loss: 0.039153292775154114\n",
            "Epoch 3, Batch 78 / 1350, Loss: 0.015232647769153118\n",
            "Epoch 3, Batch 79 / 1350, Loss: 0.4609778821468353\n",
            "Epoch 3, Batch 80 / 1350, Loss: 0.7640241384506226\n",
            "Epoch 3, Batch 81 / 1350, Loss: 0.014169876463711262\n",
            "Epoch 3, Batch 82 / 1350, Loss: 0.025287125259637833\n",
            "Epoch 3, Batch 83 / 1350, Loss: 0.30244261026382446\n",
            "Epoch 3, Batch 84 / 1350, Loss: 1.248070478439331\n",
            "Epoch 3, Batch 85 / 1350, Loss: 1.1047701835632324\n",
            "Epoch 3, Batch 86 / 1350, Loss: 0.2378084808588028\n",
            "Epoch 3, Batch 87 / 1350, Loss: 0.04883507266640663\n",
            "Epoch 3, Batch 88 / 1350, Loss: 0.47119927406311035\n",
            "Epoch 3, Batch 89 / 1350, Loss: 0.06467478722333908\n",
            "Epoch 3, Batch 90 / 1350, Loss: 0.508236289024353\n",
            "Epoch 3, Batch 91 / 1350, Loss: 0.04889567196369171\n",
            "Epoch 3, Batch 92 / 1350, Loss: 0.2630223333835602\n",
            "Epoch 3, Batch 93 / 1350, Loss: 0.1759643852710724\n",
            "Epoch 3, Batch 94 / 1350, Loss: 0.12101048976182938\n",
            "Epoch 3, Batch 95 / 1350, Loss: 0.22932787239551544\n",
            "Epoch 3, Batch 96 / 1350, Loss: 0.11884824931621552\n",
            "Epoch 3, Batch 97 / 1350, Loss: 0.10531061887741089\n",
            "Epoch 3, Batch 98 / 1350, Loss: 0.2226274609565735\n",
            "Epoch 3, Batch 99 / 1350, Loss: 0.33717334270477295\n",
            "Epoch 3, Batch 100 / 1350, Loss: 0.1941242218017578\n",
            "Epoch 3, Batch 101 / 1350, Loss: 0.3997628092765808\n",
            "Epoch 3, Batch 102 / 1350, Loss: 0.8062390089035034\n",
            "Epoch 3, Batch 103 / 1350, Loss: 0.0639604777097702\n",
            "Epoch 3, Batch 104 / 1350, Loss: 0.21852079033851624\n",
            "Epoch 3, Batch 105 / 1350, Loss: 0.43957507610321045\n",
            "Epoch 3, Batch 106 / 1350, Loss: 0.5460753440856934\n",
            "Epoch 3, Batch 107 / 1350, Loss: 0.03255550563335419\n",
            "Epoch 3, Batch 108 / 1350, Loss: 0.16684789955615997\n",
            "Epoch 3, Batch 109 / 1350, Loss: 0.11453460901975632\n",
            "Epoch 3, Batch 110 / 1350, Loss: 0.7895545959472656\n",
            "Epoch 3, Batch 111 / 1350, Loss: 0.07024838775396347\n",
            "Epoch 3, Batch 112 / 1350, Loss: 0.06145475432276726\n",
            "Epoch 3, Batch 113 / 1350, Loss: 0.025626718997955322\n",
            "Epoch 3, Batch 114 / 1350, Loss: 0.41771742701530457\n",
            "Epoch 3, Batch 115 / 1350, Loss: 0.19199290871620178\n",
            "Epoch 3, Batch 116 / 1350, Loss: 0.4316481053829193\n",
            "Epoch 3, Batch 117 / 1350, Loss: 0.2867432236671448\n",
            "Epoch 3, Batch 118 / 1350, Loss: 0.0565260574221611\n",
            "Epoch 3, Batch 119 / 1350, Loss: 0.3949229419231415\n",
            "Epoch 3, Batch 120 / 1350, Loss: 0.31413164734840393\n",
            "Epoch 3, Batch 121 / 1350, Loss: 0.03344108164310455\n",
            "Epoch 3, Batch 122 / 1350, Loss: 0.02279643714427948\n",
            "Epoch 3, Batch 123 / 1350, Loss: 0.1902431845664978\n",
            "Epoch 3, Batch 124 / 1350, Loss: 0.04524035006761551\n",
            "Epoch 3, Batch 125 / 1350, Loss: 0.5526139736175537\n",
            "Epoch 3, Batch 126 / 1350, Loss: 0.07260335236787796\n",
            "Epoch 3, Batch 127 / 1350, Loss: 0.03365851938724518\n",
            "Epoch 3, Batch 128 / 1350, Loss: 0.04193858057260513\n",
            "Epoch 3, Batch 129 / 1350, Loss: 0.018447894603013992\n",
            "Epoch 3, Batch 130 / 1350, Loss: 0.3798779249191284\n",
            "Epoch 3, Batch 131 / 1350, Loss: 1.452690839767456\n",
            "Epoch 3, Batch 132 / 1350, Loss: 0.28927865624427795\n",
            "Epoch 3, Batch 133 / 1350, Loss: 0.09274043887853622\n",
            "Epoch 3, Batch 134 / 1350, Loss: 0.1461111605167389\n",
            "Epoch 3, Batch 135 / 1350, Loss: 0.23487670719623566\n",
            "Epoch 3, Batch 136 / 1350, Loss: 0.2945006787776947\n",
            "Epoch 3, Batch 137 / 1350, Loss: 0.9265438318252563\n",
            "Epoch 3, Batch 138 / 1350, Loss: 0.06893797218799591\n",
            "Epoch 3, Batch 139 / 1350, Loss: 0.07772960513830185\n",
            "Epoch 3, Batch 140 / 1350, Loss: 0.31226447224617004\n",
            "Epoch 3, Batch 141 / 1350, Loss: 0.08489271998405457\n",
            "Epoch 3, Batch 142 / 1350, Loss: 0.05699433013796806\n",
            "Epoch 3, Batch 143 / 1350, Loss: 0.10490046441555023\n",
            "Epoch 3, Batch 144 / 1350, Loss: 0.1355026662349701\n",
            "Epoch 3, Batch 145 / 1350, Loss: 0.26910263299942017\n",
            "Epoch 3, Batch 146 / 1350, Loss: 0.6104655861854553\n",
            "Epoch 3, Batch 147 / 1350, Loss: 0.21051320433616638\n",
            "Epoch 3, Batch 148 / 1350, Loss: 0.3401965796947479\n",
            "Epoch 3, Batch 149 / 1350, Loss: 0.20218169689178467\n",
            "Epoch 3, Batch 150 / 1350, Loss: 0.3699221611022949\n",
            "Epoch 3, Batch 151 / 1350, Loss: 0.09614197164773941\n",
            "Epoch 3, Batch 152 / 1350, Loss: 0.48440971970558167\n",
            "Epoch 3, Batch 153 / 1350, Loss: 0.16703864932060242\n",
            "Epoch 3, Batch 154 / 1350, Loss: 0.036566734313964844\n",
            "Epoch 3, Batch 155 / 1350, Loss: 0.06750138849020004\n",
            "Epoch 3, Batch 156 / 1350, Loss: 0.3849487602710724\n",
            "Epoch 3, Batch 157 / 1350, Loss: 0.21712413430213928\n",
            "Epoch 3, Batch 158 / 1350, Loss: 0.1253528743982315\n",
            "Epoch 3, Batch 159 / 1350, Loss: 0.25507545471191406\n",
            "Epoch 3, Batch 160 / 1350, Loss: 0.04672376811504364\n",
            "Epoch 3, Batch 161 / 1350, Loss: 0.11735855042934418\n",
            "Epoch 3, Batch 162 / 1350, Loss: 0.23331420123577118\n",
            "Epoch 3, Batch 163 / 1350, Loss: 0.14695101976394653\n",
            "Epoch 3, Batch 164 / 1350, Loss: 0.016299955546855927\n",
            "Epoch 3, Batch 165 / 1350, Loss: 0.03507675975561142\n",
            "Epoch 3, Batch 166 / 1350, Loss: 0.028674691915512085\n",
            "Epoch 3, Batch 167 / 1350, Loss: 0.0604681558907032\n",
            "Epoch 3, Batch 168 / 1350, Loss: 0.023818830028176308\n",
            "Epoch 3, Batch 169 / 1350, Loss: 1.0872116088867188\n",
            "Epoch 3, Batch 170 / 1350, Loss: 0.015934593975543976\n",
            "Epoch 3, Batch 171 / 1350, Loss: 0.03820684924721718\n",
            "Epoch 3, Batch 172 / 1350, Loss: 0.12509986758232117\n",
            "Epoch 3, Batch 173 / 1350, Loss: 0.7275857925415039\n",
            "Epoch 3, Batch 174 / 1350, Loss: 0.22320911288261414\n",
            "Epoch 3, Batch 175 / 1350, Loss: 0.8727790713310242\n",
            "Epoch 3, Batch 176 / 1350, Loss: 0.11796850711107254\n",
            "Epoch 3, Batch 177 / 1350, Loss: 0.05763594061136246\n",
            "Epoch 3, Batch 178 / 1350, Loss: 0.10355009138584137\n",
            "Epoch 3, Batch 179 / 1350, Loss: 0.01832057721912861\n",
            "Epoch 3, Batch 180 / 1350, Loss: 1.1985113620758057\n",
            "Epoch 3, Batch 181 / 1350, Loss: 0.05634509027004242\n",
            "Epoch 3, Batch 182 / 1350, Loss: 0.7457846403121948\n",
            "Epoch 3, Batch 183 / 1350, Loss: 0.03464732691645622\n",
            "Epoch 3, Batch 184 / 1350, Loss: 0.64644855260849\n",
            "Epoch 3, Batch 185 / 1350, Loss: 0.18228253722190857\n",
            "Epoch 3, Batch 186 / 1350, Loss: 0.31815314292907715\n",
            "Epoch 3, Batch 187 / 1350, Loss: 0.46228429675102234\n",
            "Epoch 3, Batch 188 / 1350, Loss: 0.24065200984477997\n",
            "Epoch 3, Batch 189 / 1350, Loss: 0.1249103844165802\n",
            "Epoch 3, Batch 190 / 1350, Loss: 0.32829749584198\n",
            "Epoch 3, Batch 191 / 1350, Loss: 0.1269955188035965\n",
            "Epoch 3, Batch 192 / 1350, Loss: 0.030413271859288216\n",
            "Epoch 3, Batch 193 / 1350, Loss: 0.16100558638572693\n",
            "Epoch 3, Batch 194 / 1350, Loss: 0.44514524936676025\n",
            "Epoch 3, Batch 195 / 1350, Loss: 0.03509898483753204\n",
            "Epoch 3, Batch 196 / 1350, Loss: 0.1006443202495575\n",
            "Epoch 3, Batch 197 / 1350, Loss: 0.7834703922271729\n",
            "Epoch 3, Batch 198 / 1350, Loss: 0.13299331068992615\n",
            "Epoch 3, Batch 199 / 1350, Loss: 0.02462616190314293\n",
            "Epoch 3, Batch 200 / 1350, Loss: 0.381410151720047\n",
            "Epoch 3, Batch 201 / 1350, Loss: 0.04023005813360214\n",
            "Epoch 3, Batch 202 / 1350, Loss: 0.3267923891544342\n",
            "Epoch 3, Batch 203 / 1350, Loss: 0.5215223431587219\n",
            "Epoch 3, Batch 204 / 1350, Loss: 0.03908735513687134\n",
            "Epoch 3, Batch 205 / 1350, Loss: 0.10474511981010437\n",
            "Epoch 3, Batch 206 / 1350, Loss: 0.5749030709266663\n",
            "Epoch 3, Batch 207 / 1350, Loss: 0.30111396312713623\n",
            "Epoch 3, Batch 208 / 1350, Loss: 0.023483261466026306\n",
            "Epoch 3, Batch 209 / 1350, Loss: 0.13484755158424377\n",
            "Epoch 3, Batch 210 / 1350, Loss: 0.12467466294765472\n",
            "Epoch 3, Batch 211 / 1350, Loss: 0.03379400819540024\n",
            "Epoch 3, Batch 212 / 1350, Loss: 0.11041294038295746\n",
            "Epoch 3, Batch 213 / 1350, Loss: 0.32074791193008423\n",
            "Epoch 3, Batch 214 / 1350, Loss: 0.13589581847190857\n",
            "Epoch 3, Batch 215 / 1350, Loss: 0.13085654377937317\n",
            "Epoch 3, Batch 216 / 1350, Loss: 0.044625237584114075\n",
            "Epoch 3, Batch 217 / 1350, Loss: 0.554107666015625\n",
            "Epoch 3, Batch 218 / 1350, Loss: 0.06814339756965637\n",
            "Epoch 3, Batch 219 / 1350, Loss: 0.45737266540527344\n",
            "Epoch 3, Batch 220 / 1350, Loss: 0.38264402747154236\n",
            "Epoch 3, Batch 221 / 1350, Loss: 0.316995769739151\n",
            "Epoch 3, Batch 222 / 1350, Loss: 0.6624768376350403\n",
            "Epoch 3, Batch 223 / 1350, Loss: 0.10030113905668259\n",
            "Epoch 3, Batch 224 / 1350, Loss: 0.3636772036552429\n",
            "Epoch 3, Batch 225 / 1350, Loss: 0.3367553651332855\n",
            "Epoch 3, Batch 226 / 1350, Loss: 0.051287420094013214\n",
            "Epoch 3, Batch 227 / 1350, Loss: 0.06429212540388107\n",
            "Epoch 3, Batch 228 / 1350, Loss: 0.027605360373854637\n",
            "Epoch 3, Batch 229 / 1350, Loss: 0.03558875620365143\n",
            "Epoch 3, Batch 230 / 1350, Loss: 0.07753965258598328\n",
            "Epoch 3, Batch 231 / 1350, Loss: 0.07130695879459381\n",
            "Epoch 3, Batch 232 / 1350, Loss: 0.01960761845111847\n",
            "Epoch 3, Batch 233 / 1350, Loss: 0.05920453369617462\n",
            "Epoch 3, Batch 234 / 1350, Loss: 0.01518817525357008\n",
            "Epoch 3, Batch 235 / 1350, Loss: 0.05569561570882797\n",
            "Epoch 3, Batch 236 / 1350, Loss: 0.02012348175048828\n",
            "Epoch 3, Batch 237 / 1350, Loss: 0.15442748367786407\n",
            "Epoch 3, Batch 238 / 1350, Loss: 0.028321312740445137\n",
            "Epoch 3, Batch 239 / 1350, Loss: 0.2552706003189087\n",
            "Epoch 3, Batch 240 / 1350, Loss: 0.1345180869102478\n",
            "Epoch 3, Batch 241 / 1350, Loss: 0.47224825620651245\n",
            "Epoch 3, Batch 242 / 1350, Loss: 0.13482734560966492\n",
            "Epoch 3, Batch 243 / 1350, Loss: 0.3168565630912781\n",
            "Epoch 3, Batch 244 / 1350, Loss: 0.0855441614985466\n",
            "Epoch 3, Batch 245 / 1350, Loss: 0.27035245299339294\n",
            "Epoch 3, Batch 246 / 1350, Loss: 0.1631949543952942\n",
            "Epoch 3, Batch 247 / 1350, Loss: 0.1802184283733368\n",
            "Epoch 3, Batch 248 / 1350, Loss: 0.1243581473827362\n",
            "Epoch 3, Batch 249 / 1350, Loss: 0.024901777505874634\n",
            "Epoch 3, Batch 250 / 1350, Loss: 0.048873573541641235\n",
            "Epoch 3, Batch 251 / 1350, Loss: 0.32345983386039734\n",
            "Epoch 3, Batch 252 / 1350, Loss: 0.039651058614254\n",
            "Epoch 3, Batch 253 / 1350, Loss: 0.03876689821481705\n",
            "Epoch 3, Batch 254 / 1350, Loss: 0.025073684751987457\n",
            "Epoch 3, Batch 255 / 1350, Loss: 0.0468333438038826\n",
            "Epoch 3, Batch 256 / 1350, Loss: 1.1113704442977905\n",
            "Epoch 3, Batch 257 / 1350, Loss: 0.03906359523534775\n",
            "Epoch 3, Batch 258 / 1350, Loss: 0.5636076331138611\n",
            "Epoch 3, Batch 259 / 1350, Loss: 0.11854595690965652\n",
            "Epoch 3, Batch 260 / 1350, Loss: 0.060329221189022064\n",
            "Epoch 3, Batch 261 / 1350, Loss: 0.08385568112134933\n",
            "Epoch 3, Batch 262 / 1350, Loss: 0.11408466100692749\n",
            "Epoch 3, Batch 263 / 1350, Loss: 0.38114747405052185\n",
            "Epoch 3, Batch 264 / 1350, Loss: 0.08992618322372437\n",
            "Epoch 3, Batch 265 / 1350, Loss: 0.14784926176071167\n",
            "Epoch 3, Batch 266 / 1350, Loss: 0.5196083784103394\n",
            "Epoch 3, Batch 267 / 1350, Loss: 0.3096621632575989\n",
            "Epoch 3, Batch 268 / 1350, Loss: 0.15782706439495087\n",
            "Epoch 3, Batch 269 / 1350, Loss: 0.2315746545791626\n",
            "Epoch 3, Batch 270 / 1350, Loss: 0.5292955636978149\n",
            "Epoch 3, Batch 271 / 1350, Loss: 0.2649023234844208\n",
            "Epoch 3, Batch 272 / 1350, Loss: 1.1082195043563843\n",
            "Epoch 3, Batch 273 / 1350, Loss: 0.01651858724653721\n",
            "Epoch 3, Batch 274 / 1350, Loss: 0.20355211198329926\n",
            "Epoch 3, Batch 275 / 1350, Loss: 0.014229821041226387\n",
            "Epoch 3, Batch 276 / 1350, Loss: 0.1792178750038147\n",
            "Epoch 3, Batch 277 / 1350, Loss: 0.012602015398442745\n",
            "Epoch 3, Batch 278 / 1350, Loss: 0.02316577360033989\n",
            "Epoch 3, Batch 279 / 1350, Loss: 0.02452802285552025\n",
            "Epoch 3, Batch 280 / 1350, Loss: 0.06870485842227936\n",
            "Epoch 3, Batch 281 / 1350, Loss: 0.7203847169876099\n",
            "Epoch 3, Batch 282 / 1350, Loss: 0.028193023055791855\n",
            "Epoch 3, Batch 283 / 1350, Loss: 0.37677478790283203\n",
            "Epoch 3, Batch 284 / 1350, Loss: 0.18767644464969635\n",
            "Epoch 3, Batch 285 / 1350, Loss: 0.014770923182368279\n",
            "Epoch 3, Batch 286 / 1350, Loss: 1.026186227798462\n",
            "Epoch 3, Batch 287 / 1350, Loss: 0.45042967796325684\n",
            "Epoch 3, Batch 288 / 1350, Loss: 0.628226101398468\n",
            "Epoch 3, Batch 289 / 1350, Loss: 0.4261969327926636\n",
            "Epoch 3, Batch 290 / 1350, Loss: 0.697150707244873\n",
            "Epoch 3, Batch 291 / 1350, Loss: 0.24921007454395294\n",
            "Epoch 3, Batch 292 / 1350, Loss: 0.20759615302085876\n",
            "Epoch 3, Batch 293 / 1350, Loss: 0.3783043920993805\n",
            "Epoch 3, Batch 294 / 1350, Loss: 0.27708083391189575\n",
            "Epoch 3, Batch 295 / 1350, Loss: 0.14757998287677765\n",
            "Epoch 3, Batch 296 / 1350, Loss: 1.1018919944763184\n",
            "Epoch 3, Batch 297 / 1350, Loss: 0.21184992790222168\n",
            "Epoch 3, Batch 298 / 1350, Loss: 0.6580663323402405\n",
            "Epoch 3, Batch 299 / 1350, Loss: 0.0938943400979042\n",
            "Epoch 3, Batch 300 / 1350, Loss: 0.07239017635583878\n",
            "Epoch 3, Batch 301 / 1350, Loss: 0.2971853017807007\n",
            "Epoch 3, Batch 302 / 1350, Loss: 0.49458712339401245\n",
            "Epoch 3, Batch 303 / 1350, Loss: 0.8939024806022644\n",
            "Epoch 3, Batch 304 / 1350, Loss: 0.769595205783844\n",
            "Epoch 3, Batch 305 / 1350, Loss: 0.11527840793132782\n",
            "Epoch 3, Batch 306 / 1350, Loss: 0.06354915350675583\n",
            "Epoch 3, Batch 307 / 1350, Loss: 0.5518307685852051\n",
            "Epoch 3, Batch 308 / 1350, Loss: 0.024077769368886948\n",
            "Epoch 3, Batch 309 / 1350, Loss: 0.08458462357521057\n",
            "Epoch 3, Batch 310 / 1350, Loss: 0.10126805305480957\n",
            "Epoch 3, Batch 311 / 1350, Loss: 0.22736717760562897\n",
            "Epoch 3, Batch 312 / 1350, Loss: 0.297141969203949\n",
            "Epoch 3, Batch 313 / 1350, Loss: 0.09754641354084015\n",
            "Epoch 3, Batch 314 / 1350, Loss: 0.3958893120288849\n",
            "Epoch 3, Batch 315 / 1350, Loss: 0.44175198674201965\n",
            "Epoch 3, Batch 316 / 1350, Loss: 0.5006492137908936\n",
            "Epoch 3, Batch 317 / 1350, Loss: 0.12182855606079102\n",
            "Epoch 3, Batch 318 / 1350, Loss: 0.14638954401016235\n",
            "Epoch 3, Batch 319 / 1350, Loss: 0.702272891998291\n",
            "Epoch 3, Batch 320 / 1350, Loss: 0.0232505202293396\n",
            "Epoch 3, Batch 321 / 1350, Loss: 0.2694942355155945\n",
            "Epoch 3, Batch 322 / 1350, Loss: 0.6002852916717529\n",
            "Epoch 3, Batch 323 / 1350, Loss: 0.16947561502456665\n",
            "Epoch 3, Batch 324 / 1350, Loss: 0.1271250694990158\n",
            "Epoch 3, Batch 325 / 1350, Loss: 0.520180344581604\n",
            "Epoch 3, Batch 326 / 1350, Loss: 0.18837644159793854\n",
            "Epoch 3, Batch 327 / 1350, Loss: 0.031074825674295425\n",
            "Epoch 3, Batch 328 / 1350, Loss: 0.047640278935432434\n",
            "Epoch 3, Batch 329 / 1350, Loss: 0.11350876837968826\n",
            "Epoch 3, Batch 330 / 1350, Loss: 0.1737767606973648\n",
            "Epoch 3, Batch 331 / 1350, Loss: 0.9639664888381958\n",
            "Epoch 3, Batch 332 / 1350, Loss: 0.13150648772716522\n",
            "Epoch 3, Batch 333 / 1350, Loss: 0.3459777534008026\n",
            "Epoch 3, Batch 334 / 1350, Loss: 0.08081622421741486\n",
            "Epoch 3, Batch 335 / 1350, Loss: 0.08178840577602386\n",
            "Epoch 3, Batch 336 / 1350, Loss: 0.09164802730083466\n",
            "Epoch 3, Batch 337 / 1350, Loss: 0.17754779756069183\n",
            "Epoch 3, Batch 338 / 1350, Loss: 0.023214440792798996\n",
            "Epoch 3, Batch 339 / 1350, Loss: 0.11270718276500702\n",
            "Epoch 3, Batch 340 / 1350, Loss: 0.6380522847175598\n",
            "Epoch 3, Batch 341 / 1350, Loss: 0.37920767068862915\n",
            "Epoch 3, Batch 342 / 1350, Loss: 0.2859081029891968\n",
            "Epoch 3, Batch 343 / 1350, Loss: 0.2510460317134857\n",
            "Epoch 3, Batch 344 / 1350, Loss: 0.04163123667240143\n",
            "Epoch 3, Batch 345 / 1350, Loss: 0.02239437773823738\n",
            "Epoch 3, Batch 346 / 1350, Loss: 0.021842220798134804\n",
            "Epoch 3, Batch 347 / 1350, Loss: 0.08134552091360092\n",
            "Epoch 3, Batch 348 / 1350, Loss: 0.049761928617954254\n",
            "Epoch 3, Batch 349 / 1350, Loss: 0.034508030861616135\n",
            "Epoch 3, Batch 350 / 1350, Loss: 0.09141019731760025\n",
            "Epoch 3, Batch 351 / 1350, Loss: 1.188676357269287\n",
            "Epoch 3, Batch 352 / 1350, Loss: 0.10537160187959671\n",
            "Epoch 3, Batch 353 / 1350, Loss: 0.10387904196977615\n",
            "Epoch 3, Batch 354 / 1350, Loss: 0.019001280888915062\n",
            "Epoch 3, Batch 355 / 1350, Loss: 0.30610889196395874\n",
            "Epoch 3, Batch 356 / 1350, Loss: 0.13014182448387146\n",
            "Epoch 3, Batch 357 / 1350, Loss: 0.08815208822488785\n",
            "Epoch 3, Batch 358 / 1350, Loss: 0.13866564631462097\n",
            "Epoch 3, Batch 359 / 1350, Loss: 0.048421986401081085\n",
            "Epoch 3, Batch 360 / 1350, Loss: 0.024213623255491257\n",
            "Epoch 3, Batch 361 / 1350, Loss: 0.10885011404752731\n",
            "Epoch 3, Batch 362 / 1350, Loss: 0.06674287468194962\n",
            "Epoch 3, Batch 363 / 1350, Loss: 0.20922352373600006\n",
            "Epoch 3, Batch 364 / 1350, Loss: 0.0996260717511177\n",
            "Epoch 3, Batch 365 / 1350, Loss: 0.09582161158323288\n",
            "Epoch 3, Batch 366 / 1350, Loss: 0.17680908739566803\n",
            "Epoch 3, Batch 367 / 1350, Loss: 0.3089333772659302\n",
            "Epoch 3, Batch 368 / 1350, Loss: 0.8890767693519592\n",
            "Epoch 3, Batch 369 / 1350, Loss: 0.034045711159706116\n",
            "Epoch 3, Batch 370 / 1350, Loss: 0.07269974797964096\n",
            "Epoch 3, Batch 371 / 1350, Loss: 0.030492566525936127\n",
            "Epoch 3, Batch 372 / 1350, Loss: 0.17385278642177582\n",
            "Epoch 3, Batch 373 / 1350, Loss: 0.43279922008514404\n",
            "Epoch 3, Batch 374 / 1350, Loss: 0.02490212395787239\n",
            "Epoch 3, Batch 375 / 1350, Loss: 0.2522895336151123\n",
            "Epoch 3, Batch 376 / 1350, Loss: 0.28736618161201477\n",
            "Epoch 3, Batch 377 / 1350, Loss: 0.3604583740234375\n",
            "Epoch 3, Batch 378 / 1350, Loss: 0.19187669456005096\n",
            "Epoch 3, Batch 379 / 1350, Loss: 0.5655772686004639\n",
            "Epoch 3, Batch 380 / 1350, Loss: 0.04178161919116974\n",
            "Epoch 3, Batch 381 / 1350, Loss: 0.0682152509689331\n",
            "Epoch 3, Batch 382 / 1350, Loss: 0.014081154018640518\n",
            "Epoch 3, Batch 383 / 1350, Loss: 0.09561219811439514\n",
            "Epoch 3, Batch 384 / 1350, Loss: 0.024559948593378067\n",
            "Epoch 3, Batch 385 / 1350, Loss: 0.029503649100661278\n",
            "Epoch 3, Batch 386 / 1350, Loss: 0.030378740280866623\n",
            "Epoch 3, Batch 387 / 1350, Loss: 0.027277067303657532\n",
            "Epoch 3, Batch 388 / 1350, Loss: 0.016523122787475586\n",
            "Epoch 3, Batch 389 / 1350, Loss: 0.5478153824806213\n",
            "Epoch 3, Batch 390 / 1350, Loss: 0.022537631914019585\n",
            "Epoch 3, Batch 391 / 1350, Loss: 0.09067385643720627\n",
            "Epoch 3, Batch 392 / 1350, Loss: 0.0328986793756485\n",
            "Epoch 3, Batch 393 / 1350, Loss: 0.014503365382552147\n",
            "Epoch 3, Batch 394 / 1350, Loss: 1.035494089126587\n",
            "Epoch 3, Batch 395 / 1350, Loss: 0.03413105383515358\n",
            "Epoch 3, Batch 396 / 1350, Loss: 0.38093048334121704\n",
            "Epoch 3, Batch 397 / 1350, Loss: 0.0791161060333252\n",
            "Epoch 3, Batch 398 / 1350, Loss: 0.0992765724658966\n",
            "Epoch 3, Batch 399 / 1350, Loss: 0.35576823353767395\n",
            "Epoch 3, Batch 400 / 1350, Loss: 0.07914304733276367\n",
            "Epoch 3, Batch 401 / 1350, Loss: 0.40153074264526367\n",
            "Epoch 3, Batch 402 / 1350, Loss: 0.27867576479911804\n",
            "Epoch 3, Batch 403 / 1350, Loss: 0.026747286319732666\n",
            "Epoch 3, Batch 404 / 1350, Loss: 1.131339430809021\n",
            "Epoch 3, Batch 405 / 1350, Loss: 0.441223680973053\n",
            "Epoch 3, Batch 406 / 1350, Loss: 0.05004145950078964\n",
            "Epoch 3, Batch 407 / 1350, Loss: 0.024543553590774536\n",
            "Epoch 3, Batch 408 / 1350, Loss: 0.04502641409635544\n",
            "Epoch 3, Batch 409 / 1350, Loss: 0.0425003319978714\n",
            "Epoch 3, Batch 410 / 1350, Loss: 1.1203452348709106\n",
            "Epoch 3, Batch 411 / 1350, Loss: 0.07940893620252609\n",
            "Epoch 3, Batch 412 / 1350, Loss: 0.8863531947135925\n",
            "Epoch 3, Batch 413 / 1350, Loss: 0.2179950326681137\n",
            "Epoch 3, Batch 414 / 1350, Loss: 0.035962920635938644\n",
            "Epoch 3, Batch 415 / 1350, Loss: 0.23806053400039673\n",
            "Epoch 3, Batch 416 / 1350, Loss: 0.07826395332813263\n",
            "Epoch 3, Batch 417 / 1350, Loss: 0.33804553747177124\n",
            "Epoch 3, Batch 418 / 1350, Loss: 0.0946497842669487\n",
            "Epoch 3, Batch 419 / 1350, Loss: 0.22950369119644165\n",
            "Epoch 3, Batch 420 / 1350, Loss: 0.29855218529701233\n",
            "Epoch 3, Batch 421 / 1350, Loss: 0.018845047801733017\n",
            "Epoch 3, Batch 422 / 1350, Loss: 0.24666473269462585\n",
            "Epoch 3, Batch 423 / 1350, Loss: 0.04738282412290573\n",
            "Epoch 3, Batch 424 / 1350, Loss: 0.20130878686904907\n",
            "Epoch 3, Batch 425 / 1350, Loss: 0.8670087456703186\n",
            "Epoch 3, Batch 426 / 1350, Loss: 0.06448028981685638\n",
            "Epoch 3, Batch 427 / 1350, Loss: 0.22765716910362244\n",
            "Epoch 3, Batch 428 / 1350, Loss: 0.31593072414398193\n",
            "Epoch 3, Batch 429 / 1350, Loss: 0.151602104306221\n",
            "Epoch 3, Batch 430 / 1350, Loss: 0.020285971462726593\n",
            "Epoch 3, Batch 431 / 1350, Loss: 0.1950327455997467\n",
            "Epoch 3, Batch 432 / 1350, Loss: 0.31622588634490967\n",
            "Epoch 3, Batch 433 / 1350, Loss: 0.35230064392089844\n",
            "Epoch 3, Batch 434 / 1350, Loss: 0.4973488450050354\n",
            "Epoch 3, Batch 435 / 1350, Loss: 0.022701118141412735\n",
            "Epoch 3, Batch 436 / 1350, Loss: 0.15987765789031982\n",
            "Epoch 3, Batch 437 / 1350, Loss: 0.37742286920547485\n",
            "Epoch 3, Batch 438 / 1350, Loss: 0.5075523257255554\n",
            "Epoch 3, Batch 439 / 1350, Loss: 0.26461726427078247\n",
            "Epoch 3, Batch 440 / 1350, Loss: 0.5198678970336914\n",
            "Epoch 3, Batch 441 / 1350, Loss: 0.1680895984172821\n",
            "Epoch 3, Batch 442 / 1350, Loss: 0.4944012761116028\n",
            "Epoch 3, Batch 443 / 1350, Loss: 0.03330607712268829\n",
            "Epoch 3, Batch 444 / 1350, Loss: 0.07575508952140808\n",
            "Epoch 3, Batch 445 / 1350, Loss: 0.049591951072216034\n",
            "Epoch 3, Batch 446 / 1350, Loss: 0.18897609412670135\n",
            "Epoch 3, Batch 447 / 1350, Loss: 0.6054835915565491\n",
            "Epoch 3, Batch 448 / 1350, Loss: 0.2918725609779358\n",
            "Epoch 3, Batch 449 / 1350, Loss: 0.12964236736297607\n",
            "Epoch 3, Batch 450 / 1350, Loss: 0.07498788833618164\n",
            "Epoch 3, Batch 451 / 1350, Loss: 1.0057469606399536\n",
            "Epoch 3, Batch 452 / 1350, Loss: 0.07920923829078674\n",
            "Epoch 3, Batch 453 / 1350, Loss: 0.06087256222963333\n",
            "Epoch 3, Batch 454 / 1350, Loss: 0.15148963034152985\n",
            "Epoch 3, Batch 455 / 1350, Loss: 0.30562540888786316\n",
            "Epoch 3, Batch 456 / 1350, Loss: 0.23897726833820343\n",
            "Epoch 3, Batch 457 / 1350, Loss: 0.05947449430823326\n",
            "Epoch 3, Batch 458 / 1350, Loss: 0.014649895019829273\n",
            "Epoch 3, Batch 459 / 1350, Loss: 0.08640743046998978\n",
            "Epoch 3, Batch 460 / 1350, Loss: 0.1874619722366333\n",
            "Epoch 3, Batch 461 / 1350, Loss: 0.024202728644013405\n",
            "Epoch 3, Batch 462 / 1350, Loss: 0.015437552705407143\n",
            "Epoch 3, Batch 463 / 1350, Loss: 0.11827004700899124\n",
            "Epoch 3, Batch 464 / 1350, Loss: 0.30042728781700134\n",
            "Epoch 3, Batch 465 / 1350, Loss: 0.18794523179531097\n",
            "Epoch 3, Batch 466 / 1350, Loss: 0.03277609497308731\n",
            "Epoch 3, Batch 467 / 1350, Loss: 1.4548265933990479\n",
            "Epoch 3, Batch 468 / 1350, Loss: 0.11141611635684967\n",
            "Epoch 3, Batch 469 / 1350, Loss: 0.3925567865371704\n",
            "Epoch 3, Batch 470 / 1350, Loss: 0.3233575224876404\n",
            "Epoch 3, Batch 471 / 1350, Loss: 0.13989557325839996\n",
            "Epoch 3, Batch 472 / 1350, Loss: 0.5290249586105347\n",
            "Epoch 3, Batch 473 / 1350, Loss: 0.3501562476158142\n",
            "Epoch 3, Batch 474 / 1350, Loss: 1.1208033561706543\n",
            "Epoch 3, Batch 475 / 1350, Loss: 0.02660912089049816\n",
            "Epoch 3, Batch 476 / 1350, Loss: 0.14948318898677826\n",
            "Epoch 3, Batch 477 / 1350, Loss: 0.13700926303863525\n",
            "Epoch 3, Batch 478 / 1350, Loss: 0.07667775452136993\n",
            "Epoch 3, Batch 479 / 1350, Loss: 0.1312149614095688\n",
            "Epoch 3, Batch 480 / 1350, Loss: 0.45519688725471497\n",
            "Epoch 3, Batch 481 / 1350, Loss: 0.161276176571846\n",
            "Epoch 3, Batch 482 / 1350, Loss: 0.056242164224386215\n",
            "Epoch 3, Batch 483 / 1350, Loss: 0.04086779057979584\n",
            "Epoch 3, Batch 484 / 1350, Loss: 0.23099087178707123\n",
            "Epoch 3, Batch 485 / 1350, Loss: 0.8311796188354492\n",
            "Epoch 3, Batch 486 / 1350, Loss: 0.03162620961666107\n",
            "Epoch 3, Batch 487 / 1350, Loss: 0.09275265038013458\n",
            "Epoch 3, Batch 488 / 1350, Loss: 0.30720055103302\n",
            "Epoch 3, Batch 489 / 1350, Loss: 0.599682629108429\n",
            "Epoch 3, Batch 490 / 1350, Loss: 0.04382256418466568\n",
            "Epoch 3, Batch 491 / 1350, Loss: 0.1621384471654892\n",
            "Epoch 3, Batch 492 / 1350, Loss: 0.36874011158943176\n",
            "Epoch 3, Batch 493 / 1350, Loss: 0.7912088632583618\n",
            "Epoch 3, Batch 494 / 1350, Loss: 0.031077267602086067\n",
            "Epoch 3, Batch 495 / 1350, Loss: 0.16978849470615387\n",
            "Epoch 3, Batch 496 / 1350, Loss: 0.016446681693196297\n",
            "Epoch 3, Batch 497 / 1350, Loss: 0.5756654143333435\n",
            "Epoch 3, Batch 498 / 1350, Loss: 0.3003794848918915\n",
            "Epoch 3, Batch 499 / 1350, Loss: 0.051661357283592224\n",
            "Epoch 3, Batch 500 / 1350, Loss: 0.038718901574611664\n",
            "Epoch 3, Batch 501 / 1350, Loss: 0.3499099612236023\n",
            "Epoch 3, Batch 502 / 1350, Loss: 0.16857510805130005\n",
            "Epoch 3, Batch 503 / 1350, Loss: 0.41427141427993774\n",
            "Epoch 3, Batch 504 / 1350, Loss: 0.1432141214609146\n",
            "Epoch 3, Batch 505 / 1350, Loss: 0.35886523127555847\n",
            "Epoch 3, Batch 506 / 1350, Loss: 0.5428398251533508\n",
            "Epoch 3, Batch 507 / 1350, Loss: 0.37508729100227356\n",
            "Epoch 3, Batch 508 / 1350, Loss: 0.4836546778678894\n",
            "Epoch 3, Batch 509 / 1350, Loss: 1.133902907371521\n",
            "Epoch 3, Batch 510 / 1350, Loss: 0.3059811592102051\n",
            "Epoch 3, Batch 511 / 1350, Loss: 0.2636021077632904\n",
            "Epoch 3, Batch 512 / 1350, Loss: 0.1021578311920166\n",
            "Epoch 3, Batch 513 / 1350, Loss: 0.1814153790473938\n",
            "Epoch 3, Batch 514 / 1350, Loss: 0.6361199617385864\n",
            "Epoch 3, Batch 515 / 1350, Loss: 0.21912795305252075\n",
            "Epoch 3, Batch 516 / 1350, Loss: 0.35011133551597595\n",
            "Epoch 3, Batch 517 / 1350, Loss: 0.18350045382976532\n",
            "Epoch 3, Batch 518 / 1350, Loss: 0.4830547869205475\n",
            "Epoch 3, Batch 519 / 1350, Loss: 0.16158130764961243\n",
            "Epoch 3, Batch 520 / 1350, Loss: 0.5413559675216675\n",
            "Epoch 3, Batch 521 / 1350, Loss: 0.519921064376831\n",
            "Epoch 3, Batch 522 / 1350, Loss: 0.7150499224662781\n",
            "Epoch 3, Batch 523 / 1350, Loss: 0.23044130206108093\n",
            "Epoch 3, Batch 524 / 1350, Loss: 0.0238957516849041\n",
            "Epoch 3, Batch 525 / 1350, Loss: 0.12605983018875122\n",
            "Epoch 3, Batch 526 / 1350, Loss: 0.17620165646076202\n",
            "Epoch 3, Batch 527 / 1350, Loss: 0.3970629572868347\n",
            "Epoch 3, Batch 528 / 1350, Loss: 0.12415154278278351\n",
            "Epoch 3, Batch 529 / 1350, Loss: 0.18866121768951416\n",
            "Epoch 3, Batch 530 / 1350, Loss: 0.14630380272865295\n",
            "Epoch 3, Batch 531 / 1350, Loss: 0.08804245293140411\n",
            "Epoch 3, Batch 532 / 1350, Loss: 0.3688581883907318\n",
            "Epoch 3, Batch 533 / 1350, Loss: 0.0833272933959961\n",
            "Epoch 3, Batch 534 / 1350, Loss: 0.08183722198009491\n",
            "Epoch 3, Batch 535 / 1350, Loss: 0.061548616737127304\n",
            "Epoch 3, Batch 536 / 1350, Loss: 0.5607842803001404\n",
            "Epoch 3, Batch 537 / 1350, Loss: 0.3446687161922455\n",
            "Epoch 3, Batch 538 / 1350, Loss: 0.25214502215385437\n",
            "Epoch 3, Batch 539 / 1350, Loss: 0.2295486330986023\n",
            "Epoch 3, Batch 540 / 1350, Loss: 0.21667438745498657\n",
            "Epoch 3, Batch 541 / 1350, Loss: 0.06513381004333496\n",
            "Epoch 3, Batch 542 / 1350, Loss: 1.045271873474121\n",
            "Epoch 3, Batch 543 / 1350, Loss: 0.32800471782684326\n",
            "Epoch 3, Batch 544 / 1350, Loss: 0.7184163331985474\n",
            "Epoch 3, Batch 545 / 1350, Loss: 0.23970171809196472\n",
            "Epoch 3, Batch 546 / 1350, Loss: 0.12748175859451294\n",
            "Epoch 3, Batch 547 / 1350, Loss: 0.18464860320091248\n",
            "Epoch 3, Batch 548 / 1350, Loss: 0.08749237656593323\n",
            "Epoch 3, Batch 549 / 1350, Loss: 0.1045563817024231\n",
            "Epoch 3, Batch 550 / 1350, Loss: 0.8549444675445557\n",
            "Epoch 3, Batch 551 / 1350, Loss: 0.5362473130226135\n",
            "Epoch 3, Batch 552 / 1350, Loss: 0.0746159628033638\n",
            "Epoch 3, Batch 553 / 1350, Loss: 0.22873049974441528\n",
            "Epoch 3, Batch 554 / 1350, Loss: 0.2731132507324219\n",
            "Epoch 3, Batch 555 / 1350, Loss: 0.7812246084213257\n",
            "Epoch 3, Batch 556 / 1350, Loss: 0.18018105626106262\n",
            "Epoch 3, Batch 557 / 1350, Loss: 0.3433297276496887\n",
            "Epoch 3, Batch 558 / 1350, Loss: 0.3524647355079651\n",
            "Epoch 3, Batch 559 / 1350, Loss: 0.20704129338264465\n",
            "Epoch 3, Batch 560 / 1350, Loss: 0.04140471667051315\n",
            "Epoch 3, Batch 561 / 1350, Loss: 0.14767497777938843\n",
            "Epoch 3, Batch 562 / 1350, Loss: 0.47110533714294434\n",
            "Epoch 3, Batch 563 / 1350, Loss: 0.16145619750022888\n",
            "Epoch 3, Batch 564 / 1350, Loss: 0.39642438292503357\n",
            "Epoch 3, Batch 565 / 1350, Loss: 0.04048477113246918\n",
            "Epoch 3, Batch 566 / 1350, Loss: 0.18927866220474243\n",
            "Epoch 3, Batch 567 / 1350, Loss: 0.04515695571899414\n",
            "Epoch 3, Batch 568 / 1350, Loss: 0.866580605506897\n",
            "Epoch 3, Batch 569 / 1350, Loss: 0.36055809259414673\n",
            "Epoch 3, Batch 570 / 1350, Loss: 0.1861744374036789\n",
            "Epoch 3, Batch 571 / 1350, Loss: 0.4139462113380432\n",
            "Epoch 3, Batch 572 / 1350, Loss: 0.06054487079381943\n",
            "Epoch 3, Batch 573 / 1350, Loss: 0.14535439014434814\n",
            "Epoch 3, Batch 574 / 1350, Loss: 0.30417245626449585\n",
            "Epoch 3, Batch 575 / 1350, Loss: 0.26660364866256714\n",
            "Epoch 3, Batch 576 / 1350, Loss: 0.15720674395561218\n",
            "Epoch 3, Batch 577 / 1350, Loss: 0.061929598450660706\n",
            "Epoch 3, Batch 578 / 1350, Loss: 0.9959796667098999\n",
            "Epoch 3, Batch 579 / 1350, Loss: 0.18708957731723785\n",
            "Epoch 3, Batch 580 / 1350, Loss: 0.529424786567688\n",
            "Epoch 3, Batch 581 / 1350, Loss: 0.38031795620918274\n",
            "Epoch 3, Batch 582 / 1350, Loss: 0.09177643060684204\n",
            "Epoch 3, Batch 583 / 1350, Loss: 0.059646353125572205\n",
            "Epoch 3, Batch 584 / 1350, Loss: 1.0731236934661865\n",
            "Epoch 3, Batch 585 / 1350, Loss: 0.36137136816978455\n",
            "Epoch 3, Batch 586 / 1350, Loss: 0.7775245904922485\n",
            "Epoch 3, Batch 587 / 1350, Loss: 0.41612231731414795\n",
            "Epoch 3, Batch 588 / 1350, Loss: 0.12073907256126404\n",
            "Epoch 3, Batch 589 / 1350, Loss: 0.612317681312561\n",
            "Epoch 3, Batch 590 / 1350, Loss: 1.5698134899139404\n",
            "Epoch 3, Batch 591 / 1350, Loss: 0.12755441665649414\n",
            "Epoch 3, Batch 592 / 1350, Loss: 0.17600271105766296\n",
            "Epoch 3, Batch 593 / 1350, Loss: 0.10732046514749527\n",
            "Epoch 3, Batch 594 / 1350, Loss: 0.693975567817688\n",
            "Epoch 3, Batch 595 / 1350, Loss: 0.9443730115890503\n",
            "Epoch 3, Batch 596 / 1350, Loss: 0.7275469303131104\n",
            "Epoch 3, Batch 597 / 1350, Loss: 0.17917990684509277\n",
            "Epoch 3, Batch 598 / 1350, Loss: 0.18204033374786377\n",
            "Epoch 3, Batch 599 / 1350, Loss: 0.25055551528930664\n",
            "Epoch 3, Batch 600 / 1350, Loss: 0.2538878917694092\n",
            "Epoch 3, Batch 601 / 1350, Loss: 0.28967392444610596\n",
            "Epoch 3, Batch 602 / 1350, Loss: 0.4582008719444275\n",
            "Epoch 3, Batch 603 / 1350, Loss: 0.2101123332977295\n",
            "Epoch 3, Batch 604 / 1350, Loss: 0.10296276211738586\n",
            "Epoch 3, Batch 605 / 1350, Loss: 0.20898088812828064\n",
            "Epoch 3, Batch 606 / 1350, Loss: 0.3229306936264038\n",
            "Epoch 3, Batch 607 / 1350, Loss: 0.26099658012390137\n",
            "Epoch 3, Batch 608 / 1350, Loss: 0.12156391143798828\n",
            "Epoch 3, Batch 609 / 1350, Loss: 0.052840813994407654\n",
            "Epoch 3, Batch 610 / 1350, Loss: 0.1058637797832489\n",
            "Epoch 3, Batch 611 / 1350, Loss: 0.7852387428283691\n",
            "Epoch 3, Batch 612 / 1350, Loss: 0.034565120935440063\n",
            "Epoch 3, Batch 613 / 1350, Loss: 0.21894840896129608\n",
            "Epoch 3, Batch 614 / 1350, Loss: 0.260877788066864\n",
            "Epoch 3, Batch 615 / 1350, Loss: 0.20482952892780304\n",
            "Epoch 3, Batch 616 / 1350, Loss: 0.9249989986419678\n",
            "Epoch 3, Batch 617 / 1350, Loss: 0.04627752676606178\n",
            "Epoch 3, Batch 618 / 1350, Loss: 0.10314604640007019\n",
            "Epoch 3, Batch 619 / 1350, Loss: 0.2936420440673828\n",
            "Epoch 3, Batch 620 / 1350, Loss: 0.32256051898002625\n",
            "Epoch 3, Batch 621 / 1350, Loss: 0.1594265252351761\n",
            "Epoch 3, Batch 622 / 1350, Loss: 0.1428503692150116\n",
            "Epoch 3, Batch 623 / 1350, Loss: 0.20406609773635864\n",
            "Epoch 3, Batch 624 / 1350, Loss: 0.8312107920646667\n",
            "Epoch 3, Batch 625 / 1350, Loss: 0.19372305274009705\n",
            "Epoch 3, Batch 626 / 1350, Loss: 0.2941988408565521\n",
            "Epoch 3, Batch 627 / 1350, Loss: 0.9511539936065674\n",
            "Epoch 3, Batch 628 / 1350, Loss: 0.5192060470581055\n",
            "Epoch 3, Batch 629 / 1350, Loss: 0.04786331206560135\n",
            "Epoch 3, Batch 630 / 1350, Loss: 0.0400177501142025\n",
            "Epoch 3, Batch 631 / 1350, Loss: 1.1397892236709595\n",
            "Epoch 3, Batch 632 / 1350, Loss: 0.08663491904735565\n",
            "Epoch 3, Batch 633 / 1350, Loss: 0.04914743825793266\n",
            "Epoch 3, Batch 634 / 1350, Loss: 0.33306464552879333\n",
            "Epoch 3, Batch 635 / 1350, Loss: 0.39504432678222656\n",
            "Epoch 3, Batch 636 / 1350, Loss: 0.21221372485160828\n",
            "Epoch 3, Batch 637 / 1350, Loss: 0.45909780263900757\n",
            "Epoch 3, Batch 638 / 1350, Loss: 0.3882874846458435\n",
            "Epoch 3, Batch 639 / 1350, Loss: 0.6312772035598755\n",
            "Epoch 3, Batch 640 / 1350, Loss: 0.1305094063282013\n",
            "Epoch 3, Batch 641 / 1350, Loss: 0.14740589261054993\n",
            "Epoch 3, Batch 642 / 1350, Loss: 0.10690583288669586\n",
            "Epoch 3, Batch 643 / 1350, Loss: 0.11817890405654907\n",
            "Epoch 3, Batch 644 / 1350, Loss: 0.5688984394073486\n",
            "Epoch 3, Batch 645 / 1350, Loss: 0.4573478698730469\n",
            "Epoch 3, Batch 646 / 1350, Loss: 0.17976918816566467\n",
            "Epoch 3, Batch 647 / 1350, Loss: 0.06727185845375061\n",
            "Epoch 3, Batch 648 / 1350, Loss: 0.17913781106472015\n",
            "Epoch 3, Batch 649 / 1350, Loss: 0.40470513701438904\n",
            "Epoch 3, Batch 650 / 1350, Loss: 0.08655659854412079\n",
            "Epoch 3, Batch 651 / 1350, Loss: 0.0641893669962883\n",
            "Epoch 3, Batch 652 / 1350, Loss: 0.030113186687231064\n",
            "Epoch 3, Batch 653 / 1350, Loss: 0.21919488906860352\n",
            "Epoch 3, Batch 654 / 1350, Loss: 0.39431172609329224\n",
            "Epoch 3, Batch 655 / 1350, Loss: 0.05735178664326668\n",
            "Epoch 3, Batch 656 / 1350, Loss: 0.1294180154800415\n",
            "Epoch 3, Batch 657 / 1350, Loss: 0.06063363701105118\n",
            "Epoch 3, Batch 658 / 1350, Loss: 0.10275377333164215\n",
            "Epoch 3, Batch 659 / 1350, Loss: 0.06546372920274734\n",
            "Epoch 3, Batch 660 / 1350, Loss: 0.0626852810382843\n",
            "Epoch 3, Batch 661 / 1350, Loss: 0.02092590369284153\n",
            "Epoch 3, Batch 662 / 1350, Loss: 0.026216495782136917\n",
            "Epoch 3, Batch 663 / 1350, Loss: 0.17609412968158722\n",
            "Epoch 3, Batch 664 / 1350, Loss: 0.3290083408355713\n",
            "Epoch 3, Batch 665 / 1350, Loss: 0.09227168560028076\n",
            "Epoch 3, Batch 666 / 1350, Loss: 0.6073353886604309\n",
            "Epoch 3, Batch 667 / 1350, Loss: 0.4892158508300781\n",
            "Epoch 3, Batch 668 / 1350, Loss: 0.02855994924902916\n",
            "Epoch 3, Batch 669 / 1350, Loss: 0.015497068874537945\n",
            "Epoch 3, Batch 670 / 1350, Loss: 0.1551724076271057\n",
            "Epoch 3, Batch 671 / 1350, Loss: 0.5047564506530762\n",
            "Epoch 3, Batch 672 / 1350, Loss: 0.0810311809182167\n",
            "Epoch 3, Batch 673 / 1350, Loss: 0.18109336495399475\n",
            "Epoch 3, Batch 674 / 1350, Loss: 0.4115869700908661\n",
            "Epoch 3, Batch 675 / 1350, Loss: 0.01971117965877056\n",
            "Epoch 3, Batch 676 / 1350, Loss: 0.05460077524185181\n",
            "Epoch 3, Batch 677 / 1350, Loss: 0.026188407093286514\n",
            "Epoch 3, Batch 678 / 1350, Loss: 0.7349533438682556\n",
            "Epoch 3, Batch 679 / 1350, Loss: 0.16886097192764282\n",
            "Epoch 3, Batch 680 / 1350, Loss: 0.10216712206602097\n",
            "Epoch 3, Batch 681 / 1350, Loss: 0.30313414335250854\n",
            "Epoch 3, Batch 682 / 1350, Loss: 0.35444024205207825\n",
            "Epoch 3, Batch 683 / 1350, Loss: 0.43306130170822144\n",
            "Epoch 3, Batch 684 / 1350, Loss: 0.0919257327914238\n",
            "Epoch 3, Batch 685 / 1350, Loss: 0.6276150941848755\n",
            "Epoch 3, Batch 686 / 1350, Loss: 1.04307222366333\n",
            "Epoch 3, Batch 687 / 1350, Loss: 1.136717677116394\n",
            "Epoch 3, Batch 688 / 1350, Loss: 0.0298662930727005\n",
            "Epoch 3, Batch 689 / 1350, Loss: 1.2765709161758423\n",
            "Epoch 3, Batch 690 / 1350, Loss: 0.0935213565826416\n",
            "Epoch 3, Batch 691 / 1350, Loss: 0.2585303485393524\n",
            "Epoch 3, Batch 692 / 1350, Loss: 0.2215718924999237\n",
            "Epoch 3, Batch 693 / 1350, Loss: 0.7651527523994446\n",
            "Epoch 3, Batch 694 / 1350, Loss: 0.2708013653755188\n",
            "Epoch 3, Batch 695 / 1350, Loss: 0.9168196320533752\n",
            "Epoch 3, Batch 696 / 1350, Loss: 0.062409985810518265\n",
            "Epoch 3, Batch 697 / 1350, Loss: 0.2677052319049835\n",
            "Epoch 3, Batch 698 / 1350, Loss: 0.06131485849618912\n",
            "Epoch 3, Batch 699 / 1350, Loss: 0.3272199034690857\n",
            "Epoch 3, Batch 700 / 1350, Loss: 0.589347243309021\n",
            "Epoch 3, Batch 701 / 1350, Loss: 0.29580211639404297\n",
            "Epoch 3, Batch 702 / 1350, Loss: 0.1074151024222374\n",
            "Epoch 3, Batch 703 / 1350, Loss: 0.1475677639245987\n",
            "Epoch 3, Batch 704 / 1350, Loss: 0.1318066120147705\n",
            "Epoch 3, Batch 705 / 1350, Loss: 0.4188435673713684\n",
            "Epoch 3, Batch 706 / 1350, Loss: 0.12141530215740204\n",
            "Epoch 3, Batch 707 / 1350, Loss: 0.18359577655792236\n",
            "Epoch 3, Batch 708 / 1350, Loss: 0.0833367183804512\n",
            "Epoch 3, Batch 709 / 1350, Loss: 0.6721783876419067\n",
            "Epoch 3, Batch 710 / 1350, Loss: 0.3506355881690979\n",
            "Epoch 3, Batch 711 / 1350, Loss: 0.557915985584259\n",
            "Epoch 3, Batch 712 / 1350, Loss: 0.07051417976617813\n",
            "Epoch 3, Batch 713 / 1350, Loss: 0.13282093405723572\n",
            "Epoch 3, Batch 714 / 1350, Loss: 0.08816635608673096\n",
            "Epoch 3, Batch 715 / 1350, Loss: 0.056173793971538544\n",
            "Epoch 3, Batch 716 / 1350, Loss: 0.7428376078605652\n",
            "Epoch 3, Batch 717 / 1350, Loss: 0.16688263416290283\n",
            "Epoch 3, Batch 718 / 1350, Loss: 0.07990621775388718\n",
            "Epoch 3, Batch 719 / 1350, Loss: 0.9112470746040344\n",
            "Epoch 3, Batch 720 / 1350, Loss: 0.27265045046806335\n",
            "Epoch 3, Batch 721 / 1350, Loss: 0.21834689378738403\n",
            "Epoch 3, Batch 722 / 1350, Loss: 0.26899275183677673\n",
            "Epoch 3, Batch 723 / 1350, Loss: 0.032193947583436966\n",
            "Epoch 3, Batch 724 / 1350, Loss: 0.15054164826869965\n",
            "Epoch 3, Batch 725 / 1350, Loss: 0.19217786192893982\n",
            "Epoch 3, Batch 726 / 1350, Loss: 0.8788771033287048\n",
            "Epoch 3, Batch 727 / 1350, Loss: 0.26318463683128357\n",
            "Epoch 3, Batch 728 / 1350, Loss: 0.273905873298645\n",
            "Epoch 3, Batch 729 / 1350, Loss: 0.02816120535135269\n",
            "Epoch 3, Batch 730 / 1350, Loss: 0.022575218230485916\n",
            "Epoch 3, Batch 731 / 1350, Loss: 0.3663724362850189\n",
            "Epoch 3, Batch 732 / 1350, Loss: 0.8373084664344788\n",
            "Epoch 3, Batch 733 / 1350, Loss: 0.8518342971801758\n",
            "Epoch 3, Batch 734 / 1350, Loss: 0.0562000535428524\n",
            "Epoch 3, Batch 735 / 1350, Loss: 0.13039202988147736\n",
            "Epoch 3, Batch 736 / 1350, Loss: 0.04139116778969765\n",
            "Epoch 3, Batch 737 / 1350, Loss: 0.06774083524942398\n",
            "Epoch 3, Batch 738 / 1350, Loss: 0.36539286375045776\n",
            "Epoch 3, Batch 739 / 1350, Loss: 0.2862856388092041\n",
            "Epoch 3, Batch 740 / 1350, Loss: 0.26085132360458374\n",
            "Epoch 3, Batch 741 / 1350, Loss: 0.05814697593450546\n",
            "Epoch 3, Batch 742 / 1350, Loss: 0.06859844923019409\n",
            "Epoch 3, Batch 743 / 1350, Loss: 0.4105989933013916\n",
            "Epoch 3, Batch 744 / 1350, Loss: 0.1330881416797638\n",
            "Epoch 3, Batch 745 / 1350, Loss: 0.48533013463020325\n",
            "Epoch 3, Batch 746 / 1350, Loss: 0.2025085985660553\n",
            "Epoch 3, Batch 747 / 1350, Loss: 0.5571264624595642\n",
            "Epoch 3, Batch 748 / 1350, Loss: 0.07084154337644577\n",
            "Epoch 3, Batch 749 / 1350, Loss: 0.38962575793266296\n",
            "Epoch 3, Batch 750 / 1350, Loss: 0.5642856359481812\n",
            "Epoch 3, Batch 751 / 1350, Loss: 0.352650910615921\n",
            "Epoch 3, Batch 752 / 1350, Loss: 0.47294533252716064\n",
            "Epoch 3, Batch 753 / 1350, Loss: 0.4452744126319885\n",
            "Epoch 3, Batch 754 / 1350, Loss: 0.17525075376033783\n",
            "Epoch 3, Batch 755 / 1350, Loss: 0.046449314802885056\n",
            "Epoch 3, Batch 756 / 1350, Loss: 0.03448483347892761\n",
            "Epoch 3, Batch 757 / 1350, Loss: 0.5073610544204712\n",
            "Epoch 3, Batch 758 / 1350, Loss: 0.04130987077951431\n",
            "Epoch 3, Batch 759 / 1350, Loss: 0.44407153129577637\n",
            "Epoch 3, Batch 760 / 1350, Loss: 0.1227068305015564\n",
            "Epoch 3, Batch 761 / 1350, Loss: 0.38439279794692993\n",
            "Epoch 3, Batch 762 / 1350, Loss: 0.031186046078801155\n",
            "Epoch 3, Batch 763 / 1350, Loss: 0.760749101638794\n",
            "Epoch 3, Batch 764 / 1350, Loss: 0.5511560440063477\n",
            "Epoch 3, Batch 765 / 1350, Loss: 0.860402524471283\n",
            "Epoch 3, Batch 766 / 1350, Loss: 0.26428884267807007\n",
            "Epoch 3, Batch 767 / 1350, Loss: 0.06435031443834305\n",
            "Epoch 3, Batch 768 / 1350, Loss: 0.7426829934120178\n",
            "Epoch 3, Batch 769 / 1350, Loss: 0.7064294815063477\n",
            "Epoch 3, Batch 770 / 1350, Loss: 0.12926481664180756\n",
            "Epoch 3, Batch 771 / 1350, Loss: 0.7186567187309265\n",
            "Epoch 3, Batch 772 / 1350, Loss: 0.08337117731571198\n",
            "Epoch 3, Batch 773 / 1350, Loss: 1.0714704990386963\n",
            "Epoch 3, Batch 774 / 1350, Loss: 0.29097652435302734\n",
            "Epoch 3, Batch 775 / 1350, Loss: 0.5394830107688904\n",
            "Epoch 3, Batch 776 / 1350, Loss: 0.5796877145767212\n",
            "Epoch 3, Batch 777 / 1350, Loss: 0.06641151010990143\n",
            "Epoch 3, Batch 778 / 1350, Loss: 0.07656461000442505\n",
            "Epoch 3, Batch 779 / 1350, Loss: 0.9174237251281738\n",
            "Epoch 3, Batch 780 / 1350, Loss: 0.1380007266998291\n",
            "Epoch 3, Batch 781 / 1350, Loss: 0.13256977498531342\n",
            "Epoch 3, Batch 782 / 1350, Loss: 0.37130481004714966\n",
            "Epoch 3, Batch 783 / 1350, Loss: 0.4221017360687256\n",
            "Epoch 3, Batch 784 / 1350, Loss: 0.44559717178344727\n",
            "Epoch 3, Batch 785 / 1350, Loss: 0.13102924823760986\n",
            "Epoch 3, Batch 786 / 1350, Loss: 0.1059722825884819\n",
            "Epoch 3, Batch 787 / 1350, Loss: 0.2959167957305908\n",
            "Epoch 3, Batch 788 / 1350, Loss: 0.3041016459465027\n",
            "Epoch 3, Batch 789 / 1350, Loss: 0.5354663729667664\n",
            "Epoch 3, Batch 790 / 1350, Loss: 0.3571794629096985\n",
            "Epoch 3, Batch 791 / 1350, Loss: 0.4722521901130676\n",
            "Epoch 3, Batch 792 / 1350, Loss: 0.04891585558652878\n",
            "Epoch 3, Batch 793 / 1350, Loss: 1.213791847229004\n",
            "Epoch 3, Batch 794 / 1350, Loss: 0.14336156845092773\n",
            "Epoch 3, Batch 795 / 1350, Loss: 0.7571751475334167\n",
            "Epoch 3, Batch 796 / 1350, Loss: 0.12566381692886353\n",
            "Epoch 3, Batch 797 / 1350, Loss: 0.29494595527648926\n",
            "Epoch 3, Batch 798 / 1350, Loss: 0.17174717783927917\n",
            "Epoch 3, Batch 799 / 1350, Loss: 0.1549764722585678\n",
            "Epoch 3, Batch 800 / 1350, Loss: 0.12143932282924652\n",
            "Epoch 3, Batch 801 / 1350, Loss: 0.6734878420829773\n",
            "Epoch 3, Batch 802 / 1350, Loss: 0.07701466977596283\n",
            "Epoch 3, Batch 803 / 1350, Loss: 0.13487884402275085\n",
            "Epoch 3, Batch 804 / 1350, Loss: 0.24576255679130554\n",
            "Epoch 3, Batch 805 / 1350, Loss: 0.08048820495605469\n",
            "Epoch 3, Batch 806 / 1350, Loss: 0.040367916226387024\n",
            "Epoch 3, Batch 807 / 1350, Loss: 0.8925343155860901\n",
            "Epoch 3, Batch 808 / 1350, Loss: 0.12020829319953918\n",
            "Epoch 3, Batch 809 / 1350, Loss: 0.810444712638855\n",
            "Epoch 3, Batch 810 / 1350, Loss: 0.2296178638935089\n",
            "Epoch 3, Batch 811 / 1350, Loss: 0.043707266449928284\n",
            "Epoch 3, Batch 812 / 1350, Loss: 0.23911601305007935\n",
            "Epoch 3, Batch 813 / 1350, Loss: 0.2258158177137375\n",
            "Epoch 3, Batch 814 / 1350, Loss: 0.08760935068130493\n",
            "Epoch 3, Batch 815 / 1350, Loss: 0.33451908826828003\n",
            "Epoch 3, Batch 816 / 1350, Loss: 0.43655431270599365\n",
            "Epoch 3, Batch 817 / 1350, Loss: 0.021171584725379944\n",
            "Epoch 3, Batch 818 / 1350, Loss: 0.19667935371398926\n",
            "Epoch 3, Batch 819 / 1350, Loss: 0.15679170191287994\n",
            "Epoch 3, Batch 820 / 1350, Loss: 0.10397052764892578\n",
            "Epoch 3, Batch 821 / 1350, Loss: 0.575537383556366\n",
            "Epoch 3, Batch 822 / 1350, Loss: 0.8192456960678101\n",
            "Epoch 3, Batch 823 / 1350, Loss: 0.10630875080823898\n",
            "Epoch 3, Batch 824 / 1350, Loss: 0.11286312341690063\n",
            "Epoch 3, Batch 825 / 1350, Loss: 2.15720272064209\n",
            "Epoch 3, Batch 826 / 1350, Loss: 0.057092390954494476\n",
            "Epoch 3, Batch 827 / 1350, Loss: 0.0715160146355629\n",
            "Epoch 3, Batch 828 / 1350, Loss: 0.05236468091607094\n",
            "Epoch 3, Batch 829 / 1350, Loss: 0.5982706546783447\n",
            "Epoch 3, Batch 830 / 1350, Loss: 0.18486422300338745\n",
            "Epoch 3, Batch 831 / 1350, Loss: 0.04434067755937576\n",
            "Epoch 3, Batch 832 / 1350, Loss: 0.025304771959781647\n",
            "Epoch 3, Batch 833 / 1350, Loss: 0.8296830654144287\n",
            "Epoch 3, Batch 834 / 1350, Loss: 0.13247144222259521\n",
            "Epoch 3, Batch 835 / 1350, Loss: 0.515654444694519\n",
            "Epoch 3, Batch 836 / 1350, Loss: 0.06055837497115135\n",
            "Epoch 3, Batch 837 / 1350, Loss: 0.0382925420999527\n",
            "Epoch 3, Batch 838 / 1350, Loss: 0.2845836877822876\n",
            "Epoch 3, Batch 839 / 1350, Loss: 0.5643303990364075\n",
            "Epoch 3, Batch 840 / 1350, Loss: 0.03546842187643051\n",
            "Epoch 3, Batch 841 / 1350, Loss: 0.0611882284283638\n",
            "Epoch 3, Batch 842 / 1350, Loss: 0.16222000122070312\n",
            "Epoch 3, Batch 843 / 1350, Loss: 0.08220111578702927\n",
            "Epoch 3, Batch 844 / 1350, Loss: 0.29163241386413574\n",
            "Epoch 3, Batch 845 / 1350, Loss: 0.5118894577026367\n",
            "Epoch 3, Batch 846 / 1350, Loss: 0.9150005578994751\n",
            "Epoch 3, Batch 847 / 1350, Loss: 1.0253645181655884\n",
            "Epoch 3, Batch 848 / 1350, Loss: 0.15420480072498322\n",
            "Epoch 3, Batch 849 / 1350, Loss: 0.1428641974925995\n",
            "Epoch 3, Batch 850 / 1350, Loss: 0.033180419355630875\n",
            "Epoch 3, Batch 851 / 1350, Loss: 0.07310709357261658\n",
            "Epoch 3, Batch 852 / 1350, Loss: 0.15338122844696045\n",
            "Epoch 3, Batch 853 / 1350, Loss: 0.6255531311035156\n",
            "Epoch 3, Batch 854 / 1350, Loss: 0.09121833741664886\n",
            "Epoch 3, Batch 855 / 1350, Loss: 0.062136512249708176\n",
            "Epoch 3, Batch 856 / 1350, Loss: 0.4946358799934387\n",
            "Epoch 3, Batch 857 / 1350, Loss: 0.22061337530612946\n",
            "Epoch 3, Batch 858 / 1350, Loss: 0.07589100301265717\n",
            "Epoch 3, Batch 859 / 1350, Loss: 0.660764217376709\n",
            "Epoch 3, Batch 860 / 1350, Loss: 0.0705316811800003\n",
            "Epoch 3, Batch 861 / 1350, Loss: 0.035884663462638855\n",
            "Epoch 3, Batch 862 / 1350, Loss: 0.33780401945114136\n",
            "Epoch 3, Batch 863 / 1350, Loss: 0.20484407246112823\n",
            "Epoch 3, Batch 864 / 1350, Loss: 0.7938613891601562\n",
            "Epoch 3, Batch 865 / 1350, Loss: 0.5129950046539307\n",
            "Epoch 3, Batch 866 / 1350, Loss: 0.0650215744972229\n",
            "Epoch 3, Batch 867 / 1350, Loss: 0.3366270661354065\n",
            "Epoch 3, Batch 868 / 1350, Loss: 0.7070111632347107\n",
            "Epoch 3, Batch 869 / 1350, Loss: 0.045397959649562836\n",
            "Epoch 3, Batch 870 / 1350, Loss: 0.7648543119430542\n",
            "Epoch 3, Batch 871 / 1350, Loss: 0.1096629723906517\n",
            "Epoch 3, Batch 872 / 1350, Loss: 0.37375569343566895\n",
            "Epoch 3, Batch 873 / 1350, Loss: 0.07412771880626678\n",
            "Epoch 3, Batch 874 / 1350, Loss: 0.7863340377807617\n",
            "Epoch 3, Batch 875 / 1350, Loss: 0.4490392804145813\n",
            "Epoch 3, Batch 876 / 1350, Loss: 0.05366230010986328\n",
            "Epoch 3, Batch 877 / 1350, Loss: 0.21440228819847107\n",
            "Epoch 3, Batch 878 / 1350, Loss: 0.05579495057463646\n",
            "Epoch 3, Batch 879 / 1350, Loss: 0.07060442864894867\n",
            "Epoch 3, Batch 880 / 1350, Loss: 0.26323243975639343\n",
            "Epoch 3, Batch 881 / 1350, Loss: 0.3277762532234192\n",
            "Epoch 3, Batch 882 / 1350, Loss: 0.393748015165329\n",
            "Epoch 3, Batch 883 / 1350, Loss: 0.06715624034404755\n",
            "Epoch 3, Batch 884 / 1350, Loss: 0.25539636611938477\n",
            "Epoch 3, Batch 885 / 1350, Loss: 1.0024138689041138\n",
            "Epoch 3, Batch 886 / 1350, Loss: 0.9461145997047424\n",
            "Epoch 3, Batch 887 / 1350, Loss: 0.17782363295555115\n",
            "Epoch 3, Batch 888 / 1350, Loss: 0.03424975648522377\n",
            "Epoch 3, Batch 889 / 1350, Loss: 0.2620689868927002\n",
            "Epoch 3, Batch 890 / 1350, Loss: 0.054307933896780014\n",
            "Epoch 3, Batch 891 / 1350, Loss: 0.6808019280433655\n",
            "Epoch 3, Batch 892 / 1350, Loss: 0.043475423008203506\n",
            "Epoch 3, Batch 893 / 1350, Loss: 0.1847143918275833\n",
            "Epoch 3, Batch 894 / 1350, Loss: 0.7387285828590393\n",
            "Epoch 3, Batch 895 / 1350, Loss: 0.07724066078662872\n",
            "Epoch 3, Batch 896 / 1350, Loss: 0.1895299255847931\n",
            "Epoch 3, Batch 897 / 1350, Loss: 1.7354214191436768\n",
            "Epoch 3, Batch 898 / 1350, Loss: 0.44832417368888855\n",
            "Epoch 3, Batch 899 / 1350, Loss: 0.4608789086341858\n",
            "Epoch 3, Batch 900 / 1350, Loss: 0.23936988413333893\n",
            "Epoch 3, Batch 901 / 1350, Loss: 0.26761266589164734\n",
            "Epoch 3, Batch 902 / 1350, Loss: 0.34142839908599854\n",
            "Epoch 3, Batch 903 / 1350, Loss: 0.6071045398712158\n",
            "Epoch 3, Batch 904 / 1350, Loss: 0.32739806175231934\n",
            "Epoch 3, Batch 905 / 1350, Loss: 0.806509256362915\n",
            "Epoch 3, Batch 906 / 1350, Loss: 0.29862505197525024\n",
            "Epoch 3, Batch 907 / 1350, Loss: 0.08736695349216461\n",
            "Epoch 3, Batch 908 / 1350, Loss: 0.14791452884674072\n",
            "Epoch 3, Batch 909 / 1350, Loss: 0.06886221468448639\n",
            "Epoch 3, Batch 910 / 1350, Loss: 0.09009644389152527\n",
            "Epoch 3, Batch 911 / 1350, Loss: 0.3379761576652527\n",
            "Epoch 3, Batch 912 / 1350, Loss: 0.5334852933883667\n",
            "Epoch 3, Batch 913 / 1350, Loss: 0.22740912437438965\n",
            "Epoch 3, Batch 914 / 1350, Loss: 0.08420403301715851\n",
            "Epoch 3, Batch 915 / 1350, Loss: 0.14021801948547363\n",
            "Epoch 3, Batch 916 / 1350, Loss: 0.3265599310398102\n",
            "Epoch 3, Batch 917 / 1350, Loss: 0.35243433713912964\n",
            "Epoch 3, Batch 918 / 1350, Loss: 0.19108030200004578\n",
            "Epoch 3, Batch 919 / 1350, Loss: 0.31251266598701477\n",
            "Epoch 3, Batch 920 / 1350, Loss: 0.8731389045715332\n",
            "Epoch 3, Batch 921 / 1350, Loss: 0.22608788311481476\n",
            "Epoch 3, Batch 922 / 1350, Loss: 0.10815931856632233\n",
            "Epoch 3, Batch 923 / 1350, Loss: 0.5565102100372314\n",
            "Epoch 3, Batch 924 / 1350, Loss: 0.18317201733589172\n",
            "Epoch 3, Batch 925 / 1350, Loss: 0.2257031500339508\n",
            "Epoch 3, Batch 926 / 1350, Loss: 0.029044728726148605\n",
            "Epoch 3, Batch 927 / 1350, Loss: 0.1389249861240387\n",
            "Epoch 3, Batch 928 / 1350, Loss: 0.3190484642982483\n",
            "Epoch 3, Batch 929 / 1350, Loss: 0.08166486024856567\n",
            "Epoch 3, Batch 930 / 1350, Loss: 0.24709156155586243\n",
            "Epoch 3, Batch 931 / 1350, Loss: 0.3808462619781494\n",
            "Epoch 3, Batch 932 / 1350, Loss: 0.4293605089187622\n",
            "Epoch 3, Batch 933 / 1350, Loss: 0.4081479609012604\n",
            "Epoch 3, Batch 934 / 1350, Loss: 0.07799725234508514\n",
            "Epoch 3, Batch 935 / 1350, Loss: 0.42242631316185\n",
            "Epoch 3, Batch 936 / 1350, Loss: 0.09434668719768524\n",
            "Epoch 3, Batch 937 / 1350, Loss: 0.48805010318756104\n",
            "Epoch 3, Batch 938 / 1350, Loss: 0.2533431351184845\n",
            "Epoch 3, Batch 939 / 1350, Loss: 0.301967591047287\n",
            "Epoch 3, Batch 940 / 1350, Loss: 0.296758234500885\n",
            "Epoch 3, Batch 941 / 1350, Loss: 0.05905617028474808\n",
            "Epoch 3, Batch 942 / 1350, Loss: 0.39599528908729553\n",
            "Epoch 3, Batch 943 / 1350, Loss: 0.08445718139410019\n",
            "Epoch 3, Batch 944 / 1350, Loss: 0.16497889161109924\n",
            "Epoch 3, Batch 945 / 1350, Loss: 0.6338894367218018\n",
            "Epoch 3, Batch 946 / 1350, Loss: 0.04611990228295326\n",
            "Epoch 3, Batch 947 / 1350, Loss: 0.04402630403637886\n",
            "Epoch 3, Batch 948 / 1350, Loss: 0.15676641464233398\n",
            "Epoch 3, Batch 949 / 1350, Loss: 0.6633013486862183\n",
            "Epoch 3, Batch 950 / 1350, Loss: 0.17682062089443207\n",
            "Epoch 3, Batch 951 / 1350, Loss: 0.23791395127773285\n",
            "Epoch 3, Batch 952 / 1350, Loss: 0.41577422618865967\n",
            "Epoch 3, Batch 953 / 1350, Loss: 0.18612036108970642\n",
            "Epoch 3, Batch 954 / 1350, Loss: 0.05072770640254021\n",
            "Epoch 3, Batch 955 / 1350, Loss: 0.0520843043923378\n",
            "Epoch 3, Batch 956 / 1350, Loss: 0.10046321898698807\n",
            "Epoch 3, Batch 957 / 1350, Loss: 0.03616029769182205\n",
            "Epoch 3, Batch 958 / 1350, Loss: 0.030727289617061615\n",
            "Epoch 3, Batch 959 / 1350, Loss: 0.026631580665707588\n",
            "Epoch 3, Batch 960 / 1350, Loss: 0.25230059027671814\n",
            "Epoch 3, Batch 961 / 1350, Loss: 0.012353298254311085\n",
            "Epoch 3, Batch 962 / 1350, Loss: 0.05813584849238396\n",
            "Epoch 3, Batch 963 / 1350, Loss: 0.016122404485940933\n",
            "Epoch 3, Batch 964 / 1350, Loss: 0.08358988910913467\n",
            "Epoch 3, Batch 965 / 1350, Loss: 0.09558384120464325\n",
            "Epoch 3, Batch 966 / 1350, Loss: 0.04937073215842247\n",
            "Epoch 3, Batch 967 / 1350, Loss: 0.010926944203674793\n",
            "Epoch 3, Batch 968 / 1350, Loss: 0.09619791805744171\n",
            "Epoch 3, Batch 969 / 1350, Loss: 0.1004365086555481\n",
            "Epoch 3, Batch 970 / 1350, Loss: 0.014573159627616405\n",
            "Epoch 3, Batch 971 / 1350, Loss: 0.4214930236339569\n",
            "Epoch 3, Batch 972 / 1350, Loss: 0.03732304647564888\n",
            "Epoch 3, Batch 973 / 1350, Loss: 0.9368487596511841\n",
            "Epoch 3, Batch 974 / 1350, Loss: 0.0109044648706913\n",
            "Epoch 3, Batch 975 / 1350, Loss: 0.013281743042171001\n",
            "Epoch 3, Batch 976 / 1350, Loss: 0.1053653284907341\n",
            "Epoch 3, Batch 977 / 1350, Loss: 0.2340746968984604\n",
            "Epoch 3, Batch 978 / 1350, Loss: 0.11988679319620132\n",
            "Epoch 3, Batch 979 / 1350, Loss: 0.028242839500308037\n",
            "Epoch 3, Batch 980 / 1350, Loss: 0.2471260279417038\n",
            "Epoch 3, Batch 981 / 1350, Loss: 0.012510890141129494\n",
            "Epoch 3, Batch 982 / 1350, Loss: 0.8647985458374023\n",
            "Epoch 3, Batch 983 / 1350, Loss: 0.3630663752555847\n",
            "Epoch 3, Batch 984 / 1350, Loss: 0.8342828154563904\n",
            "Epoch 3, Batch 985 / 1350, Loss: 0.07046480476856232\n",
            "Epoch 3, Batch 986 / 1350, Loss: 0.041920602321624756\n",
            "Epoch 3, Batch 987 / 1350, Loss: 0.05582164227962494\n",
            "Epoch 3, Batch 988 / 1350, Loss: 0.02334088832139969\n",
            "Epoch 3, Batch 989 / 1350, Loss: 0.6960369348526001\n",
            "Epoch 3, Batch 990 / 1350, Loss: 0.312107115983963\n",
            "Epoch 3, Batch 991 / 1350, Loss: 0.15537112951278687\n",
            "Epoch 3, Batch 992 / 1350, Loss: 0.10118191689252853\n",
            "Epoch 3, Batch 993 / 1350, Loss: 0.10277306288480759\n",
            "Epoch 3, Batch 994 / 1350, Loss: 0.4480833113193512\n",
            "Epoch 3, Batch 995 / 1350, Loss: 0.200810968875885\n",
            "Epoch 3, Batch 996 / 1350, Loss: 0.2411632388830185\n",
            "Epoch 3, Batch 997 / 1350, Loss: 0.13719166815280914\n",
            "Epoch 3, Batch 998 / 1350, Loss: 0.1251080483198166\n",
            "Epoch 3, Batch 999 / 1350, Loss: 0.033945661038160324\n",
            "Epoch 3, Batch 1000 / 1350, Loss: 0.04389360174536705\n",
            "Epoch 3, Batch 1001 / 1350, Loss: 0.41997095942497253\n",
            "Epoch 3, Batch 1002 / 1350, Loss: 0.022178325802087784\n",
            "Epoch 3, Batch 1003 / 1350, Loss: 0.25494515895843506\n",
            "Epoch 3, Batch 1004 / 1350, Loss: 0.21960169076919556\n",
            "Epoch 3, Batch 1005 / 1350, Loss: 0.012883678078651428\n",
            "Epoch 3, Batch 1006 / 1350, Loss: 0.354995459318161\n",
            "Epoch 3, Batch 1007 / 1350, Loss: 0.012571320869028568\n",
            "Epoch 3, Batch 1008 / 1350, Loss: 0.0254512969404459\n",
            "Epoch 3, Batch 1009 / 1350, Loss: 0.02047119475901127\n",
            "Epoch 3, Batch 1010 / 1350, Loss: 0.9049069285392761\n",
            "Epoch 3, Batch 1011 / 1350, Loss: 0.22663378715515137\n",
            "Epoch 3, Batch 1012 / 1350, Loss: 1.1359835863113403\n",
            "Epoch 3, Batch 1013 / 1350, Loss: 0.07732334733009338\n",
            "Epoch 3, Batch 1014 / 1350, Loss: 0.28674566745758057\n",
            "Epoch 3, Batch 1015 / 1350, Loss: 0.13931186497211456\n",
            "Epoch 3, Batch 1016 / 1350, Loss: 1.852110505104065\n",
            "Epoch 3, Batch 1017 / 1350, Loss: 0.2082061618566513\n",
            "Epoch 3, Batch 1018 / 1350, Loss: 0.04770079627633095\n",
            "Epoch 3, Batch 1019 / 1350, Loss: 0.16352805495262146\n",
            "Epoch 3, Batch 1020 / 1350, Loss: 0.6015646457672119\n",
            "Epoch 3, Batch 1021 / 1350, Loss: 0.11717896163463593\n",
            "Epoch 3, Batch 1022 / 1350, Loss: 2.0589098930358887\n",
            "Epoch 3, Batch 1023 / 1350, Loss: 0.08745580911636353\n",
            "Epoch 3, Batch 1024 / 1350, Loss: 0.07351983338594437\n",
            "Epoch 3, Batch 1025 / 1350, Loss: 0.1322070211172104\n",
            "Epoch 3, Batch 1026 / 1350, Loss: 0.1410083919763565\n",
            "Epoch 3, Batch 1027 / 1350, Loss: 0.2598241865634918\n",
            "Epoch 3, Batch 1028 / 1350, Loss: 0.03108753077685833\n",
            "Epoch 3, Batch 1029 / 1350, Loss: 0.8714006543159485\n",
            "Epoch 3, Batch 1030 / 1350, Loss: 0.025189027190208435\n",
            "Epoch 3, Batch 1031 / 1350, Loss: 0.3368959128856659\n",
            "Epoch 3, Batch 1032 / 1350, Loss: 0.05188591033220291\n",
            "Epoch 3, Batch 1033 / 1350, Loss: 0.13916201889514923\n",
            "Epoch 3, Batch 1034 / 1350, Loss: 0.38729721307754517\n",
            "Epoch 3, Batch 1035 / 1350, Loss: 0.07872094959020615\n",
            "Epoch 3, Batch 1036 / 1350, Loss: 0.05056319385766983\n",
            "Epoch 3, Batch 1037 / 1350, Loss: 0.2701749801635742\n",
            "Epoch 3, Batch 1038 / 1350, Loss: 0.5104678869247437\n",
            "Epoch 3, Batch 1039 / 1350, Loss: 0.5482801198959351\n",
            "Epoch 3, Batch 1040 / 1350, Loss: 0.13951900601387024\n",
            "Epoch 3, Batch 1041 / 1350, Loss: 0.4706709086894989\n",
            "Epoch 3, Batch 1042 / 1350, Loss: 0.19375257194042206\n",
            "Epoch 3, Batch 1043 / 1350, Loss: 0.26717087626457214\n",
            "Epoch 3, Batch 1044 / 1350, Loss: 0.14506827294826508\n",
            "Epoch 3, Batch 1045 / 1350, Loss: 0.18229474127292633\n",
            "Epoch 3, Batch 1046 / 1350, Loss: 0.24694377183914185\n",
            "Epoch 3, Batch 1047 / 1350, Loss: 0.16512537002563477\n",
            "Epoch 3, Batch 1048 / 1350, Loss: 0.04316883534193039\n",
            "Epoch 3, Batch 1049 / 1350, Loss: 0.8004884719848633\n",
            "Epoch 3, Batch 1050 / 1350, Loss: 0.11228760331869125\n",
            "Epoch 3, Batch 1051 / 1350, Loss: 0.05960956588387489\n",
            "Epoch 3, Batch 1052 / 1350, Loss: 0.49198856949806213\n",
            "Epoch 3, Batch 1053 / 1350, Loss: 0.5993176698684692\n",
            "Epoch 3, Batch 1054 / 1350, Loss: 0.10066656768321991\n",
            "Epoch 3, Batch 1055 / 1350, Loss: 0.27047061920166016\n",
            "Epoch 3, Batch 1056 / 1350, Loss: 0.7296057939529419\n",
            "Epoch 3, Batch 1057 / 1350, Loss: 0.6853536367416382\n",
            "Epoch 3, Batch 1058 / 1350, Loss: 0.04606792330741882\n",
            "Epoch 3, Batch 1059 / 1350, Loss: 0.33959269523620605\n",
            "Epoch 3, Batch 1060 / 1350, Loss: 0.04744303971529007\n",
            "Epoch 3, Batch 1061 / 1350, Loss: 0.11585726588964462\n",
            "Epoch 3, Batch 1062 / 1350, Loss: 0.19230464100837708\n",
            "Epoch 3, Batch 1063 / 1350, Loss: 0.1438496708869934\n",
            "Epoch 3, Batch 1064 / 1350, Loss: 0.040069445967674255\n",
            "Epoch 3, Batch 1065 / 1350, Loss: 0.07804954051971436\n",
            "Epoch 3, Batch 1066 / 1350, Loss: 0.08791908621788025\n",
            "Epoch 3, Batch 1067 / 1350, Loss: 0.0944613441824913\n",
            "Epoch 3, Batch 1068 / 1350, Loss: 0.6040478944778442\n",
            "Epoch 3, Batch 1069 / 1350, Loss: 0.07350604981184006\n",
            "Epoch 3, Batch 1070 / 1350, Loss: 0.27762532234191895\n",
            "Epoch 3, Batch 1071 / 1350, Loss: 0.05476406216621399\n",
            "Epoch 3, Batch 1072 / 1350, Loss: 0.34244513511657715\n",
            "Epoch 3, Batch 1073 / 1350, Loss: 0.10357777774333954\n",
            "Epoch 3, Batch 1074 / 1350, Loss: 0.5725669264793396\n",
            "Epoch 3, Batch 1075 / 1350, Loss: 0.09324541687965393\n",
            "Epoch 3, Batch 1076 / 1350, Loss: 0.27365046739578247\n",
            "Epoch 3, Batch 1077 / 1350, Loss: 0.1210046112537384\n",
            "Epoch 3, Batch 1078 / 1350, Loss: 0.9158974885940552\n",
            "Epoch 3, Batch 1079 / 1350, Loss: 0.16217298805713654\n",
            "Epoch 3, Batch 1080 / 1350, Loss: 0.09431113302707672\n",
            "Epoch 3, Batch 1081 / 1350, Loss: 0.0678735002875328\n",
            "Epoch 3, Batch 1082 / 1350, Loss: 0.35362306237220764\n",
            "Epoch 3, Batch 1083 / 1350, Loss: 0.04848833009600639\n",
            "Epoch 3, Batch 1084 / 1350, Loss: 0.01666889153420925\n",
            "Epoch 3, Batch 1085 / 1350, Loss: 0.10720852762460709\n",
            "Epoch 3, Batch 1086 / 1350, Loss: 0.0779130607843399\n",
            "Epoch 3, Batch 1087 / 1350, Loss: 0.11193303018808365\n",
            "Epoch 3, Batch 1088 / 1350, Loss: 0.05309353768825531\n",
            "Epoch 3, Batch 1089 / 1350, Loss: 0.08167131245136261\n",
            "Epoch 3, Batch 1090 / 1350, Loss: 0.1807827651500702\n",
            "Epoch 3, Batch 1091 / 1350, Loss: 0.24082903563976288\n",
            "Epoch 3, Batch 1092 / 1350, Loss: 0.05531776696443558\n",
            "Epoch 3, Batch 1093 / 1350, Loss: 0.26293283700942993\n",
            "Epoch 3, Batch 1094 / 1350, Loss: 0.37338191270828247\n",
            "Epoch 3, Batch 1095 / 1350, Loss: 0.2698087692260742\n",
            "Epoch 3, Batch 1096 / 1350, Loss: 0.6836118698120117\n",
            "Epoch 3, Batch 1097 / 1350, Loss: 1.014916181564331\n",
            "Epoch 3, Batch 1098 / 1350, Loss: 0.015344959683716297\n",
            "Epoch 3, Batch 1099 / 1350, Loss: 0.4590073823928833\n",
            "Epoch 3, Batch 1100 / 1350, Loss: 0.027495387941598892\n",
            "Epoch 3, Batch 1101 / 1350, Loss: 0.51438969373703\n",
            "Epoch 3, Batch 1102 / 1350, Loss: 0.03293994069099426\n",
            "Epoch 3, Batch 1103 / 1350, Loss: 0.45645999908447266\n",
            "Epoch 3, Batch 1104 / 1350, Loss: 0.1816345751285553\n",
            "Epoch 3, Batch 1105 / 1350, Loss: 0.9041196703910828\n",
            "Epoch 3, Batch 1106 / 1350, Loss: 0.12640345096588135\n",
            "Epoch 3, Batch 1107 / 1350, Loss: 0.36156848073005676\n",
            "Epoch 3, Batch 1108 / 1350, Loss: 0.21636514365673065\n",
            "Epoch 3, Batch 1109 / 1350, Loss: 0.27088019251823425\n",
            "Epoch 3, Batch 1110 / 1350, Loss: 0.4835284948348999\n",
            "Epoch 3, Batch 1111 / 1350, Loss: 0.5204542875289917\n",
            "Epoch 3, Batch 1112 / 1350, Loss: 0.342819482088089\n",
            "Epoch 3, Batch 1113 / 1350, Loss: 0.04508483409881592\n",
            "Epoch 3, Batch 1114 / 1350, Loss: 1.0468636751174927\n",
            "Epoch 3, Batch 1115 / 1350, Loss: 0.13951683044433594\n",
            "Epoch 3, Batch 1116 / 1350, Loss: 0.021501071751117706\n",
            "Epoch 3, Batch 1117 / 1350, Loss: 0.044627219438552856\n",
            "Epoch 3, Batch 1118 / 1350, Loss: 0.202402725815773\n",
            "Epoch 3, Batch 1119 / 1350, Loss: 1.041358470916748\n",
            "Epoch 3, Batch 1120 / 1350, Loss: 1.1067959070205688\n",
            "Epoch 3, Batch 1121 / 1350, Loss: 0.02122041955590248\n",
            "Epoch 3, Batch 1122 / 1350, Loss: 0.1422157734632492\n",
            "Epoch 3, Batch 1123 / 1350, Loss: 0.04561574384570122\n",
            "Epoch 3, Batch 1124 / 1350, Loss: 0.09799826145172119\n",
            "Epoch 3, Batch 1125 / 1350, Loss: 0.457248330116272\n",
            "Epoch 3, Batch 1126 / 1350, Loss: 0.035011567175388336\n",
            "Epoch 3, Batch 1127 / 1350, Loss: 0.04845064878463745\n",
            "Epoch 3, Batch 1128 / 1350, Loss: 0.7401681542396545\n",
            "Epoch 3, Batch 1129 / 1350, Loss: 0.19804677367210388\n",
            "Epoch 3, Batch 1130 / 1350, Loss: 0.2954009771347046\n",
            "Epoch 3, Batch 1131 / 1350, Loss: 0.24770143628120422\n",
            "Epoch 3, Batch 1132 / 1350, Loss: 0.14764776825904846\n",
            "Epoch 3, Batch 1133 / 1350, Loss: 0.7312713861465454\n",
            "Epoch 3, Batch 1134 / 1350, Loss: 0.29054731130599976\n",
            "Epoch 3, Batch 1135 / 1350, Loss: 0.053271859884262085\n",
            "Epoch 3, Batch 1136 / 1350, Loss: 0.06898277252912521\n",
            "Epoch 3, Batch 1137 / 1350, Loss: 0.3494834005832672\n",
            "Epoch 3, Batch 1138 / 1350, Loss: 0.05011836439371109\n",
            "Epoch 3, Batch 1139 / 1350, Loss: 0.5320286154747009\n",
            "Epoch 3, Batch 1140 / 1350, Loss: 0.06358618289232254\n",
            "Epoch 3, Batch 1141 / 1350, Loss: 0.6110893487930298\n",
            "Epoch 3, Batch 1142 / 1350, Loss: 0.3342050015926361\n",
            "Epoch 3, Batch 1143 / 1350, Loss: 1.0303438901901245\n",
            "Epoch 3, Batch 1144 / 1350, Loss: 0.17703783512115479\n",
            "Epoch 3, Batch 1145 / 1350, Loss: 0.07081419229507446\n",
            "Epoch 3, Batch 1146 / 1350, Loss: 0.030772630125284195\n",
            "Epoch 3, Batch 1147 / 1350, Loss: 0.37315863370895386\n",
            "Epoch 3, Batch 1148 / 1350, Loss: 0.04965759068727493\n",
            "Epoch 3, Batch 1149 / 1350, Loss: 0.7624527215957642\n",
            "Epoch 3, Batch 1150 / 1350, Loss: 0.031837113201618195\n",
            "Epoch 3, Batch 1151 / 1350, Loss: 0.07193852961063385\n",
            "Epoch 3, Batch 1152 / 1350, Loss: 0.18358224630355835\n",
            "Epoch 3, Batch 1153 / 1350, Loss: 0.130254328250885\n",
            "Epoch 3, Batch 1154 / 1350, Loss: 0.5113540291786194\n",
            "Epoch 3, Batch 1155 / 1350, Loss: 0.21845325827598572\n",
            "Epoch 3, Batch 1156 / 1350, Loss: 0.25528842210769653\n",
            "Epoch 3, Batch 1157 / 1350, Loss: 0.23866692185401917\n",
            "Epoch 3, Batch 1158 / 1350, Loss: 0.035128723829984665\n",
            "Epoch 3, Batch 1159 / 1350, Loss: 0.041326332837343216\n",
            "Epoch 3, Batch 1160 / 1350, Loss: 0.14770005643367767\n",
            "Epoch 3, Batch 1161 / 1350, Loss: 0.09823191910982132\n",
            "Epoch 3, Batch 1162 / 1350, Loss: 0.08078688383102417\n",
            "Epoch 3, Batch 1163 / 1350, Loss: 0.22016596794128418\n",
            "Epoch 3, Batch 1164 / 1350, Loss: 0.5568674802780151\n",
            "Epoch 3, Batch 1165 / 1350, Loss: 0.5203981995582581\n",
            "Epoch 3, Batch 1166 / 1350, Loss: 0.3045453429222107\n",
            "Epoch 3, Batch 1167 / 1350, Loss: 0.07222200930118561\n",
            "Epoch 3, Batch 1168 / 1350, Loss: 0.027846399694681168\n",
            "Epoch 3, Batch 1169 / 1350, Loss: 0.07929722219705582\n",
            "Epoch 3, Batch 1170 / 1350, Loss: 0.11318165063858032\n",
            "Epoch 3, Batch 1171 / 1350, Loss: 0.04221560060977936\n",
            "Epoch 3, Batch 1172 / 1350, Loss: 0.6743844747543335\n",
            "Epoch 3, Batch 1173 / 1350, Loss: 0.023496756330132484\n",
            "Epoch 3, Batch 1174 / 1350, Loss: 0.1710035502910614\n",
            "Epoch 3, Batch 1175 / 1350, Loss: 0.023395972326397896\n",
            "Epoch 3, Batch 1176 / 1350, Loss: 0.43368250131607056\n",
            "Epoch 3, Batch 1177 / 1350, Loss: 0.0356774739921093\n",
            "Epoch 3, Batch 1178 / 1350, Loss: 0.10416889935731888\n",
            "Epoch 3, Batch 1179 / 1350, Loss: 0.01190321147441864\n",
            "Epoch 3, Batch 1180 / 1350, Loss: 0.3107242286205292\n",
            "Epoch 3, Batch 1181 / 1350, Loss: 0.43215784430503845\n",
            "Epoch 3, Batch 1182 / 1350, Loss: 0.1409587562084198\n",
            "Epoch 3, Batch 1183 / 1350, Loss: 0.5071397423744202\n",
            "Epoch 3, Batch 1184 / 1350, Loss: 0.04724201560020447\n",
            "Epoch 3, Batch 1185 / 1350, Loss: 0.012827528640627861\n",
            "Epoch 3, Batch 1186 / 1350, Loss: 0.05708005279302597\n",
            "Epoch 3, Batch 1187 / 1350, Loss: 0.7235099673271179\n",
            "Epoch 3, Batch 1188 / 1350, Loss: 0.21803390979766846\n",
            "Epoch 3, Batch 1189 / 1350, Loss: 0.6717041730880737\n",
            "Epoch 3, Batch 1190 / 1350, Loss: 0.47243112325668335\n",
            "Epoch 3, Batch 1191 / 1350, Loss: 0.2287694662809372\n",
            "Epoch 3, Batch 1192 / 1350, Loss: 0.5821211934089661\n",
            "Epoch 3, Batch 1193 / 1350, Loss: 0.532508134841919\n",
            "Epoch 3, Batch 1194 / 1350, Loss: 0.03072461113333702\n",
            "Epoch 3, Batch 1195 / 1350, Loss: 0.07852699607610703\n",
            "Epoch 3, Batch 1196 / 1350, Loss: 0.1908046156167984\n",
            "Epoch 3, Batch 1197 / 1350, Loss: 0.15473255515098572\n",
            "Epoch 3, Batch 1198 / 1350, Loss: 0.39383968710899353\n",
            "Epoch 3, Batch 1199 / 1350, Loss: 0.07028047740459442\n",
            "Epoch 3, Batch 1200 / 1350, Loss: 0.9018234014511108\n",
            "Epoch 3, Batch 1201 / 1350, Loss: 0.4707869589328766\n",
            "Epoch 3, Batch 1202 / 1350, Loss: 0.1671075075864792\n",
            "Epoch 3, Batch 1203 / 1350, Loss: 0.15837648510932922\n",
            "Epoch 3, Batch 1204 / 1350, Loss: 0.14515268802642822\n",
            "Epoch 3, Batch 1205 / 1350, Loss: 0.026141194626688957\n",
            "Epoch 3, Batch 1206 / 1350, Loss: 0.7057799100875854\n",
            "Epoch 3, Batch 1207 / 1350, Loss: 0.2138209044933319\n",
            "Epoch 3, Batch 1208 / 1350, Loss: 0.10457378625869751\n",
            "Epoch 3, Batch 1209 / 1350, Loss: 0.043790172785520554\n",
            "Epoch 3, Batch 1210 / 1350, Loss: 0.14360924065113068\n",
            "Epoch 3, Batch 1211 / 1350, Loss: 0.05416495352983475\n",
            "Epoch 3, Batch 1212 / 1350, Loss: 0.4804219901561737\n",
            "Epoch 3, Batch 1213 / 1350, Loss: 0.032196495682001114\n",
            "Epoch 3, Batch 1214 / 1350, Loss: 0.6993387937545776\n",
            "Epoch 3, Batch 1215 / 1350, Loss: 0.03412026911973953\n",
            "Epoch 3, Batch 1216 / 1350, Loss: 0.5960952043533325\n",
            "Epoch 3, Batch 1217 / 1350, Loss: 0.6432333588600159\n",
            "Epoch 3, Batch 1218 / 1350, Loss: 0.1004638522863388\n",
            "Epoch 3, Batch 1219 / 1350, Loss: 1.1879570484161377\n",
            "Epoch 3, Batch 1220 / 1350, Loss: 0.05635504052042961\n",
            "Epoch 3, Batch 1221 / 1350, Loss: 0.04295646771788597\n",
            "Epoch 3, Batch 1222 / 1350, Loss: 0.04877958819270134\n",
            "Epoch 3, Batch 1223 / 1350, Loss: 0.05214672535657883\n",
            "Epoch 3, Batch 1224 / 1350, Loss: 0.16177618503570557\n",
            "Epoch 3, Batch 1225 / 1350, Loss: 0.16373775899410248\n",
            "Epoch 3, Batch 1226 / 1350, Loss: 0.14361535012722015\n",
            "Epoch 3, Batch 1227 / 1350, Loss: 0.06423646956682205\n",
            "Epoch 3, Batch 1228 / 1350, Loss: 0.6534751057624817\n",
            "Epoch 3, Batch 1229 / 1350, Loss: 0.011687593534588814\n",
            "Epoch 3, Batch 1230 / 1350, Loss: 0.15235039591789246\n",
            "Epoch 3, Batch 1231 / 1350, Loss: 0.17386126518249512\n",
            "Epoch 3, Batch 1232 / 1350, Loss: 0.03321283310651779\n",
            "Epoch 3, Batch 1233 / 1350, Loss: 0.08976452052593231\n",
            "Epoch 3, Batch 1234 / 1350, Loss: 0.6617893576622009\n",
            "Epoch 3, Batch 1235 / 1350, Loss: 0.31867754459381104\n",
            "Epoch 3, Batch 1236 / 1350, Loss: 0.2680925130844116\n",
            "Epoch 3, Batch 1237 / 1350, Loss: 0.039537589997053146\n",
            "Epoch 3, Batch 1238 / 1350, Loss: 0.22850549221038818\n",
            "Epoch 3, Batch 1239 / 1350, Loss: 0.01210915856063366\n",
            "Epoch 3, Batch 1240 / 1350, Loss: 0.7691904902458191\n",
            "Epoch 3, Batch 1241 / 1350, Loss: 0.29169654846191406\n",
            "Epoch 3, Batch 1242 / 1350, Loss: 0.08248137682676315\n",
            "Epoch 3, Batch 1243 / 1350, Loss: 0.10621603578329086\n",
            "Epoch 3, Batch 1244 / 1350, Loss: 0.14809007942676544\n",
            "Epoch 3, Batch 1245 / 1350, Loss: 0.34997230768203735\n",
            "Epoch 3, Batch 1246 / 1350, Loss: 0.15763908624649048\n",
            "Epoch 3, Batch 1247 / 1350, Loss: 0.04416137933731079\n",
            "Epoch 3, Batch 1248 / 1350, Loss: 0.31821978092193604\n",
            "Epoch 3, Batch 1249 / 1350, Loss: 0.1621004045009613\n",
            "Epoch 3, Batch 1250 / 1350, Loss: 0.11212983727455139\n",
            "Epoch 3, Batch 1251 / 1350, Loss: 0.6221661567687988\n",
            "Epoch 3, Batch 1252 / 1350, Loss: 0.2924444079399109\n",
            "Epoch 3, Batch 1253 / 1350, Loss: 0.7799246311187744\n",
            "Epoch 3, Batch 1254 / 1350, Loss: 0.13057148456573486\n",
            "Epoch 3, Batch 1255 / 1350, Loss: 0.3547757565975189\n",
            "Epoch 3, Batch 1256 / 1350, Loss: 0.11166825145483017\n",
            "Epoch 3, Batch 1257 / 1350, Loss: 0.1745343953371048\n",
            "Epoch 3, Batch 1258 / 1350, Loss: 0.34668105840682983\n",
            "Epoch 3, Batch 1259 / 1350, Loss: 0.2530530095100403\n",
            "Epoch 3, Batch 1260 / 1350, Loss: 0.1981056183576584\n",
            "Epoch 3, Batch 1261 / 1350, Loss: 0.7000486254692078\n",
            "Epoch 3, Batch 1262 / 1350, Loss: 0.13193556666374207\n",
            "Epoch 3, Batch 1263 / 1350, Loss: 0.14022305607795715\n",
            "Epoch 3, Batch 1264 / 1350, Loss: 0.06880785524845123\n",
            "Epoch 3, Batch 1265 / 1350, Loss: 0.05992140620946884\n",
            "Epoch 3, Batch 1266 / 1350, Loss: 0.05541360378265381\n",
            "Epoch 3, Batch 1267 / 1350, Loss: 0.06312979012727737\n",
            "Epoch 3, Batch 1268 / 1350, Loss: 0.04854915663599968\n",
            "Epoch 3, Batch 1269 / 1350, Loss: 0.14951875805854797\n",
            "Epoch 3, Batch 1270 / 1350, Loss: 0.5891668796539307\n",
            "Epoch 3, Batch 1271 / 1350, Loss: 0.20081260800361633\n",
            "Epoch 3, Batch 1272 / 1350, Loss: 0.05012006685137749\n",
            "Epoch 3, Batch 1273 / 1350, Loss: 0.6564062833786011\n",
            "Epoch 3, Batch 1274 / 1350, Loss: 0.13305853307247162\n",
            "Epoch 3, Batch 1275 / 1350, Loss: 0.02265051193535328\n",
            "Epoch 3, Batch 1276 / 1350, Loss: 0.1922685205936432\n",
            "Epoch 3, Batch 1277 / 1350, Loss: 0.029627986252307892\n",
            "Epoch 3, Batch 1278 / 1350, Loss: 0.24619445204734802\n",
            "Epoch 3, Batch 1279 / 1350, Loss: 0.08701431006193161\n",
            "Epoch 3, Batch 1280 / 1350, Loss: 0.03694472461938858\n",
            "Epoch 3, Batch 1281 / 1350, Loss: 0.057365722954273224\n",
            "Epoch 3, Batch 1282 / 1350, Loss: 0.5475325584411621\n",
            "Epoch 3, Batch 1283 / 1350, Loss: 0.3627886474132538\n",
            "Epoch 3, Batch 1284 / 1350, Loss: 0.09730180352926254\n",
            "Epoch 3, Batch 1285 / 1350, Loss: 1.1735866069793701\n",
            "Epoch 3, Batch 1286 / 1350, Loss: 0.11334624886512756\n",
            "Epoch 3, Batch 1287 / 1350, Loss: 0.06112741306424141\n",
            "Epoch 3, Batch 1288 / 1350, Loss: 0.22693265974521637\n",
            "Epoch 3, Batch 1289 / 1350, Loss: 1.2150957584381104\n",
            "Epoch 3, Batch 1290 / 1350, Loss: 0.03897302597761154\n",
            "Epoch 3, Batch 1291 / 1350, Loss: 1.444309115409851\n",
            "Epoch 3, Batch 1292 / 1350, Loss: 0.907928466796875\n",
            "Epoch 3, Batch 1293 / 1350, Loss: 0.1871289610862732\n",
            "Epoch 3, Batch 1294 / 1350, Loss: 0.058113276958465576\n",
            "Epoch 3, Batch 1295 / 1350, Loss: 0.01038447953760624\n",
            "Epoch 3, Batch 1296 / 1350, Loss: 0.1031562089920044\n",
            "Epoch 3, Batch 1297 / 1350, Loss: 0.06799350678920746\n",
            "Epoch 3, Batch 1298 / 1350, Loss: 0.4415148198604584\n",
            "Epoch 3, Batch 1299 / 1350, Loss: 0.13563768565654755\n",
            "Epoch 3, Batch 1300 / 1350, Loss: 0.05747528746724129\n",
            "Epoch 3, Batch 1301 / 1350, Loss: 0.09504320472478867\n",
            "Epoch 3, Batch 1302 / 1350, Loss: 0.06380025297403336\n",
            "Epoch 3, Batch 1303 / 1350, Loss: 0.8226773142814636\n",
            "Epoch 3, Batch 1304 / 1350, Loss: 0.03863189369440079\n",
            "Epoch 3, Batch 1305 / 1350, Loss: 0.6400425434112549\n",
            "Epoch 3, Batch 1306 / 1350, Loss: 0.18182511627674103\n",
            "Epoch 3, Batch 1307 / 1350, Loss: 0.11062824726104736\n",
            "Epoch 3, Batch 1308 / 1350, Loss: 0.17875701189041138\n",
            "Epoch 3, Batch 1309 / 1350, Loss: 0.1273779571056366\n",
            "Epoch 3, Batch 1310 / 1350, Loss: 0.16341108083724976\n",
            "Epoch 3, Batch 1311 / 1350, Loss: 0.11830711364746094\n",
            "Epoch 3, Batch 1312 / 1350, Loss: 0.17099428176879883\n",
            "Epoch 3, Batch 1313 / 1350, Loss: 0.7115026712417603\n",
            "Epoch 3, Batch 1314 / 1350, Loss: 0.1620272994041443\n",
            "Epoch 3, Batch 1315 / 1350, Loss: 0.15683656930923462\n",
            "Epoch 3, Batch 1316 / 1350, Loss: 0.6246475577354431\n",
            "Epoch 3, Batch 1317 / 1350, Loss: 0.39628317952156067\n",
            "Epoch 3, Batch 1318 / 1350, Loss: 0.13664665818214417\n",
            "Epoch 3, Batch 1319 / 1350, Loss: 0.17887771129608154\n",
            "Epoch 3, Batch 1320 / 1350, Loss: 0.08829375356435776\n",
            "Epoch 3, Batch 1321 / 1350, Loss: 0.05325816199183464\n",
            "Epoch 3, Batch 1322 / 1350, Loss: 0.07972440123558044\n",
            "Epoch 3, Batch 1323 / 1350, Loss: 0.1427684724330902\n",
            "Epoch 3, Batch 1324 / 1350, Loss: 0.016208328306674957\n",
            "Epoch 3, Batch 1325 / 1350, Loss: 0.10667211562395096\n",
            "Epoch 3, Batch 1326 / 1350, Loss: 0.3733457028865814\n",
            "Epoch 3, Batch 1327 / 1350, Loss: 0.30041420459747314\n",
            "Epoch 3, Batch 1328 / 1350, Loss: 0.011866148561239243\n",
            "Epoch 3, Batch 1329 / 1350, Loss: 0.1589408814907074\n",
            "Epoch 3, Batch 1330 / 1350, Loss: 0.09302628040313721\n",
            "Epoch 3, Batch 1331 / 1350, Loss: 0.9983029365539551\n",
            "Epoch 3, Batch 1332 / 1350, Loss: 0.30764707922935486\n",
            "Epoch 3, Batch 1333 / 1350, Loss: 0.5668068528175354\n",
            "Epoch 3, Batch 1334 / 1350, Loss: 0.2601001262664795\n",
            "Epoch 3, Batch 1335 / 1350, Loss: 0.16328640282154083\n",
            "Epoch 3, Batch 1336 / 1350, Loss: 0.019259823486208916\n",
            "Epoch 3, Batch 1337 / 1350, Loss: 0.12190663814544678\n",
            "Epoch 3, Batch 1338 / 1350, Loss: 1.1436275243759155\n",
            "Epoch 3, Batch 1339 / 1350, Loss: 0.6642574071884155\n",
            "Epoch 3, Batch 1340 / 1350, Loss: 0.3632223606109619\n",
            "Epoch 3, Batch 1341 / 1350, Loss: 0.7263171076774597\n",
            "Epoch 3, Batch 1342 / 1350, Loss: 0.025016993284225464\n",
            "Epoch 3, Batch 1343 / 1350, Loss: 0.024599840864539146\n",
            "Epoch 3, Batch 1344 / 1350, Loss: 0.571225106716156\n",
            "Epoch 3, Batch 1345 / 1350, Loss: 0.2647172510623932\n",
            "Epoch 3, Batch 1346 / 1350, Loss: 0.021968556568026543\n",
            "Epoch 3, Batch 1347 / 1350, Loss: 0.11769914627075195\n",
            "Epoch 3, Batch 1348 / 1350, Loss: 0.1047067940235138\n",
            "Epoch 3, Batch 1349 / 1350, Loss: 0.6267359256744385\n",
            "Epoch 3, Batch 1350 / 1350, Loss: 3.714648485183716\n",
            "Epoch 3, Loss: 0.27820761661562654, Accuracy: 0.9429312581063554, Auc: 0.9466027374805344, f1: 0.9224962254655259\n",
            "Epoch 3, Train Loss: 5.289863132832336, Validation Accuracy: 0.8014184397163121\n",
            "Epoch 4, Batch 1 / 1350, Loss: 0.013352492824196815\n",
            "Epoch 4, Batch 2 / 1350, Loss: 0.07857624441385269\n",
            "Epoch 4, Batch 3 / 1350, Loss: 0.057019613683223724\n",
            "Epoch 4, Batch 4 / 1350, Loss: 0.09079472720623016\n",
            "Epoch 4, Batch 5 / 1350, Loss: 0.05833609402179718\n",
            "Epoch 4, Batch 6 / 1350, Loss: 0.04910832643508911\n",
            "Epoch 4, Batch 7 / 1350, Loss: 0.1716306358575821\n",
            "Epoch 4, Batch 8 / 1350, Loss: 0.030448269098997116\n",
            "Epoch 4, Batch 9 / 1350, Loss: 0.48916032910346985\n",
            "Epoch 4, Batch 10 / 1350, Loss: 0.1251751184463501\n",
            "Epoch 4, Batch 11 / 1350, Loss: 0.11667441576719284\n",
            "Epoch 4, Batch 12 / 1350, Loss: 0.29536935687065125\n",
            "Epoch 4, Batch 13 / 1350, Loss: 0.445328027009964\n",
            "Epoch 4, Batch 14 / 1350, Loss: 0.38603734970092773\n",
            "Epoch 4, Batch 15 / 1350, Loss: 0.030002180486917496\n",
            "Epoch 4, Batch 16 / 1350, Loss: 0.036618106067180634\n",
            "Epoch 4, Batch 17 / 1350, Loss: 0.20448724925518036\n",
            "Epoch 4, Batch 18 / 1350, Loss: 0.10737423598766327\n",
            "Epoch 4, Batch 19 / 1350, Loss: 0.20856328308582306\n",
            "Epoch 4, Batch 20 / 1350, Loss: 0.1280239224433899\n",
            "Epoch 4, Batch 21 / 1350, Loss: 0.09998167306184769\n",
            "Epoch 4, Batch 22 / 1350, Loss: 0.34318387508392334\n",
            "Epoch 4, Batch 23 / 1350, Loss: 0.03642650321125984\n",
            "Epoch 4, Batch 24 / 1350, Loss: 0.027373434975743294\n",
            "Epoch 4, Batch 25 / 1350, Loss: 0.07564108073711395\n",
            "Epoch 4, Batch 26 / 1350, Loss: 0.03089943155646324\n",
            "Epoch 4, Batch 27 / 1350, Loss: 0.04789907857775688\n",
            "Epoch 4, Batch 28 / 1350, Loss: 0.41051313281059265\n",
            "Epoch 4, Batch 29 / 1350, Loss: 0.25983473658561707\n",
            "Epoch 4, Batch 30 / 1350, Loss: 0.6171035766601562\n",
            "Epoch 4, Batch 31 / 1350, Loss: 0.28783294558525085\n",
            "Epoch 4, Batch 32 / 1350, Loss: 0.23534120619297028\n",
            "Epoch 4, Batch 33 / 1350, Loss: 0.2577856183052063\n",
            "Epoch 4, Batch 34 / 1350, Loss: 0.20049427449703217\n",
            "Epoch 4, Batch 35 / 1350, Loss: 0.09278866648674011\n",
            "Epoch 4, Batch 36 / 1350, Loss: 0.15759915113449097\n",
            "Epoch 4, Batch 37 / 1350, Loss: 1.291473150253296\n",
            "Epoch 4, Batch 38 / 1350, Loss: 0.05985827371478081\n",
            "Epoch 4, Batch 39 / 1350, Loss: 0.39092275500297546\n",
            "Epoch 4, Batch 40 / 1350, Loss: 0.13123632967472076\n",
            "Epoch 4, Batch 41 / 1350, Loss: 0.5717989802360535\n",
            "Epoch 4, Batch 42 / 1350, Loss: 0.13240641355514526\n",
            "Epoch 4, Batch 43 / 1350, Loss: 0.43442288041114807\n",
            "Epoch 4, Batch 44 / 1350, Loss: 0.09288986772298813\n",
            "Epoch 4, Batch 45 / 1350, Loss: 0.49407631158828735\n",
            "Epoch 4, Batch 46 / 1350, Loss: 0.5912328362464905\n",
            "Epoch 4, Batch 47 / 1350, Loss: 0.2633470594882965\n",
            "Epoch 4, Batch 48 / 1350, Loss: 0.49344757199287415\n",
            "Epoch 4, Batch 49 / 1350, Loss: 0.52558434009552\n",
            "Epoch 4, Batch 50 / 1350, Loss: 0.469631552696228\n",
            "Epoch 4, Batch 51 / 1350, Loss: 0.13458193838596344\n",
            "Epoch 4, Batch 52 / 1350, Loss: 0.13516320288181305\n",
            "Epoch 4, Batch 53 / 1350, Loss: 0.12341594696044922\n",
            "Epoch 4, Batch 54 / 1350, Loss: 0.30335313081741333\n",
            "Epoch 4, Batch 55 / 1350, Loss: 0.17512227594852448\n",
            "Epoch 4, Batch 56 / 1350, Loss: 0.09929803013801575\n",
            "Epoch 4, Batch 57 / 1350, Loss: 0.21362558007240295\n",
            "Epoch 4, Batch 58 / 1350, Loss: 0.03408876433968544\n",
            "Epoch 4, Batch 59 / 1350, Loss: 0.09006833285093307\n",
            "Epoch 4, Batch 60 / 1350, Loss: 0.04977671802043915\n",
            "Epoch 4, Batch 61 / 1350, Loss: 0.04221825301647186\n",
            "Epoch 4, Batch 62 / 1350, Loss: 0.26684698462486267\n",
            "Epoch 4, Batch 63 / 1350, Loss: 0.2323150634765625\n",
            "Epoch 4, Batch 64 / 1350, Loss: 0.02254694513976574\n",
            "Epoch 4, Batch 65 / 1350, Loss: 0.7285259366035461\n",
            "Epoch 4, Batch 66 / 1350, Loss: 0.253338485956192\n",
            "Epoch 4, Batch 67 / 1350, Loss: 0.062305375933647156\n",
            "Epoch 4, Batch 68 / 1350, Loss: 0.14148132503032684\n",
            "Epoch 4, Batch 69 / 1350, Loss: 0.03452259302139282\n",
            "Epoch 4, Batch 70 / 1350, Loss: 0.5393273830413818\n",
            "Epoch 4, Batch 71 / 1350, Loss: 0.056271329522132874\n",
            "Epoch 4, Batch 72 / 1350, Loss: 0.9583555459976196\n",
            "Epoch 4, Batch 73 / 1350, Loss: 0.16895952820777893\n",
            "Epoch 4, Batch 74 / 1350, Loss: 0.13659796118736267\n",
            "Epoch 4, Batch 75 / 1350, Loss: 0.06243107467889786\n",
            "Epoch 4, Batch 76 / 1350, Loss: 0.09948813915252686\n",
            "Epoch 4, Batch 77 / 1350, Loss: 0.016866497695446014\n",
            "Epoch 4, Batch 78 / 1350, Loss: 0.07695236802101135\n",
            "Epoch 4, Batch 79 / 1350, Loss: 0.0901954248547554\n",
            "Epoch 4, Batch 80 / 1350, Loss: 0.08017511665821075\n",
            "Epoch 4, Batch 81 / 1350, Loss: 0.11148040741682053\n",
            "Epoch 4, Batch 82 / 1350, Loss: 0.040846195071935654\n",
            "Epoch 4, Batch 83 / 1350, Loss: 0.08902300894260406\n",
            "Epoch 4, Batch 84 / 1350, Loss: 0.07613273710012436\n",
            "Epoch 4, Batch 85 / 1350, Loss: 0.027610111981630325\n",
            "Epoch 4, Batch 86 / 1350, Loss: 0.11988731473684311\n",
            "Epoch 4, Batch 87 / 1350, Loss: 0.10063145309686661\n",
            "Epoch 4, Batch 88 / 1350, Loss: 0.017094893380999565\n",
            "Epoch 4, Batch 89 / 1350, Loss: 0.20192810893058777\n",
            "Epoch 4, Batch 90 / 1350, Loss: 0.10807901620864868\n",
            "Epoch 4, Batch 91 / 1350, Loss: 0.07889862358570099\n",
            "Epoch 4, Batch 92 / 1350, Loss: 0.1185901090502739\n",
            "Epoch 4, Batch 93 / 1350, Loss: 0.027915887534618378\n",
            "Epoch 4, Batch 94 / 1350, Loss: 0.8914462924003601\n",
            "Epoch 4, Batch 95 / 1350, Loss: 0.024057157337665558\n",
            "Epoch 4, Batch 96 / 1350, Loss: 0.15120820701122284\n",
            "Epoch 4, Batch 97 / 1350, Loss: 0.2731189429759979\n",
            "Epoch 4, Batch 98 / 1350, Loss: 0.012453516945242882\n",
            "Epoch 4, Batch 99 / 1350, Loss: 0.01813443936407566\n",
            "Epoch 4, Batch 100 / 1350, Loss: 0.10929753631353378\n",
            "Epoch 4, Batch 101 / 1350, Loss: 0.021018870174884796\n",
            "Epoch 4, Batch 102 / 1350, Loss: 0.009200147353112698\n",
            "Epoch 4, Batch 103 / 1350, Loss: 0.32893356680870056\n",
            "Epoch 4, Batch 104 / 1350, Loss: 0.22617068886756897\n",
            "Epoch 4, Batch 105 / 1350, Loss: 0.1610943078994751\n",
            "Epoch 4, Batch 106 / 1350, Loss: 0.01461903378367424\n",
            "Epoch 4, Batch 107 / 1350, Loss: 0.12838341295719147\n",
            "Epoch 4, Batch 108 / 1350, Loss: 0.17326487600803375\n",
            "Epoch 4, Batch 109 / 1350, Loss: 0.6247822046279907\n",
            "Epoch 4, Batch 110 / 1350, Loss: 0.4682828187942505\n",
            "Epoch 4, Batch 111 / 1350, Loss: 0.11157999187707901\n",
            "Epoch 4, Batch 112 / 1350, Loss: 0.0938468873500824\n",
            "Epoch 4, Batch 113 / 1350, Loss: 0.9536649584770203\n",
            "Epoch 4, Batch 114 / 1350, Loss: 0.019495191052556038\n",
            "Epoch 4, Batch 115 / 1350, Loss: 0.12226127088069916\n",
            "Epoch 4, Batch 116 / 1350, Loss: 0.8406411409378052\n",
            "Epoch 4, Batch 117 / 1350, Loss: 0.6176971197128296\n",
            "Epoch 4, Batch 118 / 1350, Loss: 0.014650420285761356\n",
            "Epoch 4, Batch 119 / 1350, Loss: 0.03702526539564133\n",
            "Epoch 4, Batch 120 / 1350, Loss: 0.009275322780013084\n",
            "Epoch 4, Batch 121 / 1350, Loss: 0.01610921323299408\n",
            "Epoch 4, Batch 122 / 1350, Loss: 0.013595560565590858\n",
            "Epoch 4, Batch 123 / 1350, Loss: 0.030309760943055153\n",
            "Epoch 4, Batch 124 / 1350, Loss: 0.16920563578605652\n",
            "Epoch 4, Batch 125 / 1350, Loss: 0.24199774861335754\n",
            "Epoch 4, Batch 126 / 1350, Loss: 0.08569319546222687\n",
            "Epoch 4, Batch 127 / 1350, Loss: 0.4848743677139282\n",
            "Epoch 4, Batch 128 / 1350, Loss: 0.06622714549303055\n",
            "Epoch 4, Batch 129 / 1350, Loss: 0.0462367869913578\n",
            "Epoch 4, Batch 130 / 1350, Loss: 0.20524965226650238\n",
            "Epoch 4, Batch 131 / 1350, Loss: 0.27800849080085754\n",
            "Epoch 4, Batch 132 / 1350, Loss: 0.07642535120248795\n",
            "Epoch 4, Batch 133 / 1350, Loss: 0.05665241554379463\n",
            "Epoch 4, Batch 134 / 1350, Loss: 0.3308875262737274\n",
            "Epoch 4, Batch 135 / 1350, Loss: 0.02377445437014103\n",
            "Epoch 4, Batch 136 / 1350, Loss: 0.04835420474410057\n",
            "Epoch 4, Batch 137 / 1350, Loss: 0.8358703255653381\n",
            "Epoch 4, Batch 138 / 1350, Loss: 0.03210167586803436\n",
            "Epoch 4, Batch 139 / 1350, Loss: 0.02330627851188183\n",
            "Epoch 4, Batch 140 / 1350, Loss: 0.01869986206293106\n",
            "Epoch 4, Batch 141 / 1350, Loss: 0.013898940756917\n",
            "Epoch 4, Batch 142 / 1350, Loss: 0.02087589167058468\n",
            "Epoch 4, Batch 143 / 1350, Loss: 0.01733657345175743\n",
            "Epoch 4, Batch 144 / 1350, Loss: 0.16826562583446503\n",
            "Epoch 4, Batch 145 / 1350, Loss: 0.023936331272125244\n",
            "Epoch 4, Batch 146 / 1350, Loss: 1.2474786043167114\n",
            "Epoch 4, Batch 147 / 1350, Loss: 0.03775819018483162\n",
            "Epoch 4, Batch 148 / 1350, Loss: 0.14116889238357544\n",
            "Epoch 4, Batch 149 / 1350, Loss: 0.03765588253736496\n",
            "Epoch 4, Batch 150 / 1350, Loss: 0.13427135348320007\n",
            "Epoch 4, Batch 151 / 1350, Loss: 0.06085311993956566\n",
            "Epoch 4, Batch 152 / 1350, Loss: 0.3168814480304718\n",
            "Epoch 4, Batch 153 / 1350, Loss: 0.19715014100074768\n",
            "Epoch 4, Batch 154 / 1350, Loss: 0.031966112554073334\n",
            "Epoch 4, Batch 155 / 1350, Loss: 0.8305590152740479\n",
            "Epoch 4, Batch 156 / 1350, Loss: 0.022847410291433334\n",
            "Epoch 4, Batch 157 / 1350, Loss: 0.33755287528038025\n",
            "Epoch 4, Batch 158 / 1350, Loss: 0.018205104395747185\n",
            "Epoch 4, Batch 159 / 1350, Loss: 0.034809380769729614\n",
            "Epoch 4, Batch 160 / 1350, Loss: 0.060851890593767166\n",
            "Epoch 4, Batch 161 / 1350, Loss: 0.010601051151752472\n",
            "Epoch 4, Batch 162 / 1350, Loss: 0.036170005798339844\n",
            "Epoch 4, Batch 163 / 1350, Loss: 0.05357116088271141\n",
            "Epoch 4, Batch 164 / 1350, Loss: 0.8306562900543213\n",
            "Epoch 4, Batch 165 / 1350, Loss: 0.14224295318126678\n",
            "Epoch 4, Batch 166 / 1350, Loss: 0.019487401470541954\n",
            "Epoch 4, Batch 167 / 1350, Loss: 0.7252353429794312\n",
            "Epoch 4, Batch 168 / 1350, Loss: 0.4705987274646759\n",
            "Epoch 4, Batch 169 / 1350, Loss: 1.9269435405731201\n",
            "Epoch 4, Batch 170 / 1350, Loss: 0.024937858805060387\n",
            "Epoch 4, Batch 171 / 1350, Loss: 0.020222298800945282\n",
            "Epoch 4, Batch 172 / 1350, Loss: 0.08446604758501053\n",
            "Epoch 4, Batch 173 / 1350, Loss: 0.11609500646591187\n",
            "Epoch 4, Batch 174 / 1350, Loss: 0.7148183584213257\n",
            "Epoch 4, Batch 175 / 1350, Loss: 0.49750468134880066\n",
            "Epoch 4, Batch 176 / 1350, Loss: 0.07412474602460861\n",
            "Epoch 4, Batch 177 / 1350, Loss: 0.7243019938468933\n",
            "Epoch 4, Batch 178 / 1350, Loss: 0.30450934171676636\n",
            "Epoch 4, Batch 179 / 1350, Loss: 0.0321170836687088\n",
            "Epoch 4, Batch 180 / 1350, Loss: 0.021977223455905914\n",
            "Epoch 4, Batch 181 / 1350, Loss: 0.034604404121637344\n",
            "Epoch 4, Batch 182 / 1350, Loss: 0.05455731973052025\n",
            "Epoch 4, Batch 183 / 1350, Loss: 0.18670812249183655\n",
            "Epoch 4, Batch 184 / 1350, Loss: 0.09885767102241516\n",
            "Epoch 4, Batch 185 / 1350, Loss: 0.14757315814495087\n",
            "Epoch 4, Batch 186 / 1350, Loss: 0.1044786274433136\n",
            "Epoch 4, Batch 187 / 1350, Loss: 0.06303717195987701\n",
            "Epoch 4, Batch 188 / 1350, Loss: 0.32788586616516113\n",
            "Epoch 4, Batch 189 / 1350, Loss: 0.06867095828056335\n",
            "Epoch 4, Batch 190 / 1350, Loss: 0.06069798767566681\n",
            "Epoch 4, Batch 191 / 1350, Loss: 0.11396346241235733\n",
            "Epoch 4, Batch 192 / 1350, Loss: 0.013418447226285934\n",
            "Epoch 4, Batch 193 / 1350, Loss: 0.11084441095590591\n",
            "Epoch 4, Batch 194 / 1350, Loss: 0.03213614597916603\n",
            "Epoch 4, Batch 195 / 1350, Loss: 0.017830438911914825\n",
            "Epoch 4, Batch 196 / 1350, Loss: 0.017642121762037277\n",
            "Epoch 4, Batch 197 / 1350, Loss: 0.0613374188542366\n",
            "Epoch 4, Batch 198 / 1350, Loss: 0.04188305884599686\n",
            "Epoch 4, Batch 199 / 1350, Loss: 0.03037223219871521\n",
            "Epoch 4, Batch 200 / 1350, Loss: 0.7867596745491028\n",
            "Epoch 4, Batch 201 / 1350, Loss: 0.1789950728416443\n",
            "Epoch 4, Batch 202 / 1350, Loss: 0.6304083466529846\n",
            "Epoch 4, Batch 203 / 1350, Loss: 0.04995884746313095\n",
            "Epoch 4, Batch 204 / 1350, Loss: 0.6800699830055237\n",
            "Epoch 4, Batch 205 / 1350, Loss: 0.02935723401606083\n",
            "Epoch 4, Batch 206 / 1350, Loss: 0.07270365208387375\n",
            "Epoch 4, Batch 207 / 1350, Loss: 0.056644048541784286\n",
            "Epoch 4, Batch 208 / 1350, Loss: 0.3680354952812195\n",
            "Epoch 4, Batch 209 / 1350, Loss: 0.16447769105434418\n",
            "Epoch 4, Batch 210 / 1350, Loss: 0.036350324749946594\n",
            "Epoch 4, Batch 211 / 1350, Loss: 0.03837589919567108\n",
            "Epoch 4, Batch 212 / 1350, Loss: 0.03773726522922516\n",
            "Epoch 4, Batch 213 / 1350, Loss: 0.5092066526412964\n",
            "Epoch 4, Batch 214 / 1350, Loss: 0.024358972907066345\n",
            "Epoch 4, Batch 215 / 1350, Loss: 0.14309634268283844\n",
            "Epoch 4, Batch 216 / 1350, Loss: 0.2502804398536682\n",
            "Epoch 4, Batch 217 / 1350, Loss: 0.013553179800510406\n",
            "Epoch 4, Batch 218 / 1350, Loss: 0.022046707570552826\n",
            "Epoch 4, Batch 219 / 1350, Loss: 0.15533128380775452\n",
            "Epoch 4, Batch 220 / 1350, Loss: 0.051673002541065216\n",
            "Epoch 4, Batch 221 / 1350, Loss: 0.044428590685129166\n",
            "Epoch 4, Batch 222 / 1350, Loss: 0.04368378221988678\n",
            "Epoch 4, Batch 223 / 1350, Loss: 0.019348591566085815\n",
            "Epoch 4, Batch 224 / 1350, Loss: 0.03145354986190796\n",
            "Epoch 4, Batch 225 / 1350, Loss: 0.2057792842388153\n",
            "Epoch 4, Batch 226 / 1350, Loss: 0.16057734191417694\n",
            "Epoch 4, Batch 227 / 1350, Loss: 0.02921406179666519\n",
            "Epoch 4, Batch 228 / 1350, Loss: 0.037080924957990646\n",
            "Epoch 4, Batch 229 / 1350, Loss: 0.32219022512435913\n",
            "Epoch 4, Batch 230 / 1350, Loss: 0.02798820286989212\n",
            "Epoch 4, Batch 231 / 1350, Loss: 0.06167745962738991\n",
            "Epoch 4, Batch 232 / 1350, Loss: 0.10382350534200668\n",
            "Epoch 4, Batch 233 / 1350, Loss: 0.012173667550086975\n",
            "Epoch 4, Batch 234 / 1350, Loss: 1.00361967086792\n",
            "Epoch 4, Batch 235 / 1350, Loss: 0.5723344087600708\n",
            "Epoch 4, Batch 236 / 1350, Loss: 0.024877695366740227\n",
            "Epoch 4, Batch 237 / 1350, Loss: 0.024158725515007973\n",
            "Epoch 4, Batch 238 / 1350, Loss: 0.03505167365074158\n",
            "Epoch 4, Batch 239 / 1350, Loss: 0.26859143376350403\n",
            "Epoch 4, Batch 240 / 1350, Loss: 0.06584655493497849\n",
            "Epoch 4, Batch 241 / 1350, Loss: 1.1954066753387451\n",
            "Epoch 4, Batch 242 / 1350, Loss: 0.01736738160252571\n",
            "Epoch 4, Batch 243 / 1350, Loss: 0.41029322147369385\n",
            "Epoch 4, Batch 244 / 1350, Loss: 0.02452564612030983\n",
            "Epoch 4, Batch 245 / 1350, Loss: 0.06778617203235626\n",
            "Epoch 4, Batch 246 / 1350, Loss: 0.028587613254785538\n",
            "Epoch 4, Batch 247 / 1350, Loss: 0.3789869248867035\n",
            "Epoch 4, Batch 248 / 1350, Loss: 0.013580301776528358\n",
            "Epoch 4, Batch 249 / 1350, Loss: 0.06313887238502502\n",
            "Epoch 4, Batch 250 / 1350, Loss: 0.17582634091377258\n",
            "Epoch 4, Batch 251 / 1350, Loss: 0.10150047391653061\n",
            "Epoch 4, Batch 252 / 1350, Loss: 0.10311467945575714\n",
            "Epoch 4, Batch 253 / 1350, Loss: 0.4349355101585388\n",
            "Epoch 4, Batch 254 / 1350, Loss: 0.023770008236169815\n",
            "Epoch 4, Batch 255 / 1350, Loss: 0.16279847919940948\n",
            "Epoch 4, Batch 256 / 1350, Loss: 0.02084563486278057\n",
            "Epoch 4, Batch 257 / 1350, Loss: 0.08193798363208771\n",
            "Epoch 4, Batch 258 / 1350, Loss: 0.05437059700489044\n",
            "Epoch 4, Batch 259 / 1350, Loss: 0.021015752106904984\n",
            "Epoch 4, Batch 260 / 1350, Loss: 0.10209313035011292\n",
            "Epoch 4, Batch 261 / 1350, Loss: 0.06465278565883636\n",
            "Epoch 4, Batch 262 / 1350, Loss: 0.4027385115623474\n",
            "Epoch 4, Batch 263 / 1350, Loss: 0.11325425654649734\n",
            "Epoch 4, Batch 264 / 1350, Loss: 0.0462987944483757\n",
            "Epoch 4, Batch 265 / 1350, Loss: 0.9268914461135864\n",
            "Epoch 4, Batch 266 / 1350, Loss: 2.006465435028076\n",
            "Epoch 4, Batch 267 / 1350, Loss: 0.03698626905679703\n",
            "Epoch 4, Batch 268 / 1350, Loss: 0.14126808941364288\n",
            "Epoch 4, Batch 269 / 1350, Loss: 0.043276939541101456\n",
            "Epoch 4, Batch 270 / 1350, Loss: 0.05546634644269943\n",
            "Epoch 4, Batch 271 / 1350, Loss: 0.01280832476913929\n",
            "Epoch 4, Batch 272 / 1350, Loss: 0.029568729922175407\n",
            "Epoch 4, Batch 273 / 1350, Loss: 0.05411257967352867\n",
            "Epoch 4, Batch 274 / 1350, Loss: 0.021215608343482018\n",
            "Epoch 4, Batch 275 / 1350, Loss: 0.16583548486232758\n",
            "Epoch 4, Batch 276 / 1350, Loss: 0.050276875495910645\n",
            "Epoch 4, Batch 277 / 1350, Loss: 0.026673797518014908\n",
            "Epoch 4, Batch 278 / 1350, Loss: 0.039124347269535065\n",
            "Epoch 4, Batch 279 / 1350, Loss: 1.1727725267410278\n",
            "Epoch 4, Batch 280 / 1350, Loss: 0.028399692848324776\n",
            "Epoch 4, Batch 281 / 1350, Loss: 0.057454440742731094\n",
            "Epoch 4, Batch 282 / 1350, Loss: 0.9085649847984314\n",
            "Epoch 4, Batch 283 / 1350, Loss: 0.1465136706829071\n",
            "Epoch 4, Batch 284 / 1350, Loss: 0.08478906750679016\n",
            "Epoch 4, Batch 285 / 1350, Loss: 0.04531257972121239\n",
            "Epoch 4, Batch 286 / 1350, Loss: 0.024399207904934883\n",
            "Epoch 4, Batch 287 / 1350, Loss: 0.02378758415579796\n",
            "Epoch 4, Batch 288 / 1350, Loss: 0.036089371889829636\n",
            "Epoch 4, Batch 289 / 1350, Loss: 0.04434370994567871\n",
            "Epoch 4, Batch 290 / 1350, Loss: 0.0316128134727478\n",
            "Epoch 4, Batch 291 / 1350, Loss: 0.03852952644228935\n",
            "Epoch 4, Batch 292 / 1350, Loss: 0.11143499612808228\n",
            "Epoch 4, Batch 293 / 1350, Loss: 0.0756661593914032\n",
            "Epoch 4, Batch 294 / 1350, Loss: 0.020602582022547722\n",
            "Epoch 4, Batch 295 / 1350, Loss: 0.05658544600009918\n",
            "Epoch 4, Batch 296 / 1350, Loss: 0.06912273913621902\n",
            "Epoch 4, Batch 297 / 1350, Loss: 1.7001488208770752\n",
            "Epoch 4, Batch 298 / 1350, Loss: 0.026504820212721825\n",
            "Epoch 4, Batch 299 / 1350, Loss: 0.0729583278298378\n",
            "Epoch 4, Batch 300 / 1350, Loss: 0.051984332501888275\n",
            "Epoch 4, Batch 301 / 1350, Loss: 0.028739051893353462\n",
            "Epoch 4, Batch 302 / 1350, Loss: 0.0369599275290966\n",
            "Epoch 4, Batch 303 / 1350, Loss: 0.03493228182196617\n",
            "Epoch 4, Batch 304 / 1350, Loss: 0.030945833772420883\n",
            "Epoch 4, Batch 305 / 1350, Loss: 0.11919047683477402\n",
            "Epoch 4, Batch 306 / 1350, Loss: 0.03899607062339783\n",
            "Epoch 4, Batch 307 / 1350, Loss: 0.1430937647819519\n",
            "Epoch 4, Batch 308 / 1350, Loss: 0.05008993297815323\n",
            "Epoch 4, Batch 309 / 1350, Loss: 0.6760624051094055\n",
            "Epoch 4, Batch 310 / 1350, Loss: 0.0494818240404129\n",
            "Epoch 4, Batch 311 / 1350, Loss: 0.2858709692955017\n",
            "Epoch 4, Batch 312 / 1350, Loss: 0.03054921329021454\n",
            "Epoch 4, Batch 313 / 1350, Loss: 0.032226599752902985\n",
            "Epoch 4, Batch 314 / 1350, Loss: 0.22738942503929138\n",
            "Epoch 4, Batch 315 / 1350, Loss: 0.0356665663421154\n",
            "Epoch 4, Batch 316 / 1350, Loss: 0.03401263803243637\n",
            "Epoch 4, Batch 317 / 1350, Loss: 0.04397641494870186\n",
            "Epoch 4, Batch 318 / 1350, Loss: 0.03690742701292038\n",
            "Epoch 4, Batch 319 / 1350, Loss: 0.019134650006890297\n",
            "Epoch 4, Batch 320 / 1350, Loss: 0.015565896406769753\n",
            "Epoch 4, Batch 321 / 1350, Loss: 0.014689188450574875\n",
            "Epoch 4, Batch 322 / 1350, Loss: 0.030531588941812515\n",
            "Epoch 4, Batch 323 / 1350, Loss: 0.9244635701179504\n",
            "Epoch 4, Batch 324 / 1350, Loss: 0.2724406123161316\n",
            "Epoch 4, Batch 325 / 1350, Loss: 0.08460240066051483\n",
            "Epoch 4, Batch 326 / 1350, Loss: 0.018949400633573532\n",
            "Epoch 4, Batch 327 / 1350, Loss: 0.01984911598265171\n",
            "Epoch 4, Batch 328 / 1350, Loss: 0.5022473335266113\n",
            "Epoch 4, Batch 329 / 1350, Loss: 0.10306744277477264\n",
            "Epoch 4, Batch 330 / 1350, Loss: 0.023369569331407547\n",
            "Epoch 4, Batch 331 / 1350, Loss: 0.280729740858078\n",
            "Epoch 4, Batch 332 / 1350, Loss: 0.026575593277812004\n",
            "Epoch 4, Batch 333 / 1350, Loss: 0.057514920830726624\n",
            "Epoch 4, Batch 334 / 1350, Loss: 0.3226119875907898\n",
            "Epoch 4, Batch 335 / 1350, Loss: 0.7094367146492004\n",
            "Epoch 4, Batch 336 / 1350, Loss: 0.016646992415189743\n",
            "Epoch 4, Batch 337 / 1350, Loss: 0.12451718747615814\n",
            "Epoch 4, Batch 338 / 1350, Loss: 0.6609689593315125\n",
            "Epoch 4, Batch 339 / 1350, Loss: 0.04142121970653534\n",
            "Epoch 4, Batch 340 / 1350, Loss: 0.33202964067459106\n",
            "Epoch 4, Batch 341 / 1350, Loss: 0.03253877907991409\n",
            "Epoch 4, Batch 342 / 1350, Loss: 0.023325767368078232\n",
            "Epoch 4, Batch 343 / 1350, Loss: 0.6237929463386536\n",
            "Epoch 4, Batch 344 / 1350, Loss: 0.037798624485731125\n",
            "Epoch 4, Batch 345 / 1350, Loss: 0.22832489013671875\n",
            "Epoch 4, Batch 346 / 1350, Loss: 0.1722164750099182\n",
            "Epoch 4, Batch 347 / 1350, Loss: 0.06400037556886673\n",
            "Epoch 4, Batch 348 / 1350, Loss: 0.03987622633576393\n",
            "Epoch 4, Batch 349 / 1350, Loss: 0.6889635324478149\n",
            "Epoch 4, Batch 350 / 1350, Loss: 0.027175327762961388\n",
            "Epoch 4, Batch 351 / 1350, Loss: 0.9337050318717957\n",
            "Epoch 4, Batch 352 / 1350, Loss: 0.793323278427124\n",
            "Epoch 4, Batch 353 / 1350, Loss: 0.04882684350013733\n",
            "Epoch 4, Batch 354 / 1350, Loss: 0.034332290291786194\n",
            "Epoch 4, Batch 355 / 1350, Loss: 0.31484925746917725\n",
            "Epoch 4, Batch 356 / 1350, Loss: 0.02798047475516796\n",
            "Epoch 4, Batch 357 / 1350, Loss: 0.041037485003471375\n",
            "Epoch 4, Batch 358 / 1350, Loss: 0.3695554733276367\n",
            "Epoch 4, Batch 359 / 1350, Loss: 0.18428431451320648\n",
            "Epoch 4, Batch 360 / 1350, Loss: 0.027020417153835297\n",
            "Epoch 4, Batch 361 / 1350, Loss: 0.052659548819065094\n",
            "Epoch 4, Batch 362 / 1350, Loss: 0.1347375065088272\n",
            "Epoch 4, Batch 363 / 1350, Loss: 0.034602418541908264\n",
            "Epoch 4, Batch 364 / 1350, Loss: 0.07666153460741043\n",
            "Epoch 4, Batch 365 / 1350, Loss: 0.12317806482315063\n",
            "Epoch 4, Batch 366 / 1350, Loss: 0.02346208691596985\n",
            "Epoch 4, Batch 367 / 1350, Loss: 0.1331653743982315\n",
            "Epoch 4, Batch 368 / 1350, Loss: 0.6092856526374817\n",
            "Epoch 4, Batch 369 / 1350, Loss: 0.17821703851222992\n",
            "Epoch 4, Batch 370 / 1350, Loss: 0.269766241312027\n",
            "Epoch 4, Batch 371 / 1350, Loss: 0.033676162362098694\n",
            "Epoch 4, Batch 372 / 1350, Loss: 0.040535248816013336\n",
            "Epoch 4, Batch 373 / 1350, Loss: 0.17306973040103912\n",
            "Epoch 4, Batch 374 / 1350, Loss: 0.07052624225616455\n",
            "Epoch 4, Batch 375 / 1350, Loss: 0.0400959774851799\n",
            "Epoch 4, Batch 376 / 1350, Loss: 0.04061079025268555\n",
            "Epoch 4, Batch 377 / 1350, Loss: 0.10818588733673096\n",
            "Epoch 4, Batch 378 / 1350, Loss: 0.19131697714328766\n",
            "Epoch 4, Batch 379 / 1350, Loss: 0.037055276334285736\n",
            "Epoch 4, Batch 380 / 1350, Loss: 0.014165607281029224\n",
            "Epoch 4, Batch 381 / 1350, Loss: 0.08492330461740494\n",
            "Epoch 4, Batch 382 / 1350, Loss: 0.12441610544919968\n",
            "Epoch 4, Batch 383 / 1350, Loss: 0.7948918342590332\n",
            "Epoch 4, Batch 384 / 1350, Loss: 0.3406603932380676\n",
            "Epoch 4, Batch 385 / 1350, Loss: 0.9541093111038208\n",
            "Epoch 4, Batch 386 / 1350, Loss: 0.03718274086713791\n",
            "Epoch 4, Batch 387 / 1350, Loss: 0.040104176849126816\n",
            "Epoch 4, Batch 388 / 1350, Loss: 0.030894018709659576\n",
            "Epoch 4, Batch 389 / 1350, Loss: 0.7964221835136414\n",
            "Epoch 4, Batch 390 / 1350, Loss: 0.25263532996177673\n",
            "Epoch 4, Batch 391 / 1350, Loss: 0.08623409271240234\n",
            "Epoch 4, Batch 392 / 1350, Loss: 0.022720415145158768\n",
            "Epoch 4, Batch 393 / 1350, Loss: 0.3985656797885895\n",
            "Epoch 4, Batch 394 / 1350, Loss: 0.13897031545639038\n",
            "Epoch 4, Batch 395 / 1350, Loss: 0.011798934079706669\n",
            "Epoch 4, Batch 396 / 1350, Loss: 0.026159662753343582\n",
            "Epoch 4, Batch 397 / 1350, Loss: 0.10539273172616959\n",
            "Epoch 4, Batch 398 / 1350, Loss: 0.13753733038902283\n",
            "Epoch 4, Batch 399 / 1350, Loss: 0.023104406893253326\n",
            "Epoch 4, Batch 400 / 1350, Loss: 0.037843283265829086\n",
            "Epoch 4, Batch 401 / 1350, Loss: 0.015574765391647816\n",
            "Epoch 4, Batch 402 / 1350, Loss: 0.082675039768219\n",
            "Epoch 4, Batch 403 / 1350, Loss: 0.14228303730487823\n",
            "Epoch 4, Batch 404 / 1350, Loss: 0.18899521231651306\n",
            "Epoch 4, Batch 405 / 1350, Loss: 0.04570414870977402\n",
            "Epoch 4, Batch 406 / 1350, Loss: 0.014701209962368011\n",
            "Epoch 4, Batch 407 / 1350, Loss: 0.06408844143152237\n",
            "Epoch 4, Batch 408 / 1350, Loss: 0.07064376026391983\n",
            "Epoch 4, Batch 409 / 1350, Loss: 0.4620453715324402\n",
            "Epoch 4, Batch 410 / 1350, Loss: 0.03592107817530632\n",
            "Epoch 4, Batch 411 / 1350, Loss: 0.22881022095680237\n",
            "Epoch 4, Batch 412 / 1350, Loss: 0.020189736038446426\n",
            "Epoch 4, Batch 413 / 1350, Loss: 0.010061755776405334\n",
            "Epoch 4, Batch 414 / 1350, Loss: 0.03993203490972519\n",
            "Epoch 4, Batch 415 / 1350, Loss: 0.9662830233573914\n",
            "Epoch 4, Batch 416 / 1350, Loss: 0.03177180141210556\n",
            "Epoch 4, Batch 417 / 1350, Loss: 0.04930558800697327\n",
            "Epoch 4, Batch 418 / 1350, Loss: 0.011384240351617336\n",
            "Epoch 4, Batch 419 / 1350, Loss: 0.009370310232043266\n",
            "Epoch 4, Batch 420 / 1350, Loss: 0.020390592515468597\n",
            "Epoch 4, Batch 421 / 1350, Loss: 0.009638966992497444\n",
            "Epoch 4, Batch 422 / 1350, Loss: 0.05001136660575867\n",
            "Epoch 4, Batch 423 / 1350, Loss: 0.015752647072076797\n",
            "Epoch 4, Batch 424 / 1350, Loss: 0.011901355348527431\n",
            "Epoch 4, Batch 425 / 1350, Loss: 1.6881885528564453\n",
            "Epoch 4, Batch 426 / 1350, Loss: 0.029837291687726974\n",
            "Epoch 4, Batch 427 / 1350, Loss: 0.019954461604356766\n",
            "Epoch 4, Batch 428 / 1350, Loss: 0.1855488419532776\n",
            "Epoch 4, Batch 429 / 1350, Loss: 0.01474751066416502\n",
            "Epoch 4, Batch 430 / 1350, Loss: 0.0455637164413929\n",
            "Epoch 4, Batch 431 / 1350, Loss: 0.012622987851500511\n",
            "Epoch 4, Batch 432 / 1350, Loss: 0.6695787906646729\n",
            "Epoch 4, Batch 433 / 1350, Loss: 0.02771574631333351\n",
            "Epoch 4, Batch 434 / 1350, Loss: 0.018518861383199692\n",
            "Epoch 4, Batch 435 / 1350, Loss: 0.011255240067839622\n",
            "Epoch 4, Batch 436 / 1350, Loss: 0.03766239434480667\n",
            "Epoch 4, Batch 437 / 1350, Loss: 0.32439109683036804\n",
            "Epoch 4, Batch 438 / 1350, Loss: 0.35658419132232666\n",
            "Epoch 4, Batch 439 / 1350, Loss: 0.31005749106407166\n",
            "Epoch 4, Batch 440 / 1350, Loss: 0.39400655031204224\n",
            "Epoch 4, Batch 441 / 1350, Loss: 0.03002590872347355\n",
            "Epoch 4, Batch 442 / 1350, Loss: 0.1993728131055832\n",
            "Epoch 4, Batch 443 / 1350, Loss: 0.028727389872074127\n",
            "Epoch 4, Batch 444 / 1350, Loss: 0.07229509949684143\n",
            "Epoch 4, Batch 445 / 1350, Loss: 0.016582142561674118\n",
            "Epoch 4, Batch 446 / 1350, Loss: 0.2663678824901581\n",
            "Epoch 4, Batch 447 / 1350, Loss: 0.025556299835443497\n",
            "Epoch 4, Batch 448 / 1350, Loss: 1.0223491191864014\n",
            "Epoch 4, Batch 449 / 1350, Loss: 0.5034564733505249\n",
            "Epoch 4, Batch 450 / 1350, Loss: 0.10269208997488022\n",
            "Epoch 4, Batch 451 / 1350, Loss: 0.013924969360232353\n",
            "Epoch 4, Batch 452 / 1350, Loss: 0.0437266081571579\n",
            "Epoch 4, Batch 453 / 1350, Loss: 0.7522151470184326\n",
            "Epoch 4, Batch 454 / 1350, Loss: 0.43156322836875916\n",
            "Epoch 4, Batch 455 / 1350, Loss: 0.0836932435631752\n",
            "Epoch 4, Batch 456 / 1350, Loss: 0.153432235121727\n",
            "Epoch 4, Batch 457 / 1350, Loss: 0.045212313532829285\n",
            "Epoch 4, Batch 458 / 1350, Loss: 0.1277041733264923\n",
            "Epoch 4, Batch 459 / 1350, Loss: 0.041274718940258026\n",
            "Epoch 4, Batch 460 / 1350, Loss: 0.4163140058517456\n",
            "Epoch 4, Batch 461 / 1350, Loss: 0.108230821788311\n",
            "Epoch 4, Batch 462 / 1350, Loss: 0.23382997512817383\n",
            "Epoch 4, Batch 463 / 1350, Loss: 0.035918228328228\n",
            "Epoch 4, Batch 464 / 1350, Loss: 0.12503165006637573\n",
            "Epoch 4, Batch 465 / 1350, Loss: 0.4417975842952728\n",
            "Epoch 4, Batch 466 / 1350, Loss: 0.05405241250991821\n",
            "Epoch 4, Batch 467 / 1350, Loss: 0.061753951013088226\n",
            "Epoch 4, Batch 468 / 1350, Loss: 0.17266015708446503\n",
            "Epoch 4, Batch 469 / 1350, Loss: 0.32936891913414\n",
            "Epoch 4, Batch 470 / 1350, Loss: 1.0409026145935059\n",
            "Epoch 4, Batch 471 / 1350, Loss: 0.06596899777650833\n",
            "Epoch 4, Batch 472 / 1350, Loss: 0.03977194428443909\n",
            "Epoch 4, Batch 473 / 1350, Loss: 0.077141672372818\n",
            "Epoch 4, Batch 474 / 1350, Loss: 0.40727105736732483\n",
            "Epoch 4, Batch 475 / 1350, Loss: 0.5924488306045532\n",
            "Epoch 4, Batch 476 / 1350, Loss: 0.09151799976825714\n",
            "Epoch 4, Batch 477 / 1350, Loss: 0.043550755828619\n",
            "Epoch 4, Batch 478 / 1350, Loss: 0.04917680099606514\n",
            "Epoch 4, Batch 479 / 1350, Loss: 0.30805590748786926\n",
            "Epoch 4, Batch 480 / 1350, Loss: 0.09561328589916229\n",
            "Epoch 4, Batch 481 / 1350, Loss: 0.01873529702425003\n",
            "Epoch 4, Batch 482 / 1350, Loss: 0.20715442299842834\n",
            "Epoch 4, Batch 483 / 1350, Loss: 0.9642638564109802\n",
            "Epoch 4, Batch 484 / 1350, Loss: 0.15739446878433228\n",
            "Epoch 4, Batch 485 / 1350, Loss: 0.021867748349905014\n",
            "Epoch 4, Batch 486 / 1350, Loss: 0.06281986832618713\n",
            "Epoch 4, Batch 487 / 1350, Loss: 0.019100651144981384\n",
            "Epoch 4, Batch 488 / 1350, Loss: 0.17876502871513367\n",
            "Epoch 4, Batch 489 / 1350, Loss: 0.025192949920892715\n",
            "Epoch 4, Batch 490 / 1350, Loss: 0.03798074275255203\n",
            "Epoch 4, Batch 491 / 1350, Loss: 0.08699104189872742\n",
            "Epoch 4, Batch 492 / 1350, Loss: 0.16785567998886108\n",
            "Epoch 4, Batch 493 / 1350, Loss: 0.06299424916505814\n",
            "Epoch 4, Batch 494 / 1350, Loss: 0.603302538394928\n",
            "Epoch 4, Batch 495 / 1350, Loss: 0.01418010052293539\n",
            "Epoch 4, Batch 496 / 1350, Loss: 0.08030866831541061\n",
            "Epoch 4, Batch 497 / 1350, Loss: 0.021632038056850433\n",
            "Epoch 4, Batch 498 / 1350, Loss: 0.20311051607131958\n",
            "Epoch 4, Batch 499 / 1350, Loss: 0.035480573773384094\n",
            "Epoch 4, Batch 500 / 1350, Loss: 0.11334884166717529\n",
            "Epoch 4, Batch 501 / 1350, Loss: 0.038252126425504684\n",
            "Epoch 4, Batch 502 / 1350, Loss: 0.19951596856117249\n",
            "Epoch 4, Batch 503 / 1350, Loss: 0.9164942502975464\n",
            "Epoch 4, Batch 504 / 1350, Loss: 0.04808707907795906\n",
            "Epoch 4, Batch 505 / 1350, Loss: 0.04980308935046196\n",
            "Epoch 4, Batch 506 / 1350, Loss: 0.1538979709148407\n",
            "Epoch 4, Batch 507 / 1350, Loss: 0.019761011004447937\n",
            "Epoch 4, Batch 508 / 1350, Loss: 0.07279062271118164\n",
            "Epoch 4, Batch 509 / 1350, Loss: 0.15185320377349854\n",
            "Epoch 4, Batch 510 / 1350, Loss: 0.5641716718673706\n",
            "Epoch 4, Batch 511 / 1350, Loss: 0.018030021339654922\n",
            "Epoch 4, Batch 512 / 1350, Loss: 0.015983903780579567\n",
            "Epoch 4, Batch 513 / 1350, Loss: 0.011814209632575512\n",
            "Epoch 4, Batch 514 / 1350, Loss: 0.06728091835975647\n",
            "Epoch 4, Batch 515 / 1350, Loss: 0.3794197142124176\n",
            "Epoch 4, Batch 516 / 1350, Loss: 0.3991868793964386\n",
            "Epoch 4, Batch 517 / 1350, Loss: 0.0199066624045372\n",
            "Epoch 4, Batch 518 / 1350, Loss: 0.03867645934224129\n",
            "Epoch 4, Batch 519 / 1350, Loss: 0.8489320874214172\n",
            "Epoch 4, Batch 520 / 1350, Loss: 0.057068727910518646\n",
            "Epoch 4, Batch 521 / 1350, Loss: 0.008333936333656311\n",
            "Epoch 4, Batch 522 / 1350, Loss: 0.03432593494653702\n",
            "Epoch 4, Batch 523 / 1350, Loss: 0.02763894945383072\n",
            "Epoch 4, Batch 524 / 1350, Loss: 0.007663647644221783\n",
            "Epoch 4, Batch 525 / 1350, Loss: 0.12685558199882507\n",
            "Epoch 4, Batch 526 / 1350, Loss: 0.06629488617181778\n",
            "Epoch 4, Batch 527 / 1350, Loss: 0.07308453321456909\n",
            "Epoch 4, Batch 528 / 1350, Loss: 0.08911291509866714\n",
            "Epoch 4, Batch 529 / 1350, Loss: 0.8104979395866394\n",
            "Epoch 4, Batch 530 / 1350, Loss: 0.01653924398124218\n",
            "Epoch 4, Batch 531 / 1350, Loss: 0.34432679414749146\n",
            "Epoch 4, Batch 532 / 1350, Loss: 0.5360127687454224\n",
            "Epoch 4, Batch 533 / 1350, Loss: 0.06195623427629471\n",
            "Epoch 4, Batch 534 / 1350, Loss: 0.1950026899576187\n",
            "Epoch 4, Batch 535 / 1350, Loss: 0.010965494439005852\n",
            "Epoch 4, Batch 536 / 1350, Loss: 0.02659386210143566\n",
            "Epoch 4, Batch 537 / 1350, Loss: 0.06588368862867355\n",
            "Epoch 4, Batch 538 / 1350, Loss: 0.03394682705402374\n",
            "Epoch 4, Batch 539 / 1350, Loss: 0.03676255792379379\n",
            "Epoch 4, Batch 540 / 1350, Loss: 0.020801503211259842\n",
            "Epoch 4, Batch 541 / 1350, Loss: 0.03616498410701752\n",
            "Epoch 4, Batch 542 / 1350, Loss: 0.06234785169363022\n",
            "Epoch 4, Batch 543 / 1350, Loss: 0.262122243642807\n",
            "Epoch 4, Batch 544 / 1350, Loss: 0.340486615896225\n",
            "Epoch 4, Batch 545 / 1350, Loss: 0.01471650879830122\n",
            "Epoch 4, Batch 546 / 1350, Loss: 0.018342923372983932\n",
            "Epoch 4, Batch 547 / 1350, Loss: 0.040207792073488235\n",
            "Epoch 4, Batch 548 / 1350, Loss: 0.015391435474157333\n",
            "Epoch 4, Batch 549 / 1350, Loss: 0.019589073956012726\n",
            "Epoch 4, Batch 550 / 1350, Loss: 0.7563400268554688\n",
            "Epoch 4, Batch 551 / 1350, Loss: 0.09077125042676926\n",
            "Epoch 4, Batch 552 / 1350, Loss: 0.13341109454631805\n",
            "Epoch 4, Batch 553 / 1350, Loss: 0.5090950131416321\n",
            "Epoch 4, Batch 554 / 1350, Loss: 0.04341940954327583\n",
            "Epoch 4, Batch 555 / 1350, Loss: 0.18709760904312134\n",
            "Epoch 4, Batch 556 / 1350, Loss: 0.010967595502734184\n",
            "Epoch 4, Batch 557 / 1350, Loss: 0.1528887301683426\n",
            "Epoch 4, Batch 558 / 1350, Loss: 0.6742033362388611\n",
            "Epoch 4, Batch 559 / 1350, Loss: 0.1584177017211914\n",
            "Epoch 4, Batch 560 / 1350, Loss: 0.008340690284967422\n",
            "Epoch 4, Batch 561 / 1350, Loss: 0.4579203724861145\n",
            "Epoch 4, Batch 562 / 1350, Loss: 0.09180903434753418\n",
            "Epoch 4, Batch 563 / 1350, Loss: 0.06589975208044052\n",
            "Epoch 4, Batch 564 / 1350, Loss: 0.17103685438632965\n",
            "Epoch 4, Batch 565 / 1350, Loss: 0.03835636377334595\n",
            "Epoch 4, Batch 566 / 1350, Loss: 0.44346192479133606\n",
            "Epoch 4, Batch 567 / 1350, Loss: 0.47451239824295044\n",
            "Epoch 4, Batch 568 / 1350, Loss: 0.013315379619598389\n",
            "Epoch 4, Batch 569 / 1350, Loss: 0.19383633136749268\n",
            "Epoch 4, Batch 570 / 1350, Loss: 0.00836715754121542\n",
            "Epoch 4, Batch 571 / 1350, Loss: 0.009881952777504921\n",
            "Epoch 4, Batch 572 / 1350, Loss: 0.015648476779460907\n",
            "Epoch 4, Batch 573 / 1350, Loss: 0.38351112604141235\n",
            "Epoch 4, Batch 574 / 1350, Loss: 0.07832269370555878\n",
            "Epoch 4, Batch 575 / 1350, Loss: 0.028743324801325798\n",
            "Epoch 4, Batch 576 / 1350, Loss: 0.013145841658115387\n",
            "Epoch 4, Batch 577 / 1350, Loss: 0.40958383679389954\n",
            "Epoch 4, Batch 578 / 1350, Loss: 0.08834033459424973\n",
            "Epoch 4, Batch 579 / 1350, Loss: 0.3257783353328705\n",
            "Epoch 4, Batch 580 / 1350, Loss: 0.127422034740448\n",
            "Epoch 4, Batch 581 / 1350, Loss: 0.008545863442122936\n",
            "Epoch 4, Batch 582 / 1350, Loss: 0.06427489966154099\n",
            "Epoch 4, Batch 583 / 1350, Loss: 0.7757970690727234\n",
            "Epoch 4, Batch 584 / 1350, Loss: 0.05282332003116608\n",
            "Epoch 4, Batch 585 / 1350, Loss: 0.02525169774889946\n",
            "Epoch 4, Batch 586 / 1350, Loss: 0.009624868631362915\n",
            "Epoch 4, Batch 587 / 1350, Loss: 0.2894555330276489\n",
            "Epoch 4, Batch 588 / 1350, Loss: 0.008145734667778015\n",
            "Epoch 4, Batch 589 / 1350, Loss: 0.11220346391201019\n",
            "Epoch 4, Batch 590 / 1350, Loss: 0.016828536987304688\n",
            "Epoch 4, Batch 591 / 1350, Loss: 0.09011619538068771\n",
            "Epoch 4, Batch 592 / 1350, Loss: 0.4001087248325348\n",
            "Epoch 4, Batch 593 / 1350, Loss: 0.008418669924139977\n",
            "Epoch 4, Batch 594 / 1350, Loss: 0.04193594306707382\n",
            "Epoch 4, Batch 595 / 1350, Loss: 0.09338198602199554\n",
            "Epoch 4, Batch 596 / 1350, Loss: 0.05888042971491814\n",
            "Epoch 4, Batch 597 / 1350, Loss: 0.04731175675988197\n",
            "Epoch 4, Batch 598 / 1350, Loss: 0.18549644947052002\n",
            "Epoch 4, Batch 599 / 1350, Loss: 0.01554948091506958\n",
            "Epoch 4, Batch 600 / 1350, Loss: 0.02063015103340149\n",
            "Epoch 4, Batch 601 / 1350, Loss: 0.02491411194205284\n",
            "Epoch 4, Batch 602 / 1350, Loss: 0.5014933943748474\n",
            "Epoch 4, Batch 603 / 1350, Loss: 0.29039156436920166\n",
            "Epoch 4, Batch 604 / 1350, Loss: 0.10787937045097351\n",
            "Epoch 4, Batch 605 / 1350, Loss: 0.020598191767930984\n",
            "Epoch 4, Batch 606 / 1350, Loss: 0.007373309228569269\n",
            "Epoch 4, Batch 607 / 1350, Loss: 0.026559283956885338\n",
            "Epoch 4, Batch 608 / 1350, Loss: 0.021620817482471466\n",
            "Epoch 4, Batch 609 / 1350, Loss: 0.0071533373557031155\n",
            "Epoch 4, Batch 610 / 1350, Loss: 0.025195717811584473\n",
            "Epoch 4, Batch 611 / 1350, Loss: 0.052478548139333725\n",
            "Epoch 4, Batch 612 / 1350, Loss: 0.17147284746170044\n",
            "Epoch 4, Batch 613 / 1350, Loss: 0.24821846187114716\n",
            "Epoch 4, Batch 614 / 1350, Loss: 0.007356336805969477\n",
            "Epoch 4, Batch 615 / 1350, Loss: 0.014383459463715553\n",
            "Epoch 4, Batch 616 / 1350, Loss: 0.17691102623939514\n",
            "Epoch 4, Batch 617 / 1350, Loss: 0.058326706290245056\n",
            "Epoch 4, Batch 618 / 1350, Loss: 0.0963357537984848\n",
            "Epoch 4, Batch 619 / 1350, Loss: 0.01046643778681755\n",
            "Epoch 4, Batch 620 / 1350, Loss: 0.0601641982793808\n",
            "Epoch 4, Batch 621 / 1350, Loss: 0.025572465732693672\n",
            "Epoch 4, Batch 622 / 1350, Loss: 0.03323202580213547\n",
            "Epoch 4, Batch 623 / 1350, Loss: 0.010217832401394844\n",
            "Epoch 4, Batch 624 / 1350, Loss: 0.006508637219667435\n",
            "Epoch 4, Batch 625 / 1350, Loss: 0.039598431438207626\n",
            "Epoch 4, Batch 626 / 1350, Loss: 0.008518856950104237\n",
            "Epoch 4, Batch 627 / 1350, Loss: 0.03257090225815773\n",
            "Epoch 4, Batch 628 / 1350, Loss: 0.02898956462740898\n",
            "Epoch 4, Batch 629 / 1350, Loss: 0.07775619626045227\n",
            "Epoch 4, Batch 630 / 1350, Loss: 0.015980571508407593\n",
            "Epoch 4, Batch 631 / 1350, Loss: 0.8204509019851685\n",
            "Epoch 4, Batch 632 / 1350, Loss: 0.09914717078208923\n",
            "Epoch 4, Batch 633 / 1350, Loss: 0.007000485900789499\n",
            "Epoch 4, Batch 634 / 1350, Loss: 0.013968175277113914\n",
            "Epoch 4, Batch 635 / 1350, Loss: 0.008009446784853935\n",
            "Epoch 4, Batch 636 / 1350, Loss: 0.5945934057235718\n",
            "Epoch 4, Batch 637 / 1350, Loss: 0.019246842712163925\n",
            "Epoch 4, Batch 638 / 1350, Loss: 0.005013979040086269\n",
            "Epoch 4, Batch 639 / 1350, Loss: 0.006293947342783213\n",
            "Epoch 4, Batch 640 / 1350, Loss: 0.0071506015956401825\n",
            "Epoch 4, Batch 641 / 1350, Loss: 0.09989145398139954\n",
            "Epoch 4, Batch 642 / 1350, Loss: 0.12211856991052628\n",
            "Epoch 4, Batch 643 / 1350, Loss: 0.06485747545957565\n",
            "Epoch 4, Batch 644 / 1350, Loss: 0.3512142598628998\n",
            "Epoch 4, Batch 645 / 1350, Loss: 0.05647696554660797\n",
            "Epoch 4, Batch 646 / 1350, Loss: 0.024587269872426987\n",
            "Epoch 4, Batch 647 / 1350, Loss: 0.007160459645092487\n",
            "Epoch 4, Batch 648 / 1350, Loss: 0.13584807515144348\n",
            "Epoch 4, Batch 649 / 1350, Loss: 0.1671258807182312\n",
            "Epoch 4, Batch 650 / 1350, Loss: 0.03248743712902069\n",
            "Epoch 4, Batch 651 / 1350, Loss: 0.00602934742346406\n",
            "Epoch 4, Batch 652 / 1350, Loss: 0.6263261437416077\n",
            "Epoch 4, Batch 653 / 1350, Loss: 1.310655951499939\n",
            "Epoch 4, Batch 654 / 1350, Loss: 0.1559271216392517\n",
            "Epoch 4, Batch 655 / 1350, Loss: 0.03433002158999443\n",
            "Epoch 4, Batch 656 / 1350, Loss: 0.017217684537172318\n",
            "Epoch 4, Batch 657 / 1350, Loss: 0.0048530856147408485\n",
            "Epoch 4, Batch 658 / 1350, Loss: 0.01744595728814602\n",
            "Epoch 4, Batch 659 / 1350, Loss: 0.06615912914276123\n",
            "Epoch 4, Batch 660 / 1350, Loss: 0.013545344583690166\n",
            "Epoch 4, Batch 661 / 1350, Loss: 0.0175815150141716\n",
            "Epoch 4, Batch 662 / 1350, Loss: 0.005945991724729538\n",
            "Epoch 4, Batch 663 / 1350, Loss: 0.3713698983192444\n",
            "Epoch 4, Batch 664 / 1350, Loss: 0.013297321274876595\n",
            "Epoch 4, Batch 665 / 1350, Loss: 0.017193419858813286\n",
            "Epoch 4, Batch 666 / 1350, Loss: 0.011395779438316822\n",
            "Epoch 4, Batch 667 / 1350, Loss: 0.33707550168037415\n",
            "Epoch 4, Batch 668 / 1350, Loss: 0.007057378068566322\n",
            "Epoch 4, Batch 669 / 1350, Loss: 0.26883742213249207\n",
            "Epoch 4, Batch 670 / 1350, Loss: 1.271282434463501\n",
            "Epoch 4, Batch 671 / 1350, Loss: 0.10865183174610138\n",
            "Epoch 4, Batch 672 / 1350, Loss: 0.0061100260354578495\n",
            "Epoch 4, Batch 673 / 1350, Loss: 0.07524783164262772\n",
            "Epoch 4, Batch 674 / 1350, Loss: 0.05926212668418884\n",
            "Epoch 4, Batch 675 / 1350, Loss: 0.5257742404937744\n",
            "Epoch 4, Batch 676 / 1350, Loss: 0.0059710899367928505\n",
            "Epoch 4, Batch 677 / 1350, Loss: 0.06504128873348236\n",
            "Epoch 4, Batch 678 / 1350, Loss: 0.012409793213009834\n",
            "Epoch 4, Batch 679 / 1350, Loss: 0.438778281211853\n",
            "Epoch 4, Batch 680 / 1350, Loss: 0.0509503073990345\n",
            "Epoch 4, Batch 681 / 1350, Loss: 1.139519453048706\n",
            "Epoch 4, Batch 682 / 1350, Loss: 0.13999494910240173\n",
            "Epoch 4, Batch 683 / 1350, Loss: 0.034512195736169815\n",
            "Epoch 4, Batch 684 / 1350, Loss: 0.11932789534330368\n",
            "Epoch 4, Batch 685 / 1350, Loss: 0.03457564860582352\n",
            "Epoch 4, Batch 686 / 1350, Loss: 0.12145241349935532\n",
            "Epoch 4, Batch 687 / 1350, Loss: 0.0072686742059886456\n",
            "Epoch 4, Batch 688 / 1350, Loss: 0.019491784274578094\n",
            "Epoch 4, Batch 689 / 1350, Loss: 0.007388381753116846\n",
            "Epoch 4, Batch 690 / 1350, Loss: 0.36157774925231934\n",
            "Epoch 4, Batch 691 / 1350, Loss: 0.7744213342666626\n",
            "Epoch 4, Batch 692 / 1350, Loss: 0.008953550830483437\n",
            "Epoch 4, Batch 693 / 1350, Loss: 0.007412640377879143\n",
            "Epoch 4, Batch 694 / 1350, Loss: 0.02844485454261303\n",
            "Epoch 4, Batch 695 / 1350, Loss: 0.02422836795449257\n",
            "Epoch 4, Batch 696 / 1350, Loss: 0.7247771620750427\n",
            "Epoch 4, Batch 697 / 1350, Loss: 0.03774111345410347\n",
            "Epoch 4, Batch 698 / 1350, Loss: 0.07532612234354019\n",
            "Epoch 4, Batch 699 / 1350, Loss: 0.07646919041872025\n",
            "Epoch 4, Batch 700 / 1350, Loss: 0.04645800217986107\n",
            "Epoch 4, Batch 701 / 1350, Loss: 0.36303502321243286\n",
            "Epoch 4, Batch 702 / 1350, Loss: 0.36378806829452515\n",
            "Epoch 4, Batch 703 / 1350, Loss: 0.04966587945818901\n",
            "Epoch 4, Batch 704 / 1350, Loss: 0.00904171820729971\n",
            "Epoch 4, Batch 705 / 1350, Loss: 0.025662923231720924\n",
            "Epoch 4, Batch 706 / 1350, Loss: 0.0817633718252182\n",
            "Epoch 4, Batch 707 / 1350, Loss: 0.1102909967303276\n",
            "Epoch 4, Batch 708 / 1350, Loss: 0.03800056129693985\n",
            "Epoch 4, Batch 709 / 1350, Loss: 0.04484523832798004\n",
            "Epoch 4, Batch 710 / 1350, Loss: 0.028376733884215355\n",
            "Epoch 4, Batch 711 / 1350, Loss: 0.009148070588707924\n",
            "Epoch 4, Batch 712 / 1350, Loss: 0.02455134503543377\n",
            "Epoch 4, Batch 713 / 1350, Loss: 0.013892155140638351\n",
            "Epoch 4, Batch 714 / 1350, Loss: 0.07559871673583984\n",
            "Epoch 4, Batch 715 / 1350, Loss: 0.07863028347492218\n",
            "Epoch 4, Batch 716 / 1350, Loss: 0.06403046101331711\n",
            "Epoch 4, Batch 717 / 1350, Loss: 0.6661422252655029\n",
            "Epoch 4, Batch 718 / 1350, Loss: 0.015807591378688812\n",
            "Epoch 4, Batch 719 / 1350, Loss: 0.0070893121883273125\n",
            "Epoch 4, Batch 720 / 1350, Loss: 0.04758543521165848\n",
            "Epoch 4, Batch 721 / 1350, Loss: 0.41312655806541443\n",
            "Epoch 4, Batch 722 / 1350, Loss: 0.2880246043205261\n",
            "Epoch 4, Batch 723 / 1350, Loss: 0.07141999900341034\n",
            "Epoch 4, Batch 724 / 1350, Loss: 0.011948704719543457\n",
            "Epoch 4, Batch 725 / 1350, Loss: 0.0267014242708683\n",
            "Epoch 4, Batch 726 / 1350, Loss: 0.1205970048904419\n",
            "Epoch 4, Batch 727 / 1350, Loss: 0.014127673581242561\n",
            "Epoch 4, Batch 728 / 1350, Loss: 0.030514301732182503\n",
            "Epoch 4, Batch 729 / 1350, Loss: 0.12976236641407013\n",
            "Epoch 4, Batch 730 / 1350, Loss: 0.5525540709495544\n",
            "Epoch 4, Batch 731 / 1350, Loss: 0.028140924870967865\n",
            "Epoch 4, Batch 732 / 1350, Loss: 0.008012548089027405\n",
            "Epoch 4, Batch 733 / 1350, Loss: 0.2895984947681427\n",
            "Epoch 4, Batch 734 / 1350, Loss: 0.020603764802217484\n",
            "Epoch 4, Batch 735 / 1350, Loss: 0.03250911459326744\n",
            "Epoch 4, Batch 736 / 1350, Loss: 0.525593101978302\n",
            "Epoch 4, Batch 737 / 1350, Loss: 0.616280734539032\n",
            "Epoch 4, Batch 738 / 1350, Loss: 0.14911092817783356\n",
            "Epoch 4, Batch 739 / 1350, Loss: 0.16090244054794312\n",
            "Epoch 4, Batch 740 / 1350, Loss: 0.06806630641222\n",
            "Epoch 4, Batch 741 / 1350, Loss: 0.23179379105567932\n",
            "Epoch 4, Batch 742 / 1350, Loss: 0.12184720486402512\n",
            "Epoch 4, Batch 743 / 1350, Loss: 0.014761400409042835\n",
            "Epoch 4, Batch 744 / 1350, Loss: 0.0446995347738266\n",
            "Epoch 4, Batch 745 / 1350, Loss: 0.05108870193362236\n",
            "Epoch 4, Batch 746 / 1350, Loss: 0.0353805348277092\n",
            "Epoch 4, Batch 747 / 1350, Loss: 0.10821031033992767\n",
            "Epoch 4, Batch 748 / 1350, Loss: 0.7804809212684631\n",
            "Epoch 4, Batch 749 / 1350, Loss: 0.43102166056632996\n",
            "Epoch 4, Batch 750 / 1350, Loss: 0.12728197872638702\n",
            "Epoch 4, Batch 751 / 1350, Loss: 1.0059237480163574\n",
            "Epoch 4, Batch 752 / 1350, Loss: 0.022919317707419395\n",
            "Epoch 4, Batch 753 / 1350, Loss: 0.01496749185025692\n",
            "Epoch 4, Batch 754 / 1350, Loss: 0.040438663214445114\n",
            "Epoch 4, Batch 755 / 1350, Loss: 0.02527618035674095\n",
            "Epoch 4, Batch 756 / 1350, Loss: 0.20983274281024933\n",
            "Epoch 4, Batch 757 / 1350, Loss: 0.22814977169036865\n",
            "Epoch 4, Batch 758 / 1350, Loss: 0.04855664074420929\n",
            "Epoch 4, Batch 759 / 1350, Loss: 0.813425600528717\n",
            "Epoch 4, Batch 760 / 1350, Loss: 0.0770251452922821\n",
            "Epoch 4, Batch 761 / 1350, Loss: 0.2711367905139923\n",
            "Epoch 4, Batch 762 / 1350, Loss: 0.018388856202363968\n",
            "Epoch 4, Batch 763 / 1350, Loss: 0.31622520089149475\n",
            "Epoch 4, Batch 764 / 1350, Loss: 0.07823731005191803\n",
            "Epoch 4, Batch 765 / 1350, Loss: 0.009562725201249123\n",
            "Epoch 4, Batch 766 / 1350, Loss: 0.055088821798563004\n",
            "Epoch 4, Batch 767 / 1350, Loss: 0.49241238832473755\n",
            "Epoch 4, Batch 768 / 1350, Loss: 0.02961774915456772\n",
            "Epoch 4, Batch 769 / 1350, Loss: 0.6007142663002014\n",
            "Epoch 4, Batch 770 / 1350, Loss: 0.5920729041099548\n",
            "Epoch 4, Batch 771 / 1350, Loss: 0.12290984392166138\n",
            "Epoch 4, Batch 772 / 1350, Loss: 0.2262468934059143\n",
            "Epoch 4, Batch 773 / 1350, Loss: 0.19770759344100952\n",
            "Epoch 4, Batch 774 / 1350, Loss: 0.01479298435151577\n",
            "Epoch 4, Batch 775 / 1350, Loss: 0.06571903079748154\n",
            "Epoch 4, Batch 776 / 1350, Loss: 0.011570464819669724\n",
            "Epoch 4, Batch 777 / 1350, Loss: 0.2616076171398163\n",
            "Epoch 4, Batch 778 / 1350, Loss: 0.11659549921751022\n",
            "Epoch 4, Batch 779 / 1350, Loss: 0.5149364471435547\n",
            "Epoch 4, Batch 780 / 1350, Loss: 0.06947793066501617\n",
            "Epoch 4, Batch 781 / 1350, Loss: 0.0861736461520195\n",
            "Epoch 4, Batch 782 / 1350, Loss: 0.08680494874715805\n",
            "Epoch 4, Batch 783 / 1350, Loss: 0.36640480160713196\n",
            "Epoch 4, Batch 784 / 1350, Loss: 0.3438645303249359\n",
            "Epoch 4, Batch 785 / 1350, Loss: 0.0922708809375763\n",
            "Epoch 4, Batch 786 / 1350, Loss: 0.6082462072372437\n",
            "Epoch 4, Batch 787 / 1350, Loss: 0.7410904169082642\n",
            "Epoch 4, Batch 788 / 1350, Loss: 0.04423198103904724\n",
            "Epoch 4, Batch 789 / 1350, Loss: 0.06696899235248566\n",
            "Epoch 4, Batch 790 / 1350, Loss: 0.09256455302238464\n",
            "Epoch 4, Batch 791 / 1350, Loss: 0.02535405382514\n",
            "Epoch 4, Batch 792 / 1350, Loss: 0.10690297186374664\n",
            "Epoch 4, Batch 793 / 1350, Loss: 0.21526473760604858\n",
            "Epoch 4, Batch 794 / 1350, Loss: 0.14603720605373383\n",
            "Epoch 4, Batch 795 / 1350, Loss: 0.34637123346328735\n",
            "Epoch 4, Batch 796 / 1350, Loss: 0.03716844320297241\n",
            "Epoch 4, Batch 797 / 1350, Loss: 0.6597902178764343\n",
            "Epoch 4, Batch 798 / 1350, Loss: 0.10788580030202866\n",
            "Epoch 4, Batch 799 / 1350, Loss: 0.07601234316825867\n",
            "Epoch 4, Batch 800 / 1350, Loss: 0.013409638777375221\n",
            "Epoch 4, Batch 801 / 1350, Loss: 0.02004983276128769\n",
            "Epoch 4, Batch 802 / 1350, Loss: 0.07692694664001465\n",
            "Epoch 4, Batch 803 / 1350, Loss: 0.09292684495449066\n",
            "Epoch 4, Batch 804 / 1350, Loss: 0.06496134400367737\n",
            "Epoch 4, Batch 805 / 1350, Loss: 0.016680430620908737\n",
            "Epoch 4, Batch 806 / 1350, Loss: 0.022181376814842224\n",
            "Epoch 4, Batch 807 / 1350, Loss: 0.10117314010858536\n",
            "Epoch 4, Batch 808 / 1350, Loss: 0.009245369583368301\n",
            "Epoch 4, Batch 809 / 1350, Loss: 0.057329289615154266\n",
            "Epoch 4, Batch 810 / 1350, Loss: 0.14386145770549774\n",
            "Epoch 4, Batch 811 / 1350, Loss: 0.06855542212724686\n",
            "Epoch 4, Batch 812 / 1350, Loss: 0.021062273532152176\n",
            "Epoch 4, Batch 813 / 1350, Loss: 1.0710183382034302\n",
            "Epoch 4, Batch 814 / 1350, Loss: 0.01278955489397049\n",
            "Epoch 4, Batch 815 / 1350, Loss: 0.007406413555145264\n",
            "Epoch 4, Batch 816 / 1350, Loss: 0.00732028391212225\n",
            "Epoch 4, Batch 817 / 1350, Loss: 0.058449432253837585\n",
            "Epoch 4, Batch 818 / 1350, Loss: 0.10655149817466736\n",
            "Epoch 4, Batch 819 / 1350, Loss: 0.05893354117870331\n",
            "Epoch 4, Batch 820 / 1350, Loss: 0.05639831721782684\n",
            "Epoch 4, Batch 821 / 1350, Loss: 0.8677564263343811\n",
            "Epoch 4, Batch 822 / 1350, Loss: 0.16706234216690063\n",
            "Epoch 4, Batch 823 / 1350, Loss: 0.09444117546081543\n",
            "Epoch 4, Batch 824 / 1350, Loss: 0.008806074038147926\n",
            "Epoch 4, Batch 825 / 1350, Loss: 0.18459069728851318\n",
            "Epoch 4, Batch 826 / 1350, Loss: 1.2775280475616455\n",
            "Epoch 4, Batch 827 / 1350, Loss: 0.010029209777712822\n",
            "Epoch 4, Batch 828 / 1350, Loss: 0.040126651525497437\n",
            "Epoch 4, Batch 829 / 1350, Loss: 0.3043592572212219\n",
            "Epoch 4, Batch 830 / 1350, Loss: 0.1449822187423706\n",
            "Epoch 4, Batch 831 / 1350, Loss: 0.41382306814193726\n",
            "Epoch 4, Batch 832 / 1350, Loss: 0.2776159346103668\n",
            "Epoch 4, Batch 833 / 1350, Loss: 0.5220672488212585\n",
            "Epoch 4, Batch 834 / 1350, Loss: 0.007141145411878824\n",
            "Epoch 4, Batch 835 / 1350, Loss: 0.35658925771713257\n",
            "Epoch 4, Batch 836 / 1350, Loss: 0.663725733757019\n",
            "Epoch 4, Batch 837 / 1350, Loss: 1.168861985206604\n",
            "Epoch 4, Batch 838 / 1350, Loss: 0.33648809790611267\n",
            "Epoch 4, Batch 839 / 1350, Loss: 0.06857232004404068\n",
            "Epoch 4, Batch 840 / 1350, Loss: 0.329422265291214\n",
            "Epoch 4, Batch 841 / 1350, Loss: 0.6413012146949768\n",
            "Epoch 4, Batch 842 / 1350, Loss: 0.02923302724957466\n",
            "Epoch 4, Batch 843 / 1350, Loss: 0.017739931121468544\n",
            "Epoch 4, Batch 844 / 1350, Loss: 0.17985209822654724\n",
            "Epoch 4, Batch 845 / 1350, Loss: 0.014806263148784637\n",
            "Epoch 4, Batch 846 / 1350, Loss: 0.022190110757946968\n",
            "Epoch 4, Batch 847 / 1350, Loss: 0.16036167740821838\n",
            "Epoch 4, Batch 848 / 1350, Loss: 0.40070289373397827\n",
            "Epoch 4, Batch 849 / 1350, Loss: 0.3439905047416687\n",
            "Epoch 4, Batch 850 / 1350, Loss: 0.04560002684593201\n",
            "Epoch 4, Batch 851 / 1350, Loss: 0.31002530455589294\n",
            "Epoch 4, Batch 852 / 1350, Loss: 0.15769128501415253\n",
            "Epoch 4, Batch 853 / 1350, Loss: 0.05146621912717819\n",
            "Epoch 4, Batch 854 / 1350, Loss: 0.10325556248426437\n",
            "Epoch 4, Batch 855 / 1350, Loss: 0.13195666670799255\n",
            "Epoch 4, Batch 856 / 1350, Loss: 0.06487224996089935\n",
            "Epoch 4, Batch 857 / 1350, Loss: 0.013048633933067322\n",
            "Epoch 4, Batch 858 / 1350, Loss: 0.1321261078119278\n",
            "Epoch 4, Batch 859 / 1350, Loss: 0.12422940135002136\n",
            "Epoch 4, Batch 860 / 1350, Loss: 0.021113986149430275\n",
            "Epoch 4, Batch 861 / 1350, Loss: 0.6589500904083252\n",
            "Epoch 4, Batch 862 / 1350, Loss: 0.11629308760166168\n",
            "Epoch 4, Batch 863 / 1350, Loss: 0.025394458323717117\n",
            "Epoch 4, Batch 864 / 1350, Loss: 0.030065074563026428\n",
            "Epoch 4, Batch 865 / 1350, Loss: 0.16349287331104279\n",
            "Epoch 4, Batch 866 / 1350, Loss: 0.05081632733345032\n",
            "Epoch 4, Batch 867 / 1350, Loss: 0.054777130484580994\n",
            "Epoch 4, Batch 868 / 1350, Loss: 0.12052641808986664\n",
            "Epoch 4, Batch 869 / 1350, Loss: 0.01647818461060524\n",
            "Epoch 4, Batch 870 / 1350, Loss: 0.04220321401953697\n",
            "Epoch 4, Batch 871 / 1350, Loss: 0.2375212162733078\n",
            "Epoch 4, Batch 872 / 1350, Loss: 0.02294030599296093\n",
            "Epoch 4, Batch 873 / 1350, Loss: 0.057434722781181335\n",
            "Epoch 4, Batch 874 / 1350, Loss: 0.19466999173164368\n",
            "Epoch 4, Batch 875 / 1350, Loss: 0.030915461480617523\n",
            "Epoch 4, Batch 876 / 1350, Loss: 0.08340922743082047\n",
            "Epoch 4, Batch 877 / 1350, Loss: 0.030623406171798706\n",
            "Epoch 4, Batch 878 / 1350, Loss: 0.018577346578240395\n",
            "Epoch 4, Batch 879 / 1350, Loss: 0.7792776226997375\n",
            "Epoch 4, Batch 880 / 1350, Loss: 0.09114573150873184\n",
            "Epoch 4, Batch 881 / 1350, Loss: 0.04092995449900627\n",
            "Epoch 4, Batch 882 / 1350, Loss: 0.09723680466413498\n",
            "Epoch 4, Batch 883 / 1350, Loss: 0.017895709723234177\n",
            "Epoch 4, Batch 884 / 1350, Loss: 0.24053433537483215\n",
            "Epoch 4, Batch 885 / 1350, Loss: 0.27563974261283875\n",
            "Epoch 4, Batch 886 / 1350, Loss: 0.09641842544078827\n",
            "Epoch 4, Batch 887 / 1350, Loss: 0.18469849228858948\n",
            "Epoch 4, Batch 888 / 1350, Loss: 0.4986545741558075\n",
            "Epoch 4, Batch 889 / 1350, Loss: 0.05528278648853302\n",
            "Epoch 4, Batch 890 / 1350, Loss: 0.588201105594635\n",
            "Epoch 4, Batch 891 / 1350, Loss: 0.015436045825481415\n",
            "Epoch 4, Batch 892 / 1350, Loss: 0.13702327013015747\n",
            "Epoch 4, Batch 893 / 1350, Loss: 0.1315089911222458\n",
            "Epoch 4, Batch 894 / 1350, Loss: 0.014200614765286446\n",
            "Epoch 4, Batch 895 / 1350, Loss: 0.15307451784610748\n",
            "Epoch 4, Batch 896 / 1350, Loss: 0.6010417938232422\n",
            "Epoch 4, Batch 897 / 1350, Loss: 0.03725055232644081\n",
            "Epoch 4, Batch 898 / 1350, Loss: 1.2551647424697876\n",
            "Epoch 4, Batch 899 / 1350, Loss: 0.04136280715465546\n",
            "Epoch 4, Batch 900 / 1350, Loss: 0.014545302838087082\n",
            "Epoch 4, Batch 901 / 1350, Loss: 0.014237234368920326\n",
            "Epoch 4, Batch 902 / 1350, Loss: 0.061342038214206696\n",
            "Epoch 4, Batch 903 / 1350, Loss: 0.1356826275587082\n",
            "Epoch 4, Batch 904 / 1350, Loss: 0.1973593384027481\n",
            "Epoch 4, Batch 905 / 1350, Loss: 0.10338550806045532\n",
            "Epoch 4, Batch 906 / 1350, Loss: 0.2690869867801666\n",
            "Epoch 4, Batch 907 / 1350, Loss: 0.04330676421523094\n",
            "Epoch 4, Batch 908 / 1350, Loss: 0.02251516841351986\n",
            "Epoch 4, Batch 909 / 1350, Loss: 0.11645206063985825\n",
            "Epoch 4, Batch 910 / 1350, Loss: 0.009901905432343483\n",
            "Epoch 4, Batch 911 / 1350, Loss: 0.07579514384269714\n",
            "Epoch 4, Batch 912 / 1350, Loss: 0.19402414560317993\n",
            "Epoch 4, Batch 913 / 1350, Loss: 0.026358885690569878\n",
            "Epoch 4, Batch 914 / 1350, Loss: 0.012945596128702164\n",
            "Epoch 4, Batch 915 / 1350, Loss: 0.07208231836557388\n",
            "Epoch 4, Batch 916 / 1350, Loss: 0.0485738143324852\n",
            "Epoch 4, Batch 917 / 1350, Loss: 1.3102113008499146\n",
            "Epoch 4, Batch 918 / 1350, Loss: 0.07966690510511398\n",
            "Epoch 4, Batch 919 / 1350, Loss: 0.006922626867890358\n",
            "Epoch 4, Batch 920 / 1350, Loss: 0.018864629790186882\n",
            "Epoch 4, Batch 921 / 1350, Loss: 0.252545565366745\n",
            "Epoch 4, Batch 922 / 1350, Loss: 0.012117094360291958\n",
            "Epoch 4, Batch 923 / 1350, Loss: 0.3595212399959564\n",
            "Epoch 4, Batch 924 / 1350, Loss: 1.1249960660934448\n",
            "Epoch 4, Batch 925 / 1350, Loss: 0.278729110956192\n",
            "Epoch 4, Batch 926 / 1350, Loss: 0.03869013860821724\n",
            "Epoch 4, Batch 927 / 1350, Loss: 0.04021254926919937\n",
            "Epoch 4, Batch 928 / 1350, Loss: 0.035007543861866\n",
            "Epoch 4, Batch 929 / 1350, Loss: 0.012870223261415958\n",
            "Epoch 4, Batch 930 / 1350, Loss: 0.01016024500131607\n",
            "Epoch 4, Batch 931 / 1350, Loss: 0.01859530434012413\n",
            "Epoch 4, Batch 932 / 1350, Loss: 0.6537001729011536\n",
            "Epoch 4, Batch 933 / 1350, Loss: 0.04264670982956886\n",
            "Epoch 4, Batch 934 / 1350, Loss: 0.014292484149336815\n",
            "Epoch 4, Batch 935 / 1350, Loss: 0.14094266295433044\n",
            "Epoch 4, Batch 936 / 1350, Loss: 0.11381170153617859\n",
            "Epoch 4, Batch 937 / 1350, Loss: 0.06554163992404938\n",
            "Epoch 4, Batch 938 / 1350, Loss: 0.1555282026529312\n",
            "Epoch 4, Batch 939 / 1350, Loss: 0.12768492102622986\n",
            "Epoch 4, Batch 940 / 1350, Loss: 0.03463996574282646\n",
            "Epoch 4, Batch 941 / 1350, Loss: 0.021467849612236023\n",
            "Epoch 4, Batch 942 / 1350, Loss: 0.04028915613889694\n",
            "Epoch 4, Batch 943 / 1350, Loss: 0.9345290064811707\n",
            "Epoch 4, Batch 944 / 1350, Loss: 0.1453472077846527\n",
            "Epoch 4, Batch 945 / 1350, Loss: 0.017845451831817627\n",
            "Epoch 4, Batch 946 / 1350, Loss: 0.0126786008477211\n",
            "Epoch 4, Batch 947 / 1350, Loss: 0.02186691015958786\n",
            "Epoch 4, Batch 948 / 1350, Loss: 0.2869093418121338\n",
            "Epoch 4, Batch 949 / 1350, Loss: 0.17400680482387543\n",
            "Epoch 4, Batch 950 / 1350, Loss: 0.021364863961935043\n",
            "Epoch 4, Batch 951 / 1350, Loss: 0.04190050810575485\n",
            "Epoch 4, Batch 952 / 1350, Loss: 0.01640099100768566\n",
            "Epoch 4, Batch 953 / 1350, Loss: 1.359448790550232\n",
            "Epoch 4, Batch 954 / 1350, Loss: 0.1909511536359787\n",
            "Epoch 4, Batch 955 / 1350, Loss: 0.06142527610063553\n",
            "Epoch 4, Batch 956 / 1350, Loss: 0.01317922305315733\n",
            "Epoch 4, Batch 957 / 1350, Loss: 0.031872864812612534\n",
            "Epoch 4, Batch 958 / 1350, Loss: 0.11670076847076416\n",
            "Epoch 4, Batch 959 / 1350, Loss: 0.012293992564082146\n",
            "Epoch 4, Batch 960 / 1350, Loss: 0.2129141241312027\n",
            "Epoch 4, Batch 961 / 1350, Loss: 0.0872519388794899\n",
            "Epoch 4, Batch 962 / 1350, Loss: 1.0922939777374268\n",
            "Epoch 4, Batch 963 / 1350, Loss: 1.3094524145126343\n",
            "Epoch 4, Batch 964 / 1350, Loss: 0.05926230549812317\n",
            "Epoch 4, Batch 965 / 1350, Loss: 0.07980392873287201\n",
            "Epoch 4, Batch 966 / 1350, Loss: 0.3560355305671692\n",
            "Epoch 4, Batch 967 / 1350, Loss: 0.20366151630878448\n",
            "Epoch 4, Batch 968 / 1350, Loss: 0.017216894775629044\n",
            "Epoch 4, Batch 969 / 1350, Loss: 0.05098382383584976\n",
            "Epoch 4, Batch 970 / 1350, Loss: 0.24545402824878693\n",
            "Epoch 4, Batch 971 / 1350, Loss: 0.6458320021629333\n",
            "Epoch 4, Batch 972 / 1350, Loss: 0.21952703595161438\n",
            "Epoch 4, Batch 973 / 1350, Loss: 0.015996821224689484\n",
            "Epoch 4, Batch 974 / 1350, Loss: 0.7315241098403931\n",
            "Epoch 4, Batch 975 / 1350, Loss: 0.21034350991249084\n",
            "Epoch 4, Batch 976 / 1350, Loss: 0.056199587881565094\n",
            "Epoch 4, Batch 977 / 1350, Loss: 0.6983931064605713\n",
            "Epoch 4, Batch 978 / 1350, Loss: 0.052514102309942245\n",
            "Epoch 4, Batch 979 / 1350, Loss: 0.07612687349319458\n",
            "Epoch 4, Batch 980 / 1350, Loss: 0.1251489520072937\n",
            "Epoch 4, Batch 981 / 1350, Loss: 0.03430189937353134\n",
            "Epoch 4, Batch 982 / 1350, Loss: 0.051690421998500824\n",
            "Epoch 4, Batch 983 / 1350, Loss: 0.46738073229789734\n",
            "Epoch 4, Batch 984 / 1350, Loss: 0.4890761077404022\n",
            "Epoch 4, Batch 985 / 1350, Loss: 0.11614024639129639\n",
            "Epoch 4, Batch 986 / 1350, Loss: 0.0206710584461689\n",
            "Epoch 4, Batch 987 / 1350, Loss: 0.16589361429214478\n",
            "Epoch 4, Batch 988 / 1350, Loss: 0.307833731174469\n",
            "Epoch 4, Batch 989 / 1350, Loss: 0.06549623608589172\n",
            "Epoch 4, Batch 990 / 1350, Loss: 0.434641569852829\n",
            "Epoch 4, Batch 991 / 1350, Loss: 0.19840867817401886\n",
            "Epoch 4, Batch 992 / 1350, Loss: 0.528825581073761\n",
            "Epoch 4, Batch 993 / 1350, Loss: 0.12602156400680542\n",
            "Epoch 4, Batch 994 / 1350, Loss: 0.343585729598999\n",
            "Epoch 4, Batch 995 / 1350, Loss: 0.09208205342292786\n",
            "Epoch 4, Batch 996 / 1350, Loss: 0.20786422491073608\n",
            "Epoch 4, Batch 997 / 1350, Loss: 0.05360347032546997\n",
            "Epoch 4, Batch 998 / 1350, Loss: 0.3680438995361328\n",
            "Epoch 4, Batch 999 / 1350, Loss: 0.11575169861316681\n",
            "Epoch 4, Batch 1000 / 1350, Loss: 0.42532575130462646\n",
            "Epoch 4, Batch 1001 / 1350, Loss: 0.3497971296310425\n",
            "Epoch 4, Batch 1002 / 1350, Loss: 0.2830597758293152\n",
            "Epoch 4, Batch 1003 / 1350, Loss: 0.1663522869348526\n",
            "Epoch 4, Batch 1004 / 1350, Loss: 0.05860736966133118\n",
            "Epoch 4, Batch 1005 / 1350, Loss: 0.08908110857009888\n",
            "Epoch 4, Batch 1006 / 1350, Loss: 0.010024487972259521\n",
            "Epoch 4, Batch 1007 / 1350, Loss: 0.07663293927907944\n",
            "Epoch 4, Batch 1008 / 1350, Loss: 0.032243892550468445\n",
            "Epoch 4, Batch 1009 / 1350, Loss: 0.05768979713320732\n",
            "Epoch 4, Batch 1010 / 1350, Loss: 0.019801858812570572\n",
            "Epoch 4, Batch 1011 / 1350, Loss: 0.08758915960788727\n",
            "Epoch 4, Batch 1012 / 1350, Loss: 0.16493342816829681\n",
            "Epoch 4, Batch 1013 / 1350, Loss: 0.21465274691581726\n",
            "Epoch 4, Batch 1014 / 1350, Loss: 0.3671450614929199\n",
            "Epoch 4, Batch 1015 / 1350, Loss: 0.22284875810146332\n",
            "Epoch 4, Batch 1016 / 1350, Loss: 0.4167554974555969\n",
            "Epoch 4, Batch 1017 / 1350, Loss: 0.05342312902212143\n",
            "Epoch 4, Batch 1018 / 1350, Loss: 0.022234918549656868\n",
            "Epoch 4, Batch 1019 / 1350, Loss: 0.12203998863697052\n",
            "Epoch 4, Batch 1020 / 1350, Loss: 0.1638418734073639\n",
            "Epoch 4, Batch 1021 / 1350, Loss: 0.01790187880396843\n",
            "Epoch 4, Batch 1022 / 1350, Loss: 0.0941786915063858\n",
            "Epoch 4, Batch 1023 / 1350, Loss: 0.6523183584213257\n",
            "Epoch 4, Batch 1024 / 1350, Loss: 0.9132027626037598\n",
            "Epoch 4, Batch 1025 / 1350, Loss: 0.015210714191198349\n",
            "Epoch 4, Batch 1026 / 1350, Loss: 0.034447818994522095\n",
            "Epoch 4, Batch 1027 / 1350, Loss: 0.11595053970813751\n",
            "Epoch 4, Batch 1028 / 1350, Loss: 0.22655637562274933\n",
            "Epoch 4, Batch 1029 / 1350, Loss: 0.07397877424955368\n",
            "Epoch 4, Batch 1030 / 1350, Loss: 0.21362219750881195\n",
            "Epoch 4, Batch 1031 / 1350, Loss: 0.05941738933324814\n",
            "Epoch 4, Batch 1032 / 1350, Loss: 0.01654234156012535\n",
            "Epoch 4, Batch 1033 / 1350, Loss: 0.014243882149457932\n",
            "Epoch 4, Batch 1034 / 1350, Loss: 1.459088921546936\n",
            "Epoch 4, Batch 1035 / 1350, Loss: 0.02037321776151657\n",
            "Epoch 4, Batch 1036 / 1350, Loss: 0.022293822839856148\n",
            "Epoch 4, Batch 1037 / 1350, Loss: 0.058682117611169815\n",
            "Epoch 4, Batch 1038 / 1350, Loss: 0.03166714310646057\n",
            "Epoch 4, Batch 1039 / 1350, Loss: 0.06591469794511795\n",
            "Epoch 4, Batch 1040 / 1350, Loss: 0.04785868898034096\n",
            "Epoch 4, Batch 1041 / 1350, Loss: 0.5478547215461731\n",
            "Epoch 4, Batch 1042 / 1350, Loss: 0.5734677314758301\n",
            "Epoch 4, Batch 1043 / 1350, Loss: 0.25633522868156433\n",
            "Epoch 4, Batch 1044 / 1350, Loss: 1.2218962907791138\n",
            "Epoch 4, Batch 1045 / 1350, Loss: 0.28020501136779785\n",
            "Epoch 4, Batch 1046 / 1350, Loss: 0.8230413794517517\n",
            "Epoch 4, Batch 1047 / 1350, Loss: 0.173799529671669\n",
            "Epoch 4, Batch 1048 / 1350, Loss: 0.06155604124069214\n",
            "Epoch 4, Batch 1049 / 1350, Loss: 0.026751641184091568\n",
            "Epoch 4, Batch 1050 / 1350, Loss: 0.031425051391124725\n",
            "Epoch 4, Batch 1051 / 1350, Loss: 0.2780184745788574\n",
            "Epoch 4, Batch 1052 / 1350, Loss: 1.0824315547943115\n",
            "Epoch 4, Batch 1053 / 1350, Loss: 0.2375628650188446\n",
            "Epoch 4, Batch 1054 / 1350, Loss: 0.08834847807884216\n",
            "Epoch 4, Batch 1055 / 1350, Loss: 0.007326970808207989\n",
            "Epoch 4, Batch 1056 / 1350, Loss: 0.4119815528392792\n",
            "Epoch 4, Batch 1057 / 1350, Loss: 0.03381803631782532\n",
            "Epoch 4, Batch 1058 / 1350, Loss: 0.34338492155075073\n",
            "Epoch 4, Batch 1059 / 1350, Loss: 0.2658764123916626\n",
            "Epoch 4, Batch 1060 / 1350, Loss: 0.027062825858592987\n",
            "Epoch 4, Batch 1061 / 1350, Loss: 0.06280078738927841\n",
            "Epoch 4, Batch 1062 / 1350, Loss: 0.050724878907203674\n",
            "Epoch 4, Batch 1063 / 1350, Loss: 0.06570358574390411\n",
            "Epoch 4, Batch 1064 / 1350, Loss: 0.07373581826686859\n",
            "Epoch 4, Batch 1065 / 1350, Loss: 0.13917630910873413\n",
            "Epoch 4, Batch 1066 / 1350, Loss: 0.016684848815202713\n",
            "Epoch 4, Batch 1067 / 1350, Loss: 0.029865669086575508\n",
            "Epoch 4, Batch 1068 / 1350, Loss: 0.025280945003032684\n",
            "Epoch 4, Batch 1069 / 1350, Loss: 0.03209506347775459\n",
            "Epoch 4, Batch 1070 / 1350, Loss: 0.24321314692497253\n",
            "Epoch 4, Batch 1071 / 1350, Loss: 0.027379753068089485\n",
            "Epoch 4, Batch 1072 / 1350, Loss: 0.042088449001312256\n",
            "Epoch 4, Batch 1073 / 1350, Loss: 0.10206437855958939\n",
            "Epoch 4, Batch 1074 / 1350, Loss: 0.04535315930843353\n",
            "Epoch 4, Batch 1075 / 1350, Loss: 0.024382872506976128\n",
            "Epoch 4, Batch 1076 / 1350, Loss: 0.4850787818431854\n",
            "Epoch 4, Batch 1077 / 1350, Loss: 0.020502274855971336\n",
            "Epoch 4, Batch 1078 / 1350, Loss: 0.6205788254737854\n",
            "Epoch 4, Batch 1079 / 1350, Loss: 0.2299676388502121\n",
            "Epoch 4, Batch 1080 / 1350, Loss: 0.3172564208507538\n",
            "Epoch 4, Batch 1081 / 1350, Loss: 0.14619669318199158\n",
            "Epoch 4, Batch 1082 / 1350, Loss: 0.022290071472525597\n",
            "Epoch 4, Batch 1083 / 1350, Loss: 0.6420128345489502\n",
            "Epoch 4, Batch 1084 / 1350, Loss: 0.022584008052945137\n",
            "Epoch 4, Batch 1085 / 1350, Loss: 0.031022071838378906\n",
            "Epoch 4, Batch 1086 / 1350, Loss: 0.18076860904693604\n",
            "Epoch 4, Batch 1087 / 1350, Loss: 0.08264321833848953\n",
            "Epoch 4, Batch 1088 / 1350, Loss: 0.08477899432182312\n",
            "Epoch 4, Batch 1089 / 1350, Loss: 0.07214085012674332\n",
            "Epoch 4, Batch 1090 / 1350, Loss: 0.25190410017967224\n",
            "Epoch 4, Batch 1091 / 1350, Loss: 0.4270368218421936\n",
            "Epoch 4, Batch 1092 / 1350, Loss: 0.12840506434440613\n",
            "Epoch 4, Batch 1093 / 1350, Loss: 0.018614158034324646\n",
            "Epoch 4, Batch 1094 / 1350, Loss: 0.0998547151684761\n",
            "Epoch 4, Batch 1095 / 1350, Loss: 0.022264959290623665\n",
            "Epoch 4, Batch 1096 / 1350, Loss: 0.29396191239356995\n",
            "Epoch 4, Batch 1097 / 1350, Loss: 0.5951306819915771\n",
            "Epoch 4, Batch 1098 / 1350, Loss: 0.2941654920578003\n",
            "Epoch 4, Batch 1099 / 1350, Loss: 0.018928658217191696\n",
            "Epoch 4, Batch 1100 / 1350, Loss: 0.6021124720573425\n",
            "Epoch 4, Batch 1101 / 1350, Loss: 0.031687989830970764\n",
            "Epoch 4, Batch 1102 / 1350, Loss: 0.059810589998960495\n",
            "Epoch 4, Batch 1103 / 1350, Loss: 0.1460007280111313\n",
            "Epoch 4, Batch 1104 / 1350, Loss: 0.26394519209861755\n",
            "Epoch 4, Batch 1105 / 1350, Loss: 0.035362325608730316\n",
            "Epoch 4, Batch 1106 / 1350, Loss: 0.01581648737192154\n",
            "Epoch 4, Batch 1107 / 1350, Loss: 0.050647154450416565\n",
            "Epoch 4, Batch 1108 / 1350, Loss: 0.0234304778277874\n",
            "Epoch 4, Batch 1109 / 1350, Loss: 0.008184443227946758\n",
            "Epoch 4, Batch 1110 / 1350, Loss: 0.012133438140153885\n",
            "Epoch 4, Batch 1111 / 1350, Loss: 0.1533820629119873\n",
            "Epoch 4, Batch 1112 / 1350, Loss: 0.02090071141719818\n",
            "Epoch 4, Batch 1113 / 1350, Loss: 0.009968087077140808\n",
            "Epoch 4, Batch 1114 / 1350, Loss: 0.012178866192698479\n",
            "Epoch 4, Batch 1115 / 1350, Loss: 0.024956198409199715\n",
            "Epoch 4, Batch 1116 / 1350, Loss: 0.08774355053901672\n",
            "Epoch 4, Batch 1117 / 1350, Loss: 0.02471952699124813\n",
            "Epoch 4, Batch 1118 / 1350, Loss: 0.05258702114224434\n",
            "Epoch 4, Batch 1119 / 1350, Loss: 0.011587778106331825\n",
            "Epoch 4, Batch 1120 / 1350, Loss: 0.6131876111030579\n",
            "Epoch 4, Batch 1121 / 1350, Loss: 0.01401763129979372\n",
            "Epoch 4, Batch 1122 / 1350, Loss: 0.007294026203453541\n",
            "Epoch 4, Batch 1123 / 1350, Loss: 0.12907882034778595\n",
            "Epoch 4, Batch 1124 / 1350, Loss: 0.018513506278395653\n",
            "Epoch 4, Batch 1125 / 1350, Loss: 0.40502604842185974\n",
            "Epoch 4, Batch 1126 / 1350, Loss: 0.21513831615447998\n",
            "Epoch 4, Batch 1127 / 1350, Loss: 0.6723781824111938\n",
            "Epoch 4, Batch 1128 / 1350, Loss: 0.34927430748939514\n",
            "Epoch 4, Batch 1129 / 1350, Loss: 0.07833271473646164\n",
            "Epoch 4, Batch 1130 / 1350, Loss: 0.158589705824852\n",
            "Epoch 4, Batch 1131 / 1350, Loss: 1.1625148057937622\n",
            "Epoch 4, Batch 1132 / 1350, Loss: 0.15508556365966797\n",
            "Epoch 4, Batch 1133 / 1350, Loss: 0.01565493457019329\n",
            "Epoch 4, Batch 1134 / 1350, Loss: 0.027896512299776077\n",
            "Epoch 4, Batch 1135 / 1350, Loss: 0.03930787369608879\n",
            "Epoch 4, Batch 1136 / 1350, Loss: 0.0209469273686409\n",
            "Epoch 4, Batch 1137 / 1350, Loss: 0.023038798943161964\n",
            "Epoch 4, Batch 1138 / 1350, Loss: 0.025274019688367844\n",
            "Epoch 4, Batch 1139 / 1350, Loss: 0.3402385413646698\n",
            "Epoch 4, Batch 1140 / 1350, Loss: 0.008421778678894043\n",
            "Epoch 4, Batch 1141 / 1350, Loss: 0.017650453373789787\n",
            "Epoch 4, Batch 1142 / 1350, Loss: 0.07686872035264969\n",
            "Epoch 4, Batch 1143 / 1350, Loss: 0.3363420367240906\n",
            "Epoch 4, Batch 1144 / 1350, Loss: 0.018414929509162903\n",
            "Epoch 4, Batch 1145 / 1350, Loss: 0.09884445369243622\n",
            "Epoch 4, Batch 1146 / 1350, Loss: 0.010816262103617191\n",
            "Epoch 4, Batch 1147 / 1350, Loss: 1.054192304611206\n",
            "Epoch 4, Batch 1148 / 1350, Loss: 0.006836428306996822\n",
            "Epoch 4, Batch 1149 / 1350, Loss: 0.38631200790405273\n",
            "Epoch 4, Batch 1150 / 1350, Loss: 0.23134109377861023\n",
            "Epoch 4, Batch 1151 / 1350, Loss: 0.041093457490205765\n",
            "Epoch 4, Batch 1152 / 1350, Loss: 0.06435951590538025\n",
            "Epoch 4, Batch 1153 / 1350, Loss: 0.17329487204551697\n",
            "Epoch 4, Batch 1154 / 1350, Loss: 0.0905778706073761\n",
            "Epoch 4, Batch 1155 / 1350, Loss: 0.31789299845695496\n",
            "Epoch 4, Batch 1156 / 1350, Loss: 0.06545150279998779\n",
            "Epoch 4, Batch 1157 / 1350, Loss: 0.1323845535516739\n",
            "Epoch 4, Batch 1158 / 1350, Loss: 0.5481382608413696\n",
            "Epoch 4, Batch 1159 / 1350, Loss: 0.23602281510829926\n",
            "Epoch 4, Batch 1160 / 1350, Loss: 0.015873972326517105\n",
            "Epoch 4, Batch 1161 / 1350, Loss: 0.6365692019462585\n",
            "Epoch 4, Batch 1162 / 1350, Loss: 0.029803860932588577\n",
            "Epoch 4, Batch 1163 / 1350, Loss: 0.6579124927520752\n",
            "Epoch 4, Batch 1164 / 1350, Loss: 0.03760288655757904\n",
            "Epoch 4, Batch 1165 / 1350, Loss: 0.9737504720687866\n",
            "Epoch 4, Batch 1166 / 1350, Loss: 0.01404540054500103\n",
            "Epoch 4, Batch 1167 / 1350, Loss: 0.04584606736898422\n",
            "Epoch 4, Batch 1168 / 1350, Loss: 0.28897833824157715\n",
            "Epoch 4, Batch 1169 / 1350, Loss: 0.6959377527236938\n",
            "Epoch 4, Batch 1170 / 1350, Loss: 0.3690868318080902\n",
            "Epoch 4, Batch 1171 / 1350, Loss: 0.6707990169525146\n",
            "Epoch 4, Batch 1172 / 1350, Loss: 0.12304837256669998\n",
            "Epoch 4, Batch 1173 / 1350, Loss: 0.04961533471941948\n",
            "Epoch 4, Batch 1174 / 1350, Loss: 0.1833515167236328\n",
            "Epoch 4, Batch 1175 / 1350, Loss: 0.13615942001342773\n",
            "Epoch 4, Batch 1176 / 1350, Loss: 0.050222158432006836\n",
            "Epoch 4, Batch 1177 / 1350, Loss: 0.22017866373062134\n",
            "Epoch 4, Batch 1178 / 1350, Loss: 0.5478093028068542\n",
            "Epoch 4, Batch 1179 / 1350, Loss: 0.34923145174980164\n",
            "Epoch 4, Batch 1180 / 1350, Loss: 0.20992383360862732\n",
            "Epoch 4, Batch 1181 / 1350, Loss: 0.13757458329200745\n",
            "Epoch 4, Batch 1182 / 1350, Loss: 0.05043133720755577\n",
            "Epoch 4, Batch 1183 / 1350, Loss: 0.12380893528461456\n",
            "Epoch 4, Batch 1184 / 1350, Loss: 0.0631370022892952\n",
            "Epoch 4, Batch 1185 / 1350, Loss: 0.030220264568924904\n",
            "Epoch 4, Batch 1186 / 1350, Loss: 0.40747687220573425\n",
            "Epoch 4, Batch 1187 / 1350, Loss: 0.15387292206287384\n",
            "Epoch 4, Batch 1188 / 1350, Loss: 0.024808095768094063\n",
            "Epoch 4, Batch 1189 / 1350, Loss: 0.516878068447113\n",
            "Epoch 4, Batch 1190 / 1350, Loss: 0.08998982608318329\n",
            "Epoch 4, Batch 1191 / 1350, Loss: 0.7750055193901062\n",
            "Epoch 4, Batch 1192 / 1350, Loss: 0.4590860605239868\n",
            "Epoch 4, Batch 1193 / 1350, Loss: 0.12979023158550262\n",
            "Epoch 4, Batch 1194 / 1350, Loss: 0.07559015601873398\n",
            "Epoch 4, Batch 1195 / 1350, Loss: 0.06784892827272415\n",
            "Epoch 4, Batch 1196 / 1350, Loss: 0.07131561636924744\n",
            "Epoch 4, Batch 1197 / 1350, Loss: 0.125075101852417\n",
            "Epoch 4, Batch 1198 / 1350, Loss: 0.11944388598203659\n",
            "Epoch 4, Batch 1199 / 1350, Loss: 0.06371036171913147\n",
            "Epoch 4, Batch 1200 / 1350, Loss: 0.02746397629380226\n",
            "Epoch 4, Batch 1201 / 1350, Loss: 0.2771751880645752\n",
            "Epoch 4, Batch 1202 / 1350, Loss: 0.41226980090141296\n",
            "Epoch 4, Batch 1203 / 1350, Loss: 0.22103235125541687\n",
            "Epoch 4, Batch 1204 / 1350, Loss: 0.1693265438079834\n",
            "Epoch 4, Batch 1205 / 1350, Loss: 0.09484656155109406\n",
            "Epoch 4, Batch 1206 / 1350, Loss: 0.215703085064888\n",
            "Epoch 4, Batch 1207 / 1350, Loss: 0.05088125914335251\n",
            "Epoch 4, Batch 1208 / 1350, Loss: 0.13444802165031433\n",
            "Epoch 4, Batch 1209 / 1350, Loss: 0.0761672854423523\n",
            "Epoch 4, Batch 1210 / 1350, Loss: 0.13457992672920227\n",
            "Epoch 4, Batch 1211 / 1350, Loss: 0.4777933359146118\n",
            "Epoch 4, Batch 1212 / 1350, Loss: 0.008126217871904373\n",
            "Epoch 4, Batch 1213 / 1350, Loss: 0.018051378428936005\n",
            "Epoch 4, Batch 1214 / 1350, Loss: 0.0756118968129158\n",
            "Epoch 4, Batch 1215 / 1350, Loss: 0.5253886580467224\n",
            "Epoch 4, Batch 1216 / 1350, Loss: 0.05498460680246353\n",
            "Epoch 4, Batch 1217 / 1350, Loss: 0.0451643243432045\n",
            "Epoch 4, Batch 1218 / 1350, Loss: 0.016370827332139015\n",
            "Epoch 4, Batch 1219 / 1350, Loss: 0.09602053463459015\n",
            "Epoch 4, Batch 1220 / 1350, Loss: 0.028714323416352272\n",
            "Epoch 4, Batch 1221 / 1350, Loss: 0.012596366927027702\n",
            "Epoch 4, Batch 1222 / 1350, Loss: 0.30642372369766235\n",
            "Epoch 4, Batch 1223 / 1350, Loss: 0.07432739436626434\n",
            "Epoch 4, Batch 1224 / 1350, Loss: 0.11198645085096359\n",
            "Epoch 4, Batch 1225 / 1350, Loss: 0.26653754711151123\n",
            "Epoch 4, Batch 1226 / 1350, Loss: 0.042141612619161606\n",
            "Epoch 4, Batch 1227 / 1350, Loss: 0.005682495888322592\n",
            "Epoch 4, Batch 1228 / 1350, Loss: 0.41696804761886597\n",
            "Epoch 4, Batch 1229 / 1350, Loss: 0.11107267439365387\n",
            "Epoch 4, Batch 1230 / 1350, Loss: 0.22413086891174316\n",
            "Epoch 4, Batch 1231 / 1350, Loss: 0.009813232347369194\n",
            "Epoch 4, Batch 1232 / 1350, Loss: 0.46929222345352173\n",
            "Epoch 4, Batch 1233 / 1350, Loss: 0.944661021232605\n",
            "Epoch 4, Batch 1234 / 1350, Loss: 1.8756496906280518\n",
            "Epoch 4, Batch 1235 / 1350, Loss: 0.016750194132328033\n",
            "Epoch 4, Batch 1236 / 1350, Loss: 0.029065145179629326\n",
            "Epoch 4, Batch 1237 / 1350, Loss: 0.19301490485668182\n",
            "Epoch 4, Batch 1238 / 1350, Loss: 0.008120188489556313\n",
            "Epoch 4, Batch 1239 / 1350, Loss: 0.08481772243976593\n",
            "Epoch 4, Batch 1240 / 1350, Loss: 0.12292245030403137\n",
            "Epoch 4, Batch 1241 / 1350, Loss: 0.015344732441008091\n",
            "Epoch 4, Batch 1242 / 1350, Loss: 0.1771426498889923\n",
            "Epoch 4, Batch 1243 / 1350, Loss: 0.14300097525119781\n",
            "Epoch 4, Batch 1244 / 1350, Loss: 0.028184590861201286\n",
            "Epoch 4, Batch 1245 / 1350, Loss: 0.2863302528858185\n",
            "Epoch 4, Batch 1246 / 1350, Loss: 0.041171420365571976\n",
            "Epoch 4, Batch 1247 / 1350, Loss: 0.08893679082393646\n",
            "Epoch 4, Batch 1248 / 1350, Loss: 0.010261675342917442\n",
            "Epoch 4, Batch 1249 / 1350, Loss: 0.095330148935318\n",
            "Epoch 4, Batch 1250 / 1350, Loss: 0.016020789742469788\n",
            "Epoch 4, Batch 1251 / 1350, Loss: 0.11643169075250626\n",
            "Epoch 4, Batch 1252 / 1350, Loss: 0.20570823550224304\n",
            "Epoch 4, Batch 1253 / 1350, Loss: 0.07641962170600891\n",
            "Epoch 4, Batch 1254 / 1350, Loss: 0.21787546575069427\n",
            "Epoch 4, Batch 1255 / 1350, Loss: 0.5693475604057312\n",
            "Epoch 4, Batch 1256 / 1350, Loss: 0.025521613657474518\n",
            "Epoch 4, Batch 1257 / 1350, Loss: 0.266996294260025\n",
            "Epoch 4, Batch 1258 / 1350, Loss: 0.10667610168457031\n",
            "Epoch 4, Batch 1259 / 1350, Loss: 0.018091946840286255\n",
            "Epoch 4, Batch 1260 / 1350, Loss: 1.050484538078308\n",
            "Epoch 4, Batch 1261 / 1350, Loss: 0.10129845142364502\n",
            "Epoch 4, Batch 1262 / 1350, Loss: 0.01506797969341278\n",
            "Epoch 4, Batch 1263 / 1350, Loss: 0.011852549389004707\n",
            "Epoch 4, Batch 1264 / 1350, Loss: 0.2865065038204193\n",
            "Epoch 4, Batch 1265 / 1350, Loss: 0.08840558677911758\n",
            "Epoch 4, Batch 1266 / 1350, Loss: 0.03182176500558853\n",
            "Epoch 4, Batch 1267 / 1350, Loss: 0.23947614431381226\n",
            "Epoch 4, Batch 1268 / 1350, Loss: 0.19030147790908813\n",
            "Epoch 4, Batch 1269 / 1350, Loss: 0.01655985414981842\n",
            "Epoch 4, Batch 1270 / 1350, Loss: 0.7375577688217163\n",
            "Epoch 4, Batch 1271 / 1350, Loss: 0.010392319411039352\n",
            "Epoch 4, Batch 1272 / 1350, Loss: 0.01194843277335167\n",
            "Epoch 4, Batch 1273 / 1350, Loss: 0.15856704115867615\n",
            "Epoch 4, Batch 1274 / 1350, Loss: 0.479354590177536\n",
            "Epoch 4, Batch 1275 / 1350, Loss: 0.19926929473876953\n",
            "Epoch 4, Batch 1276 / 1350, Loss: 0.18472284078598022\n",
            "Epoch 4, Batch 1277 / 1350, Loss: 0.03733859211206436\n",
            "Epoch 4, Batch 1278 / 1350, Loss: 0.09727434813976288\n",
            "Epoch 4, Batch 1279 / 1350, Loss: 0.033758893609046936\n",
            "Epoch 4, Batch 1280 / 1350, Loss: 0.11627990007400513\n",
            "Epoch 4, Batch 1281 / 1350, Loss: 0.07697812467813492\n",
            "Epoch 4, Batch 1282 / 1350, Loss: 0.12437228858470917\n",
            "Epoch 4, Batch 1283 / 1350, Loss: 0.0068953754380345345\n",
            "Epoch 4, Batch 1284 / 1350, Loss: 0.009577919729053974\n",
            "Epoch 4, Batch 1285 / 1350, Loss: 0.026457015424966812\n",
            "Epoch 4, Batch 1286 / 1350, Loss: 1.178921103477478\n",
            "Epoch 4, Batch 1287 / 1350, Loss: 0.01817571371793747\n",
            "Epoch 4, Batch 1288 / 1350, Loss: 0.024525277316570282\n",
            "Epoch 4, Batch 1289 / 1350, Loss: 0.02010127156972885\n",
            "Epoch 4, Batch 1290 / 1350, Loss: 0.0728970468044281\n",
            "Epoch 4, Batch 1291 / 1350, Loss: 0.018655840307474136\n",
            "Epoch 4, Batch 1292 / 1350, Loss: 0.05580823868513107\n",
            "Epoch 4, Batch 1293 / 1350, Loss: 0.01715511456131935\n",
            "Epoch 4, Batch 1294 / 1350, Loss: 0.4625263512134552\n",
            "Epoch 4, Batch 1295 / 1350, Loss: 0.9455143809318542\n",
            "Epoch 4, Batch 1296 / 1350, Loss: 0.01604354754090309\n",
            "Epoch 4, Batch 1297 / 1350, Loss: 0.013567478395998478\n",
            "Epoch 4, Batch 1298 / 1350, Loss: 0.03494104743003845\n",
            "Epoch 4, Batch 1299 / 1350, Loss: 0.010086167603731155\n",
            "Epoch 4, Batch 1300 / 1350, Loss: 0.9919503331184387\n",
            "Epoch 4, Batch 1301 / 1350, Loss: 0.011307846754789352\n",
            "Epoch 4, Batch 1302 / 1350, Loss: 0.00919414684176445\n",
            "Epoch 4, Batch 1303 / 1350, Loss: 0.025924336165189743\n",
            "Epoch 4, Batch 1304 / 1350, Loss: 0.09118913114070892\n",
            "Epoch 4, Batch 1305 / 1350, Loss: 0.3740822374820709\n",
            "Epoch 4, Batch 1306 / 1350, Loss: 0.007882747799158096\n",
            "Epoch 4, Batch 1307 / 1350, Loss: 0.013762419112026691\n",
            "Epoch 4, Batch 1308 / 1350, Loss: 0.2820570170879364\n",
            "Epoch 4, Batch 1309 / 1350, Loss: 0.007469843607395887\n",
            "Epoch 4, Batch 1310 / 1350, Loss: 0.3766140639781952\n",
            "Epoch 4, Batch 1311 / 1350, Loss: 0.04510314390063286\n",
            "Epoch 4, Batch 1312 / 1350, Loss: 0.08805230259895325\n",
            "Epoch 4, Batch 1313 / 1350, Loss: 0.5628662109375\n",
            "Epoch 4, Batch 1314 / 1350, Loss: 0.010310614481568336\n",
            "Epoch 4, Batch 1315 / 1350, Loss: 0.19492043554782867\n",
            "Epoch 4, Batch 1316 / 1350, Loss: 0.3327704668045044\n",
            "Epoch 4, Batch 1317 / 1350, Loss: 0.19716095924377441\n",
            "Epoch 4, Batch 1318 / 1350, Loss: 0.03622808679938316\n",
            "Epoch 4, Batch 1319 / 1350, Loss: 0.11028240621089935\n",
            "Epoch 4, Batch 1320 / 1350, Loss: 0.05617405101656914\n",
            "Epoch 4, Batch 1321 / 1350, Loss: 0.24798421561717987\n",
            "Epoch 4, Batch 1322 / 1350, Loss: 0.015036340802907944\n",
            "Epoch 4, Batch 1323 / 1350, Loss: 0.08685251325368881\n",
            "Epoch 4, Batch 1324 / 1350, Loss: 0.35206708312034607\n",
            "Epoch 4, Batch 1325 / 1350, Loss: 0.028008121997117996\n",
            "Epoch 4, Batch 1326 / 1350, Loss: 0.051021985709667206\n",
            "Epoch 4, Batch 1327 / 1350, Loss: 0.010914662852883339\n",
            "Epoch 4, Batch 1328 / 1350, Loss: 0.6705992221832275\n",
            "Epoch 4, Batch 1329 / 1350, Loss: 0.009375009685754776\n",
            "Epoch 4, Batch 1330 / 1350, Loss: 0.7000252604484558\n",
            "Epoch 4, Batch 1331 / 1350, Loss: 0.016785362735390663\n",
            "Epoch 4, Batch 1332 / 1350, Loss: 0.3273637294769287\n",
            "Epoch 4, Batch 1333 / 1350, Loss: 0.05348748341202736\n",
            "Epoch 4, Batch 1334 / 1350, Loss: 0.38416606187820435\n",
            "Epoch 4, Batch 1335 / 1350, Loss: 0.4189775884151459\n",
            "Epoch 4, Batch 1336 / 1350, Loss: 0.020783986896276474\n",
            "Epoch 4, Batch 1337 / 1350, Loss: 0.2161739021539688\n",
            "Epoch 4, Batch 1338 / 1350, Loss: 0.13936369121074677\n",
            "Epoch 4, Batch 1339 / 1350, Loss: 1.1623718738555908\n",
            "Epoch 4, Batch 1340 / 1350, Loss: 0.048969872295856476\n",
            "Epoch 4, Batch 1341 / 1350, Loss: 0.12473317980766296\n",
            "Epoch 4, Batch 1342 / 1350, Loss: 0.15431709587574005\n",
            "Epoch 4, Batch 1343 / 1350, Loss: 0.05295107141137123\n",
            "Epoch 4, Batch 1344 / 1350, Loss: 0.09835871309041977\n",
            "Epoch 4, Batch 1345 / 1350, Loss: 0.13331840932369232\n",
            "Epoch 4, Batch 1346 / 1350, Loss: 0.12493878602981567\n",
            "Epoch 4, Batch 1347 / 1350, Loss: 0.3092397153377533\n",
            "Epoch 4, Batch 1348 / 1350, Loss: 0.02588106133043766\n",
            "Epoch 4, Batch 1349 / 1350, Loss: 0.01310013234615326\n",
            "Epoch 4, Batch 1350 / 1350, Loss: 0.020094044506549835\n",
            "Epoch 4, Loss: 0.18857269856319936, Accuracy: 0.9809153233277746, Auc: 0.9804981306702477, f1: 0.9732119635890767\n",
            "Epoch 4, Train Loss: 3.585537226201678, Validation Accuracy: 0.7907801418439716\n",
            "Epoch 5, Batch 1 / 1350, Loss: 0.03242780268192291\n",
            "Epoch 5, Batch 2 / 1350, Loss: 0.009116481989622116\n",
            "Epoch 5, Batch 3 / 1350, Loss: 0.4205377399921417\n",
            "Epoch 5, Batch 4 / 1350, Loss: 0.18900933861732483\n",
            "Epoch 5, Batch 5 / 1350, Loss: 0.6198803186416626\n",
            "Epoch 5, Batch 6 / 1350, Loss: 0.01907166838645935\n",
            "Epoch 5, Batch 7 / 1350, Loss: 0.011871077120304108\n",
            "Epoch 5, Batch 8 / 1350, Loss: 0.013285307213664055\n",
            "Epoch 5, Batch 9 / 1350, Loss: 0.06312838196754456\n",
            "Epoch 5, Batch 10 / 1350, Loss: 0.0468607023358345\n",
            "Epoch 5, Batch 11 / 1350, Loss: 0.028334615752100945\n",
            "Epoch 5, Batch 12 / 1350, Loss: 0.03677511215209961\n",
            "Epoch 5, Batch 13 / 1350, Loss: 0.010106615722179413\n",
            "Epoch 5, Batch 14 / 1350, Loss: 0.16374821960926056\n",
            "Epoch 5, Batch 15 / 1350, Loss: 0.015765666961669922\n",
            "Epoch 5, Batch 16 / 1350, Loss: 0.014578145928680897\n",
            "Epoch 5, Batch 17 / 1350, Loss: 0.006530070211738348\n",
            "Epoch 5, Batch 18 / 1350, Loss: 0.033649180084466934\n",
            "Epoch 5, Batch 19 / 1350, Loss: 0.13115710020065308\n",
            "Epoch 5, Batch 20 / 1350, Loss: 0.03789758309721947\n",
            "Epoch 5, Batch 21 / 1350, Loss: 0.09479280561208725\n",
            "Epoch 5, Batch 22 / 1350, Loss: 0.04607049375772476\n",
            "Epoch 5, Batch 23 / 1350, Loss: 0.01599421724677086\n",
            "Epoch 5, Batch 24 / 1350, Loss: 0.8732355833053589\n",
            "Epoch 5, Batch 25 / 1350, Loss: 0.009339572861790657\n",
            "Epoch 5, Batch 26 / 1350, Loss: 0.23256638646125793\n",
            "Epoch 5, Batch 27 / 1350, Loss: 0.005585710518062115\n",
            "Epoch 5, Batch 28 / 1350, Loss: 0.006064440589398146\n",
            "Epoch 5, Batch 29 / 1350, Loss: 0.008534586057066917\n",
            "Epoch 5, Batch 30 / 1350, Loss: 0.01784554123878479\n",
            "Epoch 5, Batch 31 / 1350, Loss: 0.005120214074850082\n",
            "Epoch 5, Batch 32 / 1350, Loss: 0.15356536209583282\n",
            "Epoch 5, Batch 33 / 1350, Loss: 0.13000822067260742\n",
            "Epoch 5, Batch 34 / 1350, Loss: 0.015382861718535423\n",
            "Epoch 5, Batch 35 / 1350, Loss: 0.005921764299273491\n",
            "Epoch 5, Batch 36 / 1350, Loss: 0.010463519021868706\n",
            "Epoch 5, Batch 37 / 1350, Loss: 0.43466445803642273\n",
            "Epoch 5, Batch 38 / 1350, Loss: 0.018045669421553612\n",
            "Epoch 5, Batch 39 / 1350, Loss: 0.3731447160243988\n",
            "Epoch 5, Batch 40 / 1350, Loss: 0.04625488072633743\n",
            "Epoch 5, Batch 41 / 1350, Loss: 0.03806348517537117\n",
            "Epoch 5, Batch 42 / 1350, Loss: 0.18413211405277252\n",
            "Epoch 5, Batch 43 / 1350, Loss: 0.007243815343827009\n",
            "Epoch 5, Batch 44 / 1350, Loss: 0.027155449613928795\n",
            "Epoch 5, Batch 45 / 1350, Loss: 0.005459507927298546\n",
            "Epoch 5, Batch 46 / 1350, Loss: 0.18880918622016907\n",
            "Epoch 5, Batch 47 / 1350, Loss: 0.005722552537918091\n",
            "Epoch 5, Batch 48 / 1350, Loss: 0.013826216571033001\n",
            "Epoch 5, Batch 49 / 1350, Loss: 0.0072227343916893005\n",
            "Epoch 5, Batch 50 / 1350, Loss: 0.0045422883704304695\n",
            "Epoch 5, Batch 51 / 1350, Loss: 0.3467242419719696\n",
            "Epoch 5, Batch 52 / 1350, Loss: 0.024492498487234116\n",
            "Epoch 5, Batch 53 / 1350, Loss: 0.006136011797934771\n",
            "Epoch 5, Batch 54 / 1350, Loss: 0.009203408844769001\n",
            "Epoch 5, Batch 55 / 1350, Loss: 0.04591420292854309\n",
            "Epoch 5, Batch 56 / 1350, Loss: 0.006679988466203213\n",
            "Epoch 5, Batch 57 / 1350, Loss: 0.028443317860364914\n",
            "Epoch 5, Batch 58 / 1350, Loss: 0.4941215217113495\n",
            "Epoch 5, Batch 59 / 1350, Loss: 0.020492926239967346\n",
            "Epoch 5, Batch 60 / 1350, Loss: 0.13047684729099274\n",
            "Epoch 5, Batch 61 / 1350, Loss: 0.02588639222085476\n",
            "Epoch 5, Batch 62 / 1350, Loss: 0.017181942239403725\n",
            "Epoch 5, Batch 63 / 1350, Loss: 0.05227245017886162\n",
            "Epoch 5, Batch 64 / 1350, Loss: 0.38080576062202454\n",
            "Epoch 5, Batch 65 / 1350, Loss: 0.004967221058905125\n",
            "Epoch 5, Batch 66 / 1350, Loss: 0.018374772742390633\n",
            "Epoch 5, Batch 67 / 1350, Loss: 0.011951119638979435\n",
            "Epoch 5, Batch 68 / 1350, Loss: 0.00549528282135725\n",
            "Epoch 5, Batch 69 / 1350, Loss: 0.02193695679306984\n",
            "Epoch 5, Batch 70 / 1350, Loss: 0.1750319004058838\n",
            "Epoch 5, Batch 71 / 1350, Loss: 0.06881283223628998\n",
            "Epoch 5, Batch 72 / 1350, Loss: 0.10691431164741516\n",
            "Epoch 5, Batch 73 / 1350, Loss: 0.01387865375727415\n",
            "Epoch 5, Batch 74 / 1350, Loss: 0.008535632863640785\n",
            "Epoch 5, Batch 75 / 1350, Loss: 0.005011012777686119\n",
            "Epoch 5, Batch 76 / 1350, Loss: 0.030159899964928627\n",
            "Epoch 5, Batch 77 / 1350, Loss: 0.6590157151222229\n",
            "Epoch 5, Batch 78 / 1350, Loss: 0.3387957513332367\n",
            "Epoch 5, Batch 79 / 1350, Loss: 0.013558770529925823\n",
            "Epoch 5, Batch 80 / 1350, Loss: 0.005121100228279829\n",
            "Epoch 5, Batch 81 / 1350, Loss: 0.2519732415676117\n",
            "Epoch 5, Batch 82 / 1350, Loss: 0.33953964710235596\n",
            "Epoch 5, Batch 83 / 1350, Loss: 0.040857285261154175\n",
            "Epoch 5, Batch 84 / 1350, Loss: 0.7202757000923157\n",
            "Epoch 5, Batch 85 / 1350, Loss: 0.1462092399597168\n",
            "Epoch 5, Batch 86 / 1350, Loss: 0.01611044630408287\n",
            "Epoch 5, Batch 87 / 1350, Loss: 0.018823103979229927\n",
            "Epoch 5, Batch 88 / 1350, Loss: 0.007281562313437462\n",
            "Epoch 5, Batch 89 / 1350, Loss: 0.1419677436351776\n",
            "Epoch 5, Batch 90 / 1350, Loss: 0.20366553962230682\n",
            "Epoch 5, Batch 91 / 1350, Loss: 0.015643566846847534\n",
            "Epoch 5, Batch 92 / 1350, Loss: 0.36515897512435913\n",
            "Epoch 5, Batch 93 / 1350, Loss: 0.07601900398731232\n",
            "Epoch 5, Batch 94 / 1350, Loss: 0.2096971720457077\n",
            "Epoch 5, Batch 95 / 1350, Loss: 0.018579786643385887\n",
            "Epoch 5, Batch 96 / 1350, Loss: 0.014611281454563141\n",
            "Epoch 5, Batch 97 / 1350, Loss: 0.016316208988428116\n",
            "Epoch 5, Batch 98 / 1350, Loss: 0.06242142990231514\n",
            "Epoch 5, Batch 99 / 1350, Loss: 0.08174744993448257\n",
            "Epoch 5, Batch 100 / 1350, Loss: 0.06338538974523544\n",
            "Epoch 5, Batch 101 / 1350, Loss: 0.02888907492160797\n",
            "Epoch 5, Batch 102 / 1350, Loss: 0.023017600178718567\n",
            "Epoch 5, Batch 103 / 1350, Loss: 0.6666340231895447\n",
            "Epoch 5, Batch 104 / 1350, Loss: 0.10345254838466644\n",
            "Epoch 5, Batch 105 / 1350, Loss: 0.009502382948994637\n",
            "Epoch 5, Batch 106 / 1350, Loss: 0.013738823123276234\n",
            "Epoch 5, Batch 107 / 1350, Loss: 0.3330058753490448\n",
            "Epoch 5, Batch 108 / 1350, Loss: 0.19991646707057953\n",
            "Epoch 5, Batch 109 / 1350, Loss: 0.006130852736532688\n",
            "Epoch 5, Batch 110 / 1350, Loss: 0.19229958951473236\n",
            "Epoch 5, Batch 111 / 1350, Loss: 0.0447256863117218\n",
            "Epoch 5, Batch 112 / 1350, Loss: 0.011951996944844723\n",
            "Epoch 5, Batch 113 / 1350, Loss: 0.02190898172557354\n",
            "Epoch 5, Batch 114 / 1350, Loss: 0.07020451128482819\n",
            "Epoch 5, Batch 115 / 1350, Loss: 0.0045779673382639885\n",
            "Epoch 5, Batch 116 / 1350, Loss: 0.12419843673706055\n",
            "Epoch 5, Batch 117 / 1350, Loss: 0.29419928789138794\n",
            "Epoch 5, Batch 118 / 1350, Loss: 0.01389493327587843\n",
            "Epoch 5, Batch 119 / 1350, Loss: 0.007791451644152403\n",
            "Epoch 5, Batch 120 / 1350, Loss: 0.0062394458800554276\n",
            "Epoch 5, Batch 121 / 1350, Loss: 0.057293493300676346\n",
            "Epoch 5, Batch 122 / 1350, Loss: 0.12796129286289215\n",
            "Epoch 5, Batch 123 / 1350, Loss: 0.0072213695384562016\n",
            "Epoch 5, Batch 124 / 1350, Loss: 0.007354808039963245\n",
            "Epoch 5, Batch 125 / 1350, Loss: 0.010385403409600258\n",
            "Epoch 5, Batch 126 / 1350, Loss: 0.009300625883042812\n",
            "Epoch 5, Batch 127 / 1350, Loss: 0.020567314699292183\n",
            "Epoch 5, Batch 128 / 1350, Loss: 0.027621570974588394\n",
            "Epoch 5, Batch 129 / 1350, Loss: 0.05501069873571396\n",
            "Epoch 5, Batch 130 / 1350, Loss: 0.00838486384600401\n",
            "Epoch 5, Batch 131 / 1350, Loss: 0.01183928269892931\n",
            "Epoch 5, Batch 132 / 1350, Loss: 0.16693007946014404\n",
            "Epoch 5, Batch 133 / 1350, Loss: 0.03799545764923096\n",
            "Epoch 5, Batch 134 / 1350, Loss: 0.010448524728417397\n",
            "Epoch 5, Batch 135 / 1350, Loss: 0.0077040838077664375\n",
            "Epoch 5, Batch 136 / 1350, Loss: 0.16225503385066986\n",
            "Epoch 5, Batch 137 / 1350, Loss: 0.14083285629749298\n",
            "Epoch 5, Batch 138 / 1350, Loss: 0.005605392158031464\n",
            "Epoch 5, Batch 139 / 1350, Loss: 0.5628309845924377\n",
            "Epoch 5, Batch 140 / 1350, Loss: 0.005565394647419453\n",
            "Epoch 5, Batch 141 / 1350, Loss: 0.0041473242454230785\n",
            "Epoch 5, Batch 142 / 1350, Loss: 0.005413060076534748\n",
            "Epoch 5, Batch 143 / 1350, Loss: 0.006183047778904438\n",
            "Epoch 5, Batch 144 / 1350, Loss: 0.0036586164496839046\n",
            "Epoch 5, Batch 145 / 1350, Loss: 0.005072598811239004\n",
            "Epoch 5, Batch 146 / 1350, Loss: 0.004435427952557802\n",
            "Epoch 5, Batch 147 / 1350, Loss: 0.00668324762955308\n",
            "Epoch 5, Batch 148 / 1350, Loss: 0.004862508736550808\n",
            "Epoch 5, Batch 149 / 1350, Loss: 0.006332940421998501\n",
            "Epoch 5, Batch 150 / 1350, Loss: 0.01836809329688549\n",
            "Epoch 5, Batch 151 / 1350, Loss: 0.027959631755948067\n",
            "Epoch 5, Batch 152 / 1350, Loss: 0.005492178723216057\n",
            "Epoch 5, Batch 153 / 1350, Loss: 0.005132577382028103\n",
            "Epoch 5, Batch 154 / 1350, Loss: 0.031586866825819016\n",
            "Epoch 5, Batch 155 / 1350, Loss: 0.006483832374215126\n",
            "Epoch 5, Batch 156 / 1350, Loss: 0.006653222255408764\n",
            "Epoch 5, Batch 157 / 1350, Loss: 0.21352557837963104\n",
            "Epoch 5, Batch 158 / 1350, Loss: 0.691804051399231\n",
            "Epoch 5, Batch 159 / 1350, Loss: 0.0071851639077067375\n",
            "Epoch 5, Batch 160 / 1350, Loss: 0.0037124305963516235\n",
            "Epoch 5, Batch 161 / 1350, Loss: 0.09027868509292603\n",
            "Epoch 5, Batch 162 / 1350, Loss: 0.16844956576824188\n",
            "Epoch 5, Batch 163 / 1350, Loss: 0.004865026101469994\n",
            "Epoch 5, Batch 164 / 1350, Loss: 0.04658661410212517\n",
            "Epoch 5, Batch 165 / 1350, Loss: 0.01094522699713707\n",
            "Epoch 5, Batch 166 / 1350, Loss: 0.00877278670668602\n",
            "Epoch 5, Batch 167 / 1350, Loss: 0.5040364265441895\n",
            "Epoch 5, Batch 168 / 1350, Loss: 0.28559017181396484\n",
            "Epoch 5, Batch 169 / 1350, Loss: 0.05065731331706047\n",
            "Epoch 5, Batch 170 / 1350, Loss: 0.003567737527191639\n",
            "Epoch 5, Batch 171 / 1350, Loss: 0.015403983183205128\n",
            "Epoch 5, Batch 172 / 1350, Loss: 0.27072498202323914\n",
            "Epoch 5, Batch 173 / 1350, Loss: 0.029160138219594955\n",
            "Epoch 5, Batch 174 / 1350, Loss: 0.004089749418199062\n",
            "Epoch 5, Batch 175 / 1350, Loss: 0.024726010859012604\n",
            "Epoch 5, Batch 176 / 1350, Loss: 0.007009116001427174\n",
            "Epoch 5, Batch 177 / 1350, Loss: 0.00780826061964035\n",
            "Epoch 5, Batch 178 / 1350, Loss: 0.07980859279632568\n",
            "Epoch 5, Batch 179 / 1350, Loss: 0.9985164403915405\n",
            "Epoch 5, Batch 180 / 1350, Loss: 0.01573556289076805\n",
            "Epoch 5, Batch 181 / 1350, Loss: 0.14581267535686493\n",
            "Epoch 5, Batch 182 / 1350, Loss: 0.07871787995100021\n",
            "Epoch 5, Batch 183 / 1350, Loss: 0.004885966889560223\n",
            "Epoch 5, Batch 184 / 1350, Loss: 0.004383356776088476\n",
            "Epoch 5, Batch 185 / 1350, Loss: 0.011111726984381676\n",
            "Epoch 5, Batch 186 / 1350, Loss: 0.016663579270243645\n",
            "Epoch 5, Batch 187 / 1350, Loss: 0.2621273994445801\n",
            "Epoch 5, Batch 188 / 1350, Loss: 0.004580123815685511\n",
            "Epoch 5, Batch 189 / 1350, Loss: 0.22340135276317596\n",
            "Epoch 5, Batch 190 / 1350, Loss: 0.008929233998060226\n",
            "Epoch 5, Batch 191 / 1350, Loss: 0.012281088158488274\n",
            "Epoch 5, Batch 192 / 1350, Loss: 0.06765726208686829\n",
            "Epoch 5, Batch 193 / 1350, Loss: 0.3080507516860962\n",
            "Epoch 5, Batch 194 / 1350, Loss: 0.05235050991177559\n",
            "Epoch 5, Batch 195 / 1350, Loss: 0.00383496331050992\n",
            "Epoch 5, Batch 196 / 1350, Loss: 0.014040181413292885\n",
            "Epoch 5, Batch 197 / 1350, Loss: 0.3781577944755554\n",
            "Epoch 5, Batch 198 / 1350, Loss: 0.004330753348767757\n",
            "Epoch 5, Batch 199 / 1350, Loss: 0.038211505860090256\n",
            "Epoch 5, Batch 200 / 1350, Loss: 0.3268699645996094\n",
            "Epoch 5, Batch 201 / 1350, Loss: 0.6066765785217285\n",
            "Epoch 5, Batch 202 / 1350, Loss: 0.0074913278222084045\n",
            "Epoch 5, Batch 203 / 1350, Loss: 0.009927117265760899\n",
            "Epoch 5, Batch 204 / 1350, Loss: 0.006080087274312973\n",
            "Epoch 5, Batch 205 / 1350, Loss: 0.00843944400548935\n",
            "Epoch 5, Batch 206 / 1350, Loss: 0.008336290717124939\n",
            "Epoch 5, Batch 207 / 1350, Loss: 0.01261608675122261\n",
            "Epoch 5, Batch 208 / 1350, Loss: 0.6046234369277954\n",
            "Epoch 5, Batch 209 / 1350, Loss: 0.01354436855763197\n",
            "Epoch 5, Batch 210 / 1350, Loss: 0.004891953896731138\n",
            "Epoch 5, Batch 211 / 1350, Loss: 0.007014561910182238\n",
            "Epoch 5, Batch 212 / 1350, Loss: 0.014259835705161095\n",
            "Epoch 5, Batch 213 / 1350, Loss: 0.01934797316789627\n",
            "Epoch 5, Batch 214 / 1350, Loss: 0.005307231098413467\n",
            "Epoch 5, Batch 215 / 1350, Loss: 0.27326488494873047\n",
            "Epoch 5, Batch 216 / 1350, Loss: 0.10443403571844101\n",
            "Epoch 5, Batch 217 / 1350, Loss: 0.004961103666573763\n",
            "Epoch 5, Batch 218 / 1350, Loss: 0.03528369590640068\n",
            "Epoch 5, Batch 219 / 1350, Loss: 0.011022588238120079\n",
            "Epoch 5, Batch 220 / 1350, Loss: 0.035504940897226334\n",
            "Epoch 5, Batch 221 / 1350, Loss: 0.011880217120051384\n",
            "Epoch 5, Batch 222 / 1350, Loss: 0.2372661828994751\n",
            "Epoch 5, Batch 223 / 1350, Loss: 0.021548369899392128\n",
            "Epoch 5, Batch 224 / 1350, Loss: 0.07162527740001678\n",
            "Epoch 5, Batch 225 / 1350, Loss: 0.02236296236515045\n",
            "Epoch 5, Batch 226 / 1350, Loss: 0.02717270702123642\n",
            "Epoch 5, Batch 227 / 1350, Loss: 0.038410037755966187\n",
            "Epoch 5, Batch 228 / 1350, Loss: 0.04428999871015549\n",
            "Epoch 5, Batch 229 / 1350, Loss: 0.3998291492462158\n",
            "Epoch 5, Batch 230 / 1350, Loss: 0.02515270933508873\n",
            "Epoch 5, Batch 231 / 1350, Loss: 0.2470654845237732\n",
            "Epoch 5, Batch 232 / 1350, Loss: 0.0037083581555634737\n",
            "Epoch 5, Batch 233 / 1350, Loss: 0.01427057757973671\n",
            "Epoch 5, Batch 234 / 1350, Loss: 0.21511048078536987\n",
            "Epoch 5, Batch 235 / 1350, Loss: 0.00456660334020853\n",
            "Epoch 5, Batch 236 / 1350, Loss: 0.0036843724083155394\n",
            "Epoch 5, Batch 237 / 1350, Loss: 0.003444114699959755\n",
            "Epoch 5, Batch 238 / 1350, Loss: 0.00453984085470438\n",
            "Epoch 5, Batch 239 / 1350, Loss: 0.008346610702574253\n",
            "Epoch 5, Batch 240 / 1350, Loss: 0.006944374646991491\n",
            "Epoch 5, Batch 241 / 1350, Loss: 0.3201095759868622\n",
            "Epoch 5, Batch 242 / 1350, Loss: 0.09438571333885193\n",
            "Epoch 5, Batch 243 / 1350, Loss: 0.003555652219802141\n",
            "Epoch 5, Batch 244 / 1350, Loss: 0.036282122135162354\n",
            "Epoch 5, Batch 245 / 1350, Loss: 0.6146869659423828\n",
            "Epoch 5, Batch 246 / 1350, Loss: 0.09759736061096191\n",
            "Epoch 5, Batch 247 / 1350, Loss: 0.04407557100057602\n",
            "Epoch 5, Batch 248 / 1350, Loss: 0.006748531945049763\n",
            "Epoch 5, Batch 249 / 1350, Loss: 0.02434888482093811\n",
            "Epoch 5, Batch 250 / 1350, Loss: 0.07780773937702179\n",
            "Epoch 5, Batch 251 / 1350, Loss: 0.15926885604858398\n",
            "Epoch 5, Batch 252 / 1350, Loss: 0.008137774653732777\n",
            "Epoch 5, Batch 253 / 1350, Loss: 0.10803539305925369\n",
            "Epoch 5, Batch 254 / 1350, Loss: 0.004169231280684471\n",
            "Epoch 5, Batch 255 / 1350, Loss: 0.06751954555511475\n",
            "Epoch 5, Batch 256 / 1350, Loss: 0.6547732949256897\n",
            "Epoch 5, Batch 257 / 1350, Loss: 0.16143444180488586\n",
            "Epoch 5, Batch 258 / 1350, Loss: 0.1068039983510971\n",
            "Epoch 5, Batch 259 / 1350, Loss: 0.046482477337121964\n",
            "Epoch 5, Batch 260 / 1350, Loss: 0.006565463729202747\n",
            "Epoch 5, Batch 261 / 1350, Loss: 0.037369851022958755\n",
            "Epoch 5, Batch 262 / 1350, Loss: 0.02737066149711609\n",
            "Epoch 5, Batch 263 / 1350, Loss: 0.11263645440340042\n",
            "Epoch 5, Batch 264 / 1350, Loss: 0.45612019300460815\n",
            "Epoch 5, Batch 265 / 1350, Loss: 0.005367612466216087\n",
            "Epoch 5, Batch 266 / 1350, Loss: 1.0653645992279053\n",
            "Epoch 5, Batch 267 / 1350, Loss: 0.026054009795188904\n",
            "Epoch 5, Batch 268 / 1350, Loss: 0.4926455616950989\n",
            "Epoch 5, Batch 269 / 1350, Loss: 0.1695786863565445\n",
            "Epoch 5, Batch 270 / 1350, Loss: 0.12497113645076752\n",
            "Epoch 5, Batch 271 / 1350, Loss: 0.003609232371672988\n",
            "Epoch 5, Batch 272 / 1350, Loss: 0.16846469044685364\n",
            "Epoch 5, Batch 273 / 1350, Loss: 0.07729948312044144\n",
            "Epoch 5, Batch 274 / 1350, Loss: 0.00944781769067049\n",
            "Epoch 5, Batch 275 / 1350, Loss: 0.013300664722919464\n",
            "Epoch 5, Batch 276 / 1350, Loss: 0.22150078415870667\n",
            "Epoch 5, Batch 277 / 1350, Loss: 0.004345365334302187\n",
            "Epoch 5, Batch 278 / 1350, Loss: 0.009629668667912483\n",
            "Epoch 5, Batch 279 / 1350, Loss: 0.01768682152032852\n",
            "Epoch 5, Batch 280 / 1350, Loss: 0.009026091545820236\n",
            "Epoch 5, Batch 281 / 1350, Loss: 0.04015113785862923\n",
            "Epoch 5, Batch 282 / 1350, Loss: 0.006062830798327923\n",
            "Epoch 5, Batch 283 / 1350, Loss: 0.03406967222690582\n",
            "Epoch 5, Batch 284 / 1350, Loss: 0.01888117752969265\n",
            "Epoch 5, Batch 285 / 1350, Loss: 0.27001065015792847\n",
            "Epoch 5, Batch 286 / 1350, Loss: 0.003692477475851774\n",
            "Epoch 5, Batch 287 / 1350, Loss: 0.11015375703573227\n",
            "Epoch 5, Batch 288 / 1350, Loss: 0.11312771588563919\n",
            "Epoch 5, Batch 289 / 1350, Loss: 0.004091251641511917\n",
            "Epoch 5, Batch 290 / 1350, Loss: 0.07904387265443802\n",
            "Epoch 5, Batch 291 / 1350, Loss: 0.0053985826671123505\n",
            "Epoch 5, Batch 292 / 1350, Loss: 0.01982533372938633\n",
            "Epoch 5, Batch 293 / 1350, Loss: 0.012046990916132927\n",
            "Epoch 5, Batch 294 / 1350, Loss: 0.9555434584617615\n",
            "Epoch 5, Batch 295 / 1350, Loss: 0.0033263457007706165\n",
            "Epoch 5, Batch 296 / 1350, Loss: 0.009908708743751049\n",
            "Epoch 5, Batch 297 / 1350, Loss: 0.06820355355739594\n",
            "Epoch 5, Batch 298 / 1350, Loss: 0.09578156471252441\n",
            "Epoch 5, Batch 299 / 1350, Loss: 0.009242081083357334\n",
            "Epoch 5, Batch 300 / 1350, Loss: 0.7635522484779358\n",
            "Epoch 5, Batch 301 / 1350, Loss: 0.01134895533323288\n",
            "Epoch 5, Batch 302 / 1350, Loss: 0.009409483522176743\n",
            "Epoch 5, Batch 303 / 1350, Loss: 0.013285752385854721\n",
            "Epoch 5, Batch 304 / 1350, Loss: 0.11139784008264542\n",
            "Epoch 5, Batch 305 / 1350, Loss: 0.03507823869585991\n",
            "Epoch 5, Batch 306 / 1350, Loss: 0.0040269517339766026\n",
            "Epoch 5, Batch 307 / 1350, Loss: 0.006391268689185381\n",
            "Epoch 5, Batch 308 / 1350, Loss: 0.0071912421844899654\n",
            "Epoch 5, Batch 309 / 1350, Loss: 0.003955047577619553\n",
            "Epoch 5, Batch 310 / 1350, Loss: 0.0729169249534607\n",
            "Epoch 5, Batch 311 / 1350, Loss: 0.036271292716264725\n",
            "Epoch 5, Batch 312 / 1350, Loss: 0.06004234030842781\n",
            "Epoch 5, Batch 313 / 1350, Loss: 0.03509819135069847\n",
            "Epoch 5, Batch 314 / 1350, Loss: 0.23040586709976196\n",
            "Epoch 5, Batch 315 / 1350, Loss: 0.06886427104473114\n",
            "Epoch 5, Batch 316 / 1350, Loss: 0.007804557681083679\n",
            "Epoch 5, Batch 317 / 1350, Loss: 0.09428610652685165\n",
            "Epoch 5, Batch 318 / 1350, Loss: 0.08186826854944229\n",
            "Epoch 5, Batch 319 / 1350, Loss: 0.05384540557861328\n",
            "Epoch 5, Batch 320 / 1350, Loss: 0.11057350039482117\n",
            "Epoch 5, Batch 321 / 1350, Loss: 1.2578707933425903\n",
            "Epoch 5, Batch 322 / 1350, Loss: 0.009345410391688347\n",
            "Epoch 5, Batch 323 / 1350, Loss: 0.01837850548326969\n",
            "Epoch 5, Batch 324 / 1350, Loss: 0.02294299006462097\n",
            "Epoch 5, Batch 325 / 1350, Loss: 0.21679165959358215\n",
            "Epoch 5, Batch 326 / 1350, Loss: 0.13666369020938873\n",
            "Epoch 5, Batch 327 / 1350, Loss: 0.16189175844192505\n",
            "Epoch 5, Batch 328 / 1350, Loss: 0.146272674202919\n",
            "Epoch 5, Batch 329 / 1350, Loss: 0.379149854183197\n",
            "Epoch 5, Batch 330 / 1350, Loss: 0.0065475343726575375\n",
            "Epoch 5, Batch 331 / 1350, Loss: 0.19777745008468628\n",
            "Epoch 5, Batch 332 / 1350, Loss: 0.006822871044278145\n",
            "Epoch 5, Batch 333 / 1350, Loss: 0.0060136448591947556\n",
            "Epoch 5, Batch 334 / 1350, Loss: 0.0036491036880761385\n",
            "Epoch 5, Batch 335 / 1350, Loss: 0.04907328635454178\n",
            "Epoch 5, Batch 336 / 1350, Loss: 0.003926284611225128\n",
            "Epoch 5, Batch 337 / 1350, Loss: 0.007769945077598095\n",
            "Epoch 5, Batch 338 / 1350, Loss: 0.027478337287902832\n",
            "Epoch 5, Batch 339 / 1350, Loss: 0.11262045055627823\n",
            "Epoch 5, Batch 340 / 1350, Loss: 0.3139766752719879\n",
            "Epoch 5, Batch 341 / 1350, Loss: 0.053510479629039764\n",
            "Epoch 5, Batch 342 / 1350, Loss: 0.07204071432352066\n",
            "Epoch 5, Batch 343 / 1350, Loss: 0.004332173615694046\n",
            "Epoch 5, Batch 344 / 1350, Loss: 0.006684388034045696\n",
            "Epoch 5, Batch 345 / 1350, Loss: 0.7927137613296509\n",
            "Epoch 5, Batch 346 / 1350, Loss: 0.022258244454860687\n",
            "Epoch 5, Batch 347 / 1350, Loss: 0.004650845192372799\n",
            "Epoch 5, Batch 348 / 1350, Loss: 0.27841663360595703\n",
            "Epoch 5, Batch 349 / 1350, Loss: 0.0034549047704786062\n",
            "Epoch 5, Batch 350 / 1350, Loss: 0.046424806118011475\n",
            "Epoch 5, Batch 351 / 1350, Loss: 0.012840254232287407\n",
            "Epoch 5, Batch 352 / 1350, Loss: 0.0066481903195381165\n",
            "Epoch 5, Batch 353 / 1350, Loss: 1.3838471174240112\n",
            "Epoch 5, Batch 354 / 1350, Loss: 0.29801619052886963\n",
            "Epoch 5, Batch 355 / 1350, Loss: 0.2563445270061493\n",
            "Epoch 5, Batch 356 / 1350, Loss: 0.05341113358736038\n",
            "Epoch 5, Batch 357 / 1350, Loss: 0.005335649475455284\n",
            "Epoch 5, Batch 358 / 1350, Loss: 0.9456109404563904\n",
            "Epoch 5, Batch 359 / 1350, Loss: 0.04270370304584503\n",
            "Epoch 5, Batch 360 / 1350, Loss: 0.07663850486278534\n",
            "Epoch 5, Batch 361 / 1350, Loss: 0.003977913409471512\n",
            "Epoch 5, Batch 362 / 1350, Loss: 0.01901387609541416\n",
            "Epoch 5, Batch 363 / 1350, Loss: 0.19510753452777863\n",
            "Epoch 5, Batch 364 / 1350, Loss: 0.0047563412226736546\n",
            "Epoch 5, Batch 365 / 1350, Loss: 0.11296075582504272\n",
            "Epoch 5, Batch 366 / 1350, Loss: 0.20403821766376495\n",
            "Epoch 5, Batch 367 / 1350, Loss: 0.0046607255935668945\n",
            "Epoch 5, Batch 368 / 1350, Loss: 0.05164686217904091\n",
            "Epoch 5, Batch 369 / 1350, Loss: 0.11728090047836304\n",
            "Epoch 5, Batch 370 / 1350, Loss: 0.008534315973520279\n",
            "Epoch 5, Batch 371 / 1350, Loss: 0.01355034951120615\n",
            "Epoch 5, Batch 372 / 1350, Loss: 0.005829842295497656\n",
            "Epoch 5, Batch 373 / 1350, Loss: 0.9619113802909851\n",
            "Epoch 5, Batch 374 / 1350, Loss: 0.025845341384410858\n",
            "Epoch 5, Batch 375 / 1350, Loss: 0.5474733114242554\n",
            "Epoch 5, Batch 376 / 1350, Loss: 0.006348324939608574\n",
            "Epoch 5, Batch 377 / 1350, Loss: 0.004317340441048145\n",
            "Epoch 5, Batch 378 / 1350, Loss: 0.01983468048274517\n",
            "Epoch 5, Batch 379 / 1350, Loss: 0.036167211830616\n",
            "Epoch 5, Batch 380 / 1350, Loss: 0.0054489728063344955\n",
            "Epoch 5, Batch 381 / 1350, Loss: 0.17407704889774323\n",
            "Epoch 5, Batch 382 / 1350, Loss: 0.005280586890876293\n",
            "Epoch 5, Batch 383 / 1350, Loss: 0.004771018400788307\n",
            "Epoch 5, Batch 384 / 1350, Loss: 0.007769542280584574\n",
            "Epoch 5, Batch 385 / 1350, Loss: 0.01017505768686533\n",
            "Epoch 5, Batch 386 / 1350, Loss: 0.10711127519607544\n",
            "Epoch 5, Batch 387 / 1350, Loss: 0.03587115928530693\n",
            "Epoch 5, Batch 388 / 1350, Loss: 0.018230609595775604\n",
            "Epoch 5, Batch 389 / 1350, Loss: 0.010159403085708618\n",
            "Epoch 5, Batch 390 / 1350, Loss: 0.008407560177147388\n",
            "Epoch 5, Batch 391 / 1350, Loss: 0.004494662396609783\n",
            "Epoch 5, Batch 392 / 1350, Loss: 0.037991032004356384\n",
            "Epoch 5, Batch 393 / 1350, Loss: 0.00857532862573862\n",
            "Epoch 5, Batch 394 / 1350, Loss: 0.011798452585935593\n",
            "Epoch 5, Batch 395 / 1350, Loss: 0.007920702919363976\n",
            "Epoch 5, Batch 396 / 1350, Loss: 0.01589996926486492\n",
            "Epoch 5, Batch 397 / 1350, Loss: 0.6669801473617554\n",
            "Epoch 5, Batch 398 / 1350, Loss: 0.1474902629852295\n",
            "Epoch 5, Batch 399 / 1350, Loss: 0.030100539326667786\n",
            "Epoch 5, Batch 400 / 1350, Loss: 0.11298276484012604\n",
            "Epoch 5, Batch 401 / 1350, Loss: 0.004538345150649548\n",
            "Epoch 5, Batch 402 / 1350, Loss: 0.007182834204286337\n",
            "Epoch 5, Batch 403 / 1350, Loss: 0.012039595283567905\n",
            "Epoch 5, Batch 404 / 1350, Loss: 0.012004967778921127\n",
            "Epoch 5, Batch 405 / 1350, Loss: 0.006145701743662357\n",
            "Epoch 5, Batch 406 / 1350, Loss: 0.04475177451968193\n",
            "Epoch 5, Batch 407 / 1350, Loss: 0.0443357415497303\n",
            "Epoch 5, Batch 408 / 1350, Loss: 0.2827247083187103\n",
            "Epoch 5, Batch 409 / 1350, Loss: 0.18040235340595245\n",
            "Epoch 5, Batch 410 / 1350, Loss: 0.9459481835365295\n",
            "Epoch 5, Batch 411 / 1350, Loss: 1.3558342456817627\n",
            "Epoch 5, Batch 412 / 1350, Loss: 0.1972978264093399\n",
            "Epoch 5, Batch 413 / 1350, Loss: 0.07897225022315979\n",
            "Epoch 5, Batch 414 / 1350, Loss: 0.007667002268135548\n",
            "Epoch 5, Batch 415 / 1350, Loss: 0.039332155138254166\n",
            "Epoch 5, Batch 416 / 1350, Loss: 0.015607839450240135\n",
            "Epoch 5, Batch 417 / 1350, Loss: 0.012929538264870644\n",
            "Epoch 5, Batch 418 / 1350, Loss: 0.027177678421139717\n",
            "Epoch 5, Batch 419 / 1350, Loss: 0.756592333316803\n",
            "Epoch 5, Batch 420 / 1350, Loss: 0.029765987768769264\n",
            "Epoch 5, Batch 421 / 1350, Loss: 1.0217851400375366\n",
            "Epoch 5, Batch 422 / 1350, Loss: 0.03376946598291397\n",
            "Epoch 5, Batch 423 / 1350, Loss: 0.8779295086860657\n",
            "Epoch 5, Batch 424 / 1350, Loss: 0.5877462029457092\n",
            "Epoch 5, Batch 425 / 1350, Loss: 0.009553699754178524\n",
            "Epoch 5, Batch 426 / 1350, Loss: 0.06044816970825195\n",
            "Epoch 5, Batch 427 / 1350, Loss: 0.09019449353218079\n",
            "Epoch 5, Batch 428 / 1350, Loss: 0.022758975625038147\n",
            "Epoch 5, Batch 429 / 1350, Loss: 0.2640761137008667\n",
            "Epoch 5, Batch 430 / 1350, Loss: 0.009567531757056713\n",
            "Epoch 5, Batch 431 / 1350, Loss: 0.3280516564846039\n",
            "Epoch 5, Batch 432 / 1350, Loss: 0.017314914613962173\n",
            "Epoch 5, Batch 433 / 1350, Loss: 0.02380910888314247\n",
            "Epoch 5, Batch 434 / 1350, Loss: 0.007106458768248558\n",
            "Epoch 5, Batch 435 / 1350, Loss: 0.007834436371922493\n",
            "Epoch 5, Batch 436 / 1350, Loss: 0.48782819509506226\n",
            "Epoch 5, Batch 437 / 1350, Loss: 0.07601382583379745\n",
            "Epoch 5, Batch 438 / 1350, Loss: 0.039296675473451614\n",
            "Epoch 5, Batch 439 / 1350, Loss: 0.07899394631385803\n",
            "Epoch 5, Batch 440 / 1350, Loss: 0.009907757863402367\n",
            "Epoch 5, Batch 441 / 1350, Loss: 0.02923281490802765\n",
            "Epoch 5, Batch 442 / 1350, Loss: 0.01118507981300354\n",
            "Epoch 5, Batch 443 / 1350, Loss: 0.009611300192773342\n",
            "Epoch 5, Batch 444 / 1350, Loss: 0.0075434306636452675\n",
            "Epoch 5, Batch 445 / 1350, Loss: 0.1237243190407753\n",
            "Epoch 5, Batch 446 / 1350, Loss: 0.022945191711187363\n",
            "Epoch 5, Batch 447 / 1350, Loss: 1.288861632347107\n",
            "Epoch 5, Batch 448 / 1350, Loss: 0.011008578352630138\n",
            "Epoch 5, Batch 449 / 1350, Loss: 0.1237514466047287\n",
            "Epoch 5, Batch 450 / 1350, Loss: 0.02235747128725052\n",
            "Epoch 5, Batch 451 / 1350, Loss: 0.0443112887442112\n",
            "Epoch 5, Batch 452 / 1350, Loss: 0.010410347953438759\n",
            "Epoch 5, Batch 453 / 1350, Loss: 0.013742756098508835\n",
            "Epoch 5, Batch 454 / 1350, Loss: 0.015771297737956047\n",
            "Epoch 5, Batch 455 / 1350, Loss: 0.24936899542808533\n",
            "Epoch 5, Batch 456 / 1350, Loss: 0.18309052288532257\n",
            "Epoch 5, Batch 457 / 1350, Loss: 0.03985682874917984\n",
            "Epoch 5, Batch 458 / 1350, Loss: 0.0274477731436491\n",
            "Epoch 5, Batch 459 / 1350, Loss: 0.01156359538435936\n",
            "Epoch 5, Batch 460 / 1350, Loss: 0.008997801691293716\n",
            "Epoch 5, Batch 461 / 1350, Loss: 0.02404753863811493\n",
            "Epoch 5, Batch 462 / 1350, Loss: 0.0337008573114872\n",
            "Epoch 5, Batch 463 / 1350, Loss: 0.1444086730480194\n",
            "Epoch 5, Batch 464 / 1350, Loss: 0.15681186318397522\n",
            "Epoch 5, Batch 465 / 1350, Loss: 0.969424843788147\n",
            "Epoch 5, Batch 466 / 1350, Loss: 0.017395194619894028\n",
            "Epoch 5, Batch 467 / 1350, Loss: 0.05497303977608681\n",
            "Epoch 5, Batch 468 / 1350, Loss: 0.19935448467731476\n",
            "Epoch 5, Batch 469 / 1350, Loss: 0.013975683599710464\n",
            "Epoch 5, Batch 470 / 1350, Loss: 0.008567208424210548\n",
            "Epoch 5, Batch 471 / 1350, Loss: 0.20290671288967133\n",
            "Epoch 5, Batch 472 / 1350, Loss: 0.2878059446811676\n",
            "Epoch 5, Batch 473 / 1350, Loss: 0.008309958502650261\n",
            "Epoch 5, Batch 474 / 1350, Loss: 0.01908745802938938\n",
            "Epoch 5, Batch 475 / 1350, Loss: 0.010389040224254131\n",
            "Epoch 5, Batch 476 / 1350, Loss: 0.017743807286024094\n",
            "Epoch 5, Batch 477 / 1350, Loss: 0.014386850409209728\n",
            "Epoch 5, Batch 478 / 1350, Loss: 0.007540754973888397\n",
            "Epoch 5, Batch 479 / 1350, Loss: 0.04381243884563446\n",
            "Epoch 5, Batch 480 / 1350, Loss: 0.02389591746032238\n",
            "Epoch 5, Batch 481 / 1350, Loss: 0.3372821807861328\n",
            "Epoch 5, Batch 482 / 1350, Loss: 0.0161411315202713\n",
            "Epoch 5, Batch 483 / 1350, Loss: 0.010208013467490673\n",
            "Epoch 5, Batch 484 / 1350, Loss: 0.007102969102561474\n",
            "Epoch 5, Batch 485 / 1350, Loss: 0.9028621315956116\n",
            "Epoch 5, Batch 486 / 1350, Loss: 0.028323359787464142\n",
            "Epoch 5, Batch 487 / 1350, Loss: 0.028367146849632263\n",
            "Epoch 5, Batch 488 / 1350, Loss: 0.008760383352637291\n",
            "Epoch 5, Batch 489 / 1350, Loss: 0.008344300091266632\n",
            "Epoch 5, Batch 490 / 1350, Loss: 0.10765056312084198\n",
            "Epoch 5, Batch 491 / 1350, Loss: 0.1255560964345932\n",
            "Epoch 5, Batch 492 / 1350, Loss: 0.06026511639356613\n",
            "Epoch 5, Batch 493 / 1350, Loss: 0.020612675696611404\n",
            "Epoch 5, Batch 494 / 1350, Loss: 0.027212800458073616\n",
            "Epoch 5, Batch 495 / 1350, Loss: 0.0244489386677742\n",
            "Epoch 5, Batch 496 / 1350, Loss: 0.020806677639484406\n",
            "Epoch 5, Batch 497 / 1350, Loss: 0.013783270493149757\n",
            "Epoch 5, Batch 498 / 1350, Loss: 0.006314555183053017\n",
            "Epoch 5, Batch 499 / 1350, Loss: 0.3592345714569092\n",
            "Epoch 5, Batch 500 / 1350, Loss: 0.1896541565656662\n",
            "Epoch 5, Batch 501 / 1350, Loss: 0.07920682430267334\n",
            "Epoch 5, Batch 502 / 1350, Loss: 0.020525125786662102\n",
            "Epoch 5, Batch 503 / 1350, Loss: 0.016488805413246155\n",
            "Epoch 5, Batch 504 / 1350, Loss: 0.0060837469063699245\n",
            "Epoch 5, Batch 505 / 1350, Loss: 0.010301600210368633\n",
            "Epoch 5, Batch 506 / 1350, Loss: 0.010529639199376106\n",
            "Epoch 5, Batch 507 / 1350, Loss: 0.018969586119055748\n",
            "Epoch 5, Batch 508 / 1350, Loss: 0.04124946892261505\n",
            "Epoch 5, Batch 509 / 1350, Loss: 0.03977527841925621\n",
            "Epoch 5, Batch 510 / 1350, Loss: 0.014875071123242378\n",
            "Epoch 5, Batch 511 / 1350, Loss: 0.06229300796985626\n",
            "Epoch 5, Batch 512 / 1350, Loss: 0.004802302457392216\n",
            "Epoch 5, Batch 513 / 1350, Loss: 0.09718181937932968\n",
            "Epoch 5, Batch 514 / 1350, Loss: 0.007747107185423374\n",
            "Epoch 5, Batch 515 / 1350, Loss: 0.02579488418996334\n",
            "Epoch 5, Batch 516 / 1350, Loss: 0.00486357556656003\n",
            "Epoch 5, Batch 517 / 1350, Loss: 0.005970461294054985\n",
            "Epoch 5, Batch 518 / 1350, Loss: 0.009914323687553406\n",
            "Epoch 5, Batch 519 / 1350, Loss: 0.014401614665985107\n",
            "Epoch 5, Batch 520 / 1350, Loss: 0.2942294180393219\n",
            "Epoch 5, Batch 521 / 1350, Loss: 0.01863699220120907\n",
            "Epoch 5, Batch 522 / 1350, Loss: 0.017252245917916298\n",
            "Epoch 5, Batch 523 / 1350, Loss: 0.784317135810852\n",
            "Epoch 5, Batch 524 / 1350, Loss: 0.448985755443573\n",
            "Epoch 5, Batch 525 / 1350, Loss: 0.005705039016902447\n",
            "Epoch 5, Batch 526 / 1350, Loss: 1.9146512746810913\n",
            "Epoch 5, Batch 527 / 1350, Loss: 1.1073598861694336\n",
            "Epoch 5, Batch 528 / 1350, Loss: 0.004899298772215843\n",
            "Epoch 5, Batch 529 / 1350, Loss: 0.2240697741508484\n",
            "Epoch 5, Batch 530 / 1350, Loss: 0.011207494884729385\n",
            "Epoch 5, Batch 531 / 1350, Loss: 0.03986508771777153\n",
            "Epoch 5, Batch 532 / 1350, Loss: 0.07145518064498901\n",
            "Epoch 5, Batch 533 / 1350, Loss: 0.010494938120245934\n",
            "Epoch 5, Batch 534 / 1350, Loss: 0.8635381460189819\n",
            "Epoch 5, Batch 535 / 1350, Loss: 0.024230092763900757\n",
            "Epoch 5, Batch 536 / 1350, Loss: 0.035034630447626114\n",
            "Epoch 5, Batch 537 / 1350, Loss: 0.04822555184364319\n",
            "Epoch 5, Batch 538 / 1350, Loss: 0.2750910520553589\n",
            "Epoch 5, Batch 539 / 1350, Loss: 0.07032829523086548\n",
            "Epoch 5, Batch 540 / 1350, Loss: 0.038945272564888\n",
            "Epoch 5, Batch 541 / 1350, Loss: 0.018473228439688683\n",
            "Epoch 5, Batch 542 / 1350, Loss: 0.3382837772369385\n",
            "Epoch 5, Batch 543 / 1350, Loss: 0.017813939601182938\n",
            "Epoch 5, Batch 544 / 1350, Loss: 0.12483815848827362\n",
            "Epoch 5, Batch 545 / 1350, Loss: 0.3064109683036804\n",
            "Epoch 5, Batch 546 / 1350, Loss: 0.11462874710559845\n",
            "Epoch 5, Batch 547 / 1350, Loss: 0.14621010422706604\n",
            "Epoch 5, Batch 548 / 1350, Loss: 0.12955161929130554\n",
            "Epoch 5, Batch 549 / 1350, Loss: 0.7961686253547668\n",
            "Epoch 5, Batch 550 / 1350, Loss: 0.014672807417809963\n",
            "Epoch 5, Batch 551 / 1350, Loss: 0.024262122809886932\n",
            "Epoch 5, Batch 552 / 1350, Loss: 0.09384772181510925\n",
            "Epoch 5, Batch 553 / 1350, Loss: 0.3529393672943115\n",
            "Epoch 5, Batch 554 / 1350, Loss: 0.037860121577978134\n",
            "Epoch 5, Batch 555 / 1350, Loss: 0.04982572793960571\n",
            "Epoch 5, Batch 556 / 1350, Loss: 0.05457781255245209\n",
            "Epoch 5, Batch 557 / 1350, Loss: 0.12991838157176971\n",
            "Epoch 5, Batch 558 / 1350, Loss: 0.022872239351272583\n",
            "Epoch 5, Batch 559 / 1350, Loss: 0.04024370014667511\n",
            "Epoch 5, Batch 560 / 1350, Loss: 0.04894360154867172\n",
            "Epoch 5, Batch 561 / 1350, Loss: 0.09474534541368484\n",
            "Epoch 5, Batch 562 / 1350, Loss: 0.03181587904691696\n",
            "Epoch 5, Batch 563 / 1350, Loss: 0.03223160281777382\n",
            "Epoch 5, Batch 564 / 1350, Loss: 0.015073730610311031\n",
            "Epoch 5, Batch 565 / 1350, Loss: 0.0330861359834671\n",
            "Epoch 5, Batch 566 / 1350, Loss: 0.03341052308678627\n",
            "Epoch 5, Batch 567 / 1350, Loss: 0.02006084844470024\n",
            "Epoch 5, Batch 568 / 1350, Loss: 0.4314923584461212\n",
            "Epoch 5, Batch 569 / 1350, Loss: 0.019845852628350258\n",
            "Epoch 5, Batch 570 / 1350, Loss: 0.015075279399752617\n",
            "Epoch 5, Batch 571 / 1350, Loss: 0.5166516304016113\n",
            "Epoch 5, Batch 572 / 1350, Loss: 0.05144605040550232\n",
            "Epoch 5, Batch 573 / 1350, Loss: 0.043768249452114105\n",
            "Epoch 5, Batch 574 / 1350, Loss: 0.023189038038253784\n",
            "Epoch 5, Batch 575 / 1350, Loss: 0.024303214624524117\n",
            "Epoch 5, Batch 576 / 1350, Loss: 0.6828153133392334\n",
            "Epoch 5, Batch 577 / 1350, Loss: 0.11952381581068039\n",
            "Epoch 5, Batch 578 / 1350, Loss: 0.023409878835082054\n",
            "Epoch 5, Batch 579 / 1350, Loss: 0.01360042579472065\n",
            "Epoch 5, Batch 580 / 1350, Loss: 0.02688737027347088\n",
            "Epoch 5, Batch 581 / 1350, Loss: 0.038986366242170334\n",
            "Epoch 5, Batch 582 / 1350, Loss: 0.010462142527103424\n",
            "Epoch 5, Batch 583 / 1350, Loss: 0.07385258376598358\n",
            "Epoch 5, Batch 584 / 1350, Loss: 0.007146626245230436\n",
            "Epoch 5, Batch 585 / 1350, Loss: 0.2649989426136017\n",
            "Epoch 5, Batch 586 / 1350, Loss: 0.38093018531799316\n",
            "Epoch 5, Batch 587 / 1350, Loss: 0.0699300765991211\n",
            "Epoch 5, Batch 588 / 1350, Loss: 0.005968776997178793\n",
            "Epoch 5, Batch 589 / 1350, Loss: 0.05447501689195633\n",
            "Epoch 5, Batch 590 / 1350, Loss: 0.03472624719142914\n",
            "Epoch 5, Batch 591 / 1350, Loss: 0.15810967981815338\n",
            "Epoch 5, Batch 592 / 1350, Loss: 0.055508773773908615\n",
            "Epoch 5, Batch 593 / 1350, Loss: 0.03963235765695572\n",
            "Epoch 5, Batch 594 / 1350, Loss: 0.26167210936546326\n",
            "Epoch 5, Batch 595 / 1350, Loss: 0.04973585531115532\n",
            "Epoch 5, Batch 596 / 1350, Loss: 0.2707293629646301\n",
            "Epoch 5, Batch 597 / 1350, Loss: 0.03201180696487427\n",
            "Epoch 5, Batch 598 / 1350, Loss: 0.22824859619140625\n",
            "Epoch 5, Batch 599 / 1350, Loss: 0.036121249198913574\n",
            "Epoch 5, Batch 600 / 1350, Loss: 0.01662493124604225\n",
            "Epoch 5, Batch 601 / 1350, Loss: 0.017775967717170715\n",
            "Epoch 5, Batch 602 / 1350, Loss: 0.021948669105768204\n",
            "Epoch 5, Batch 603 / 1350, Loss: 0.005520469043403864\n",
            "Epoch 5, Batch 604 / 1350, Loss: 0.013749383389949799\n",
            "Epoch 5, Batch 605 / 1350, Loss: 0.015732616186141968\n",
            "Epoch 5, Batch 606 / 1350, Loss: 0.0841064304113388\n",
            "Epoch 5, Batch 607 / 1350, Loss: 0.00531936576589942\n",
            "Epoch 5, Batch 608 / 1350, Loss: 0.033482182770967484\n",
            "Epoch 5, Batch 609 / 1350, Loss: 0.05333026126027107\n",
            "Epoch 5, Batch 610 / 1350, Loss: 0.01194764580577612\n",
            "Epoch 5, Batch 611 / 1350, Loss: 0.7802042961120605\n",
            "Epoch 5, Batch 612 / 1350, Loss: 0.1685272753238678\n",
            "Epoch 5, Batch 613 / 1350, Loss: 0.8458012938499451\n",
            "Epoch 5, Batch 614 / 1350, Loss: 0.03533024340867996\n",
            "Epoch 5, Batch 615 / 1350, Loss: 0.011778997257351875\n",
            "Epoch 5, Batch 616 / 1350, Loss: 0.13940834999084473\n",
            "Epoch 5, Batch 617 / 1350, Loss: 0.027711600065231323\n",
            "Epoch 5, Batch 618 / 1350, Loss: 0.393041729927063\n",
            "Epoch 5, Batch 619 / 1350, Loss: 0.014315014705061913\n",
            "Epoch 5, Batch 620 / 1350, Loss: 0.030245734378695488\n",
            "Epoch 5, Batch 621 / 1350, Loss: 0.028566667810082436\n",
            "Epoch 5, Batch 622 / 1350, Loss: 0.021556079387664795\n",
            "Epoch 5, Batch 623 / 1350, Loss: 0.10723710060119629\n",
            "Epoch 5, Batch 624 / 1350, Loss: 0.08532316237688065\n",
            "Epoch 5, Batch 625 / 1350, Loss: 0.04035203158855438\n",
            "Epoch 5, Batch 626 / 1350, Loss: 0.17509374022483826\n",
            "Epoch 5, Batch 627 / 1350, Loss: 0.03038991615176201\n",
            "Epoch 5, Batch 628 / 1350, Loss: 0.19855153560638428\n",
            "Epoch 5, Batch 629 / 1350, Loss: 0.15011411905288696\n",
            "Epoch 5, Batch 630 / 1350, Loss: 0.0074594090692698956\n",
            "Epoch 5, Batch 631 / 1350, Loss: 0.014918969012796879\n",
            "Epoch 5, Batch 632 / 1350, Loss: 0.008909633383154869\n",
            "Epoch 5, Batch 633 / 1350, Loss: 0.005439586937427521\n",
            "Epoch 5, Batch 634 / 1350, Loss: 0.004190769046545029\n",
            "Epoch 5, Batch 635 / 1350, Loss: 0.011341944336891174\n",
            "Epoch 5, Batch 636 / 1350, Loss: 0.5282332897186279\n",
            "Epoch 5, Batch 637 / 1350, Loss: 0.005117875523865223\n",
            "Epoch 5, Batch 638 / 1350, Loss: 0.017099764198064804\n",
            "Epoch 5, Batch 639 / 1350, Loss: 0.005591386929154396\n",
            "Epoch 5, Batch 640 / 1350, Loss: 0.015612034127116203\n",
            "Epoch 5, Batch 641 / 1350, Loss: 0.04506712034344673\n",
            "Epoch 5, Batch 642 / 1350, Loss: 0.019496794790029526\n",
            "Epoch 5, Batch 643 / 1350, Loss: 0.006078031379729509\n",
            "Epoch 5, Batch 644 / 1350, Loss: 0.006646584719419479\n",
            "Epoch 5, Batch 645 / 1350, Loss: 0.025225691497325897\n",
            "Epoch 5, Batch 646 / 1350, Loss: 0.028356552124023438\n",
            "Epoch 5, Batch 647 / 1350, Loss: 0.007963945157825947\n",
            "Epoch 5, Batch 648 / 1350, Loss: 0.01484023965895176\n",
            "Epoch 5, Batch 649 / 1350, Loss: 0.005567842163145542\n",
            "Epoch 5, Batch 650 / 1350, Loss: 0.2183125615119934\n",
            "Epoch 5, Batch 651 / 1350, Loss: 0.005831936374306679\n",
            "Epoch 5, Batch 652 / 1350, Loss: 0.006370688788592815\n",
            "Epoch 5, Batch 653 / 1350, Loss: 0.0042198579758405685\n",
            "Epoch 5, Batch 654 / 1350, Loss: 0.00805714726448059\n",
            "Epoch 5, Batch 655 / 1350, Loss: 0.008194690570235252\n",
            "Epoch 5, Batch 656 / 1350, Loss: 0.01066727377474308\n",
            "Epoch 5, Batch 657 / 1350, Loss: 0.0036756047047674656\n",
            "Epoch 5, Batch 658 / 1350, Loss: 0.06344390660524368\n",
            "Epoch 5, Batch 659 / 1350, Loss: 0.06958597153425217\n",
            "Epoch 5, Batch 660 / 1350, Loss: 0.005132129881531\n",
            "Epoch 5, Batch 661 / 1350, Loss: 0.6132186651229858\n",
            "Epoch 5, Batch 662 / 1350, Loss: 0.004334059078246355\n",
            "Epoch 5, Batch 663 / 1350, Loss: 0.013422626070678234\n",
            "Epoch 5, Batch 664 / 1350, Loss: 0.012050660327076912\n",
            "Epoch 5, Batch 665 / 1350, Loss: 0.018875407055020332\n",
            "Epoch 5, Batch 666 / 1350, Loss: 0.010339681059122086\n",
            "Epoch 5, Batch 667 / 1350, Loss: 0.019198507070541382\n",
            "Epoch 5, Batch 668 / 1350, Loss: 0.01783270388841629\n",
            "Epoch 5, Batch 669 / 1350, Loss: 0.14258508384227753\n",
            "Epoch 5, Batch 670 / 1350, Loss: 0.019704677164554596\n",
            "Epoch 5, Batch 671 / 1350, Loss: 0.004302260000258684\n",
            "Epoch 5, Batch 672 / 1350, Loss: 0.003466163296252489\n",
            "Epoch 5, Batch 673 / 1350, Loss: 0.015815898776054382\n",
            "Epoch 5, Batch 674 / 1350, Loss: 0.30100172758102417\n",
            "Epoch 5, Batch 675 / 1350, Loss: 0.009523355402052402\n",
            "Epoch 5, Batch 676 / 1350, Loss: 0.004025917500257492\n",
            "Epoch 5, Batch 677 / 1350, Loss: 0.007114296779036522\n",
            "Epoch 5, Batch 678 / 1350, Loss: 0.09967692196369171\n",
            "Epoch 5, Batch 679 / 1350, Loss: 0.0032854790333658457\n",
            "Epoch 5, Batch 680 / 1350, Loss: 0.004707504063844681\n",
            "Epoch 5, Batch 681 / 1350, Loss: 0.017030037939548492\n",
            "Epoch 5, Batch 682 / 1350, Loss: 0.09894135594367981\n",
            "Epoch 5, Batch 683 / 1350, Loss: 0.004498826339840889\n",
            "Epoch 5, Batch 684 / 1350, Loss: 0.020038694143295288\n",
            "Epoch 5, Batch 685 / 1350, Loss: 0.014530498534440994\n",
            "Epoch 5, Batch 686 / 1350, Loss: 0.02073468267917633\n",
            "Epoch 5, Batch 687 / 1350, Loss: 0.2256285846233368\n",
            "Epoch 5, Batch 688 / 1350, Loss: 0.003456349018961191\n",
            "Epoch 5, Batch 689 / 1350, Loss: 0.01976117119193077\n",
            "Epoch 5, Batch 690 / 1350, Loss: 0.0035605865996330976\n",
            "Epoch 5, Batch 691 / 1350, Loss: 0.03835509717464447\n",
            "Epoch 5, Batch 692 / 1350, Loss: 0.005285168532282114\n",
            "Epoch 5, Batch 693 / 1350, Loss: 0.008261475712060928\n",
            "Epoch 5, Batch 694 / 1350, Loss: 0.006788080092519522\n",
            "Epoch 5, Batch 695 / 1350, Loss: 0.002788403071463108\n",
            "Epoch 5, Batch 696 / 1350, Loss: 0.009786596521735191\n",
            "Epoch 5, Batch 697 / 1350, Loss: 0.004054635763168335\n",
            "Epoch 5, Batch 698 / 1350, Loss: 0.007200976368039846\n",
            "Epoch 5, Batch 699 / 1350, Loss: 1.25846529006958\n",
            "Epoch 5, Batch 700 / 1350, Loss: 0.005714500322937965\n",
            "Epoch 5, Batch 701 / 1350, Loss: 0.007454500067979097\n",
            "Epoch 5, Batch 702 / 1350, Loss: 0.007428272627294064\n",
            "Epoch 5, Batch 703 / 1350, Loss: 0.10873020440340042\n",
            "Epoch 5, Batch 704 / 1350, Loss: 0.005613773595541716\n",
            "Epoch 5, Batch 705 / 1350, Loss: 0.006015594117343426\n",
            "Epoch 5, Batch 706 / 1350, Loss: 0.5827322602272034\n",
            "Epoch 5, Batch 707 / 1350, Loss: 0.013145537115633488\n",
            "Epoch 5, Batch 708 / 1350, Loss: 0.04240933805704117\n",
            "Epoch 5, Batch 709 / 1350, Loss: 0.4523793160915375\n",
            "Epoch 5, Batch 710 / 1350, Loss: 0.006505537778139114\n",
            "Epoch 5, Batch 711 / 1350, Loss: 0.08200554549694061\n",
            "Epoch 5, Batch 712 / 1350, Loss: 0.013403910212218761\n",
            "Epoch 5, Batch 713 / 1350, Loss: 0.008956694044172764\n",
            "Epoch 5, Batch 714 / 1350, Loss: 0.016076616942882538\n",
            "Epoch 5, Batch 715 / 1350, Loss: 0.009911518543958664\n",
            "Epoch 5, Batch 716 / 1350, Loss: 0.23273923993110657\n",
            "Epoch 5, Batch 717 / 1350, Loss: 0.12647540867328644\n",
            "Epoch 5, Batch 718 / 1350, Loss: 0.02444608323276043\n",
            "Epoch 5, Batch 719 / 1350, Loss: 0.15083187818527222\n",
            "Epoch 5, Batch 720 / 1350, Loss: 0.25953859090805054\n",
            "Epoch 5, Batch 721 / 1350, Loss: 0.5877247452735901\n",
            "Epoch 5, Batch 722 / 1350, Loss: 0.015171406790614128\n",
            "Epoch 5, Batch 723 / 1350, Loss: 0.12488029152154922\n",
            "Epoch 5, Batch 724 / 1350, Loss: 0.09890082478523254\n",
            "Epoch 5, Batch 725 / 1350, Loss: 0.006451697554439306\n",
            "Epoch 5, Batch 726 / 1350, Loss: 0.5684528946876526\n",
            "Epoch 5, Batch 727 / 1350, Loss: 0.007517612539231777\n",
            "Epoch 5, Batch 728 / 1350, Loss: 0.09938262403011322\n",
            "Epoch 5, Batch 729 / 1350, Loss: 0.006198682356625795\n",
            "Epoch 5, Batch 730 / 1350, Loss: 0.006949582137167454\n",
            "Epoch 5, Batch 731 / 1350, Loss: 0.02386477030813694\n",
            "Epoch 5, Batch 732 / 1350, Loss: 0.02774813398718834\n",
            "Epoch 5, Batch 733 / 1350, Loss: 0.0031361496075987816\n",
            "Epoch 5, Batch 734 / 1350, Loss: 0.03516469895839691\n",
            "Epoch 5, Batch 735 / 1350, Loss: 0.008109858259558678\n",
            "Epoch 5, Batch 736 / 1350, Loss: 0.004289836157113314\n",
            "Epoch 5, Batch 737 / 1350, Loss: 0.3863241672515869\n",
            "Epoch 5, Batch 738 / 1350, Loss: 0.0044682081788778305\n",
            "Epoch 5, Batch 739 / 1350, Loss: 0.09268087893724442\n",
            "Epoch 5, Batch 740 / 1350, Loss: 0.004933477379381657\n",
            "Epoch 5, Batch 741 / 1350, Loss: 0.0034707291051745415\n",
            "Epoch 5, Batch 742 / 1350, Loss: 0.004109610337764025\n",
            "Epoch 5, Batch 743 / 1350, Loss: 0.013292978517711163\n",
            "Epoch 5, Batch 744 / 1350, Loss: 0.08781763166189194\n",
            "Epoch 5, Batch 745 / 1350, Loss: 0.0031441370956599712\n",
            "Epoch 5, Batch 746 / 1350, Loss: 0.005154429469257593\n",
            "Epoch 5, Batch 747 / 1350, Loss: 1.824915885925293\n",
            "Epoch 5, Batch 748 / 1350, Loss: 1.0937122106552124\n",
            "Epoch 5, Batch 749 / 1350, Loss: 0.7729944586753845\n",
            "Epoch 5, Batch 750 / 1350, Loss: 0.00857546553015709\n",
            "Epoch 5, Batch 751 / 1350, Loss: 0.010308489203453064\n",
            "Epoch 5, Batch 752 / 1350, Loss: 0.022523781284689903\n",
            "Epoch 5, Batch 753 / 1350, Loss: 0.006142216268926859\n",
            "Epoch 5, Batch 754 / 1350, Loss: 0.006160471122711897\n",
            "Epoch 5, Batch 755 / 1350, Loss: 0.009830262511968613\n",
            "Epoch 5, Batch 756 / 1350, Loss: 0.014659344218671322\n",
            "Epoch 5, Batch 757 / 1350, Loss: 0.02234022691845894\n",
            "Epoch 5, Batch 758 / 1350, Loss: 0.1671626716852188\n",
            "Epoch 5, Batch 759 / 1350, Loss: 0.1067325621843338\n",
            "Epoch 5, Batch 760 / 1350, Loss: 0.02823362499475479\n",
            "Epoch 5, Batch 761 / 1350, Loss: 0.03680239990353584\n",
            "Epoch 5, Batch 762 / 1350, Loss: 0.03529971465468407\n",
            "Epoch 5, Batch 763 / 1350, Loss: 0.11226599663496017\n",
            "Epoch 5, Batch 764 / 1350, Loss: 0.1031622663140297\n",
            "Epoch 5, Batch 765 / 1350, Loss: 0.04420565813779831\n",
            "Epoch 5, Batch 766 / 1350, Loss: 0.008420845493674278\n",
            "Epoch 5, Batch 767 / 1350, Loss: 0.4912734031677246\n",
            "Epoch 5, Batch 768 / 1350, Loss: 0.14582084119319916\n",
            "Epoch 5, Batch 769 / 1350, Loss: 0.014412442222237587\n",
            "Epoch 5, Batch 770 / 1350, Loss: 0.07878990471363068\n",
            "Epoch 5, Batch 771 / 1350, Loss: 0.02761874347925186\n",
            "Epoch 5, Batch 772 / 1350, Loss: 0.047958094626665115\n",
            "Epoch 5, Batch 773 / 1350, Loss: 0.043035030364990234\n",
            "Epoch 5, Batch 774 / 1350, Loss: 0.18837052583694458\n",
            "Epoch 5, Batch 775 / 1350, Loss: 0.010568447411060333\n",
            "Epoch 5, Batch 776 / 1350, Loss: 0.023075615987181664\n",
            "Epoch 5, Batch 777 / 1350, Loss: 0.42122694849967957\n",
            "Epoch 5, Batch 778 / 1350, Loss: 0.0510522797703743\n",
            "Epoch 5, Batch 779 / 1350, Loss: 0.2410385012626648\n",
            "Epoch 5, Batch 780 / 1350, Loss: 0.04182146489620209\n",
            "Epoch 5, Batch 781 / 1350, Loss: 0.05434006452560425\n",
            "Epoch 5, Batch 782 / 1350, Loss: 0.07734819501638412\n",
            "Epoch 5, Batch 783 / 1350, Loss: 0.061612553894519806\n",
            "Epoch 5, Batch 784 / 1350, Loss: 0.009508298709988594\n",
            "Epoch 5, Batch 785 / 1350, Loss: 0.004224803298711777\n",
            "Epoch 5, Batch 786 / 1350, Loss: 0.06591755151748657\n",
            "Epoch 5, Batch 787 / 1350, Loss: 0.023689597845077515\n",
            "Epoch 5, Batch 788 / 1350, Loss: 0.003659564070403576\n",
            "Epoch 5, Batch 789 / 1350, Loss: 0.008337552659213543\n",
            "Epoch 5, Batch 790 / 1350, Loss: 0.41328275203704834\n",
            "Epoch 5, Batch 791 / 1350, Loss: 0.00417591305449605\n",
            "Epoch 5, Batch 792 / 1350, Loss: 0.0035077042412012815\n",
            "Epoch 5, Batch 793 / 1350, Loss: 0.4215412735939026\n",
            "Epoch 5, Batch 794 / 1350, Loss: 0.27195054292678833\n",
            "Epoch 5, Batch 795 / 1350, Loss: 0.024191249161958694\n",
            "Epoch 5, Batch 796 / 1350, Loss: 0.01906992867588997\n",
            "Epoch 5, Batch 797 / 1350, Loss: 0.39334189891815186\n",
            "Epoch 5, Batch 798 / 1350, Loss: 0.028255125507712364\n",
            "Epoch 5, Batch 799 / 1350, Loss: 0.01706397905945778\n",
            "Epoch 5, Batch 800 / 1350, Loss: 0.06930869817733765\n",
            "Epoch 5, Batch 801 / 1350, Loss: 0.04529492184519768\n",
            "Epoch 5, Batch 802 / 1350, Loss: 0.03909377008676529\n",
            "Epoch 5, Batch 803 / 1350, Loss: 0.016128791496157646\n",
            "Epoch 5, Batch 804 / 1350, Loss: 0.004747115541249514\n",
            "Epoch 5, Batch 805 / 1350, Loss: 0.036387499421834946\n",
            "Epoch 5, Batch 806 / 1350, Loss: 0.10346394777297974\n",
            "Epoch 5, Batch 807 / 1350, Loss: 0.056113868951797485\n",
            "Epoch 5, Batch 808 / 1350, Loss: 0.005372405983507633\n",
            "Epoch 5, Batch 809 / 1350, Loss: 0.1451926827430725\n",
            "Epoch 5, Batch 810 / 1350, Loss: 0.04387236386537552\n",
            "Epoch 5, Batch 811 / 1350, Loss: 0.004649166017770767\n",
            "Epoch 5, Batch 812 / 1350, Loss: 0.003151082433760166\n",
            "Epoch 5, Batch 813 / 1350, Loss: 0.008333941921591759\n",
            "Epoch 5, Batch 814 / 1350, Loss: 0.4782155156135559\n",
            "Epoch 5, Batch 815 / 1350, Loss: 0.17478221654891968\n",
            "Epoch 5, Batch 816 / 1350, Loss: 0.05958549305796623\n",
            "Epoch 5, Batch 817 / 1350, Loss: 0.060033295303583145\n",
            "Epoch 5, Batch 818 / 1350, Loss: 0.002988016465678811\n",
            "Epoch 5, Batch 819 / 1350, Loss: 0.3039306402206421\n",
            "Epoch 5, Batch 820 / 1350, Loss: 0.0037420892622321844\n",
            "Epoch 5, Batch 821 / 1350, Loss: 0.003609727369621396\n",
            "Epoch 5, Batch 822 / 1350, Loss: 0.006902162916958332\n",
            "Epoch 5, Batch 823 / 1350, Loss: 0.09094090759754181\n",
            "Epoch 5, Batch 824 / 1350, Loss: 0.003919342532753944\n",
            "Epoch 5, Batch 825 / 1350, Loss: 0.007916862145066261\n",
            "Epoch 5, Batch 826 / 1350, Loss: 0.006282113492488861\n",
            "Epoch 5, Batch 827 / 1350, Loss: 0.0102610494941473\n",
            "Epoch 5, Batch 828 / 1350, Loss: 0.12251165509223938\n",
            "Epoch 5, Batch 829 / 1350, Loss: 0.023245491087436676\n",
            "Epoch 5, Batch 830 / 1350, Loss: 0.3455544412136078\n",
            "Epoch 5, Batch 831 / 1350, Loss: 0.16910162568092346\n",
            "Epoch 5, Batch 832 / 1350, Loss: 0.048937827348709106\n",
            "Epoch 5, Batch 833 / 1350, Loss: 0.014496788382530212\n",
            "Epoch 5, Batch 834 / 1350, Loss: 0.37215656042099\n",
            "Epoch 5, Batch 835 / 1350, Loss: 0.0057562123984098434\n",
            "Epoch 5, Batch 836 / 1350, Loss: 0.0034353595692664385\n",
            "Epoch 5, Batch 837 / 1350, Loss: 0.03604622557759285\n",
            "Epoch 5, Batch 838 / 1350, Loss: 0.030574465170502663\n",
            "Epoch 5, Batch 839 / 1350, Loss: 0.023987997323274612\n",
            "Epoch 5, Batch 840 / 1350, Loss: 0.010762451216578484\n",
            "Epoch 5, Batch 841 / 1350, Loss: 0.003544879611581564\n",
            "Epoch 5, Batch 842 / 1350, Loss: 0.016287945210933685\n",
            "Epoch 5, Batch 843 / 1350, Loss: 0.13058851659297943\n",
            "Epoch 5, Batch 844 / 1350, Loss: 0.010907134041190147\n",
            "Epoch 5, Batch 845 / 1350, Loss: 0.002823913935571909\n",
            "Epoch 5, Batch 846 / 1350, Loss: 0.026740768924355507\n",
            "Epoch 5, Batch 847 / 1350, Loss: 0.003009594976902008\n",
            "Epoch 5, Batch 848 / 1350, Loss: 0.08946942538022995\n",
            "Epoch 5, Batch 849 / 1350, Loss: 0.028587203472852707\n",
            "Epoch 5, Batch 850 / 1350, Loss: 0.005522227380424738\n",
            "Epoch 5, Batch 851 / 1350, Loss: 0.005952376872301102\n",
            "Epoch 5, Batch 852 / 1350, Loss: 0.003689244855195284\n",
            "Epoch 5, Batch 853 / 1350, Loss: 0.05823487788438797\n",
            "Epoch 5, Batch 854 / 1350, Loss: 0.002805949654430151\n",
            "Epoch 5, Batch 855 / 1350, Loss: 0.004289097152650356\n",
            "Epoch 5, Batch 856 / 1350, Loss: 0.05839637666940689\n",
            "Epoch 5, Batch 857 / 1350, Loss: 0.0040397560223937035\n",
            "Epoch 5, Batch 858 / 1350, Loss: 0.002729348372668028\n",
            "Epoch 5, Batch 859 / 1350, Loss: 0.005327981431037188\n",
            "Epoch 5, Batch 860 / 1350, Loss: 0.8571312427520752\n",
            "Epoch 5, Batch 861 / 1350, Loss: 0.0043402500450611115\n",
            "Epoch 5, Batch 862 / 1350, Loss: 0.003747934941202402\n",
            "Epoch 5, Batch 863 / 1350, Loss: 0.47602424025535583\n",
            "Epoch 5, Batch 864 / 1350, Loss: 0.17955371737480164\n",
            "Epoch 5, Batch 865 / 1350, Loss: 0.07335741817951202\n",
            "Epoch 5, Batch 866 / 1350, Loss: 0.010751474648714066\n",
            "Epoch 5, Batch 867 / 1350, Loss: 0.0034252589102834463\n",
            "Epoch 5, Batch 868 / 1350, Loss: 0.15810896456241608\n",
            "Epoch 5, Batch 869 / 1350, Loss: 0.004387568682432175\n",
            "Epoch 5, Batch 870 / 1350, Loss: 0.09327492117881775\n",
            "Epoch 5, Batch 871 / 1350, Loss: 0.16982321441173553\n",
            "Epoch 5, Batch 872 / 1350, Loss: 0.004172113258391619\n",
            "Epoch 5, Batch 873 / 1350, Loss: 0.3847291171550751\n",
            "Epoch 5, Batch 874 / 1350, Loss: 0.0038850796408951283\n",
            "Epoch 5, Batch 875 / 1350, Loss: 0.26671162247657776\n",
            "Epoch 5, Batch 876 / 1350, Loss: 0.007685858756303787\n",
            "Epoch 5, Batch 877 / 1350, Loss: 0.1302376538515091\n",
            "Epoch 5, Batch 878 / 1350, Loss: 0.010518170893192291\n",
            "Epoch 5, Batch 879 / 1350, Loss: 0.027871571481227875\n",
            "Epoch 5, Batch 880 / 1350, Loss: 0.002623798791319132\n",
            "Epoch 5, Batch 881 / 1350, Loss: 0.027617890387773514\n",
            "Epoch 5, Batch 882 / 1350, Loss: 0.031767360866069794\n",
            "Epoch 5, Batch 883 / 1350, Loss: 0.003649200079962611\n",
            "Epoch 5, Batch 884 / 1350, Loss: 0.27020540833473206\n",
            "Epoch 5, Batch 885 / 1350, Loss: 0.015715744346380234\n",
            "Epoch 5, Batch 886 / 1350, Loss: 0.4371832609176636\n",
            "Epoch 5, Batch 887 / 1350, Loss: 0.0027329158037900925\n",
            "Epoch 5, Batch 888 / 1350, Loss: 0.006874711252748966\n",
            "Epoch 5, Batch 889 / 1350, Loss: 0.22975550591945648\n",
            "Epoch 5, Batch 890 / 1350, Loss: 0.027860764414072037\n",
            "Epoch 5, Batch 891 / 1350, Loss: 1.5359843969345093\n",
            "Epoch 5, Batch 892 / 1350, Loss: 0.03622954711318016\n",
            "Epoch 5, Batch 893 / 1350, Loss: 0.0043774922378361225\n",
            "Epoch 5, Batch 894 / 1350, Loss: 0.0029278204310685396\n",
            "Epoch 5, Batch 895 / 1350, Loss: 0.011765539646148682\n",
            "Epoch 5, Batch 896 / 1350, Loss: 0.005452028475701809\n",
            "Epoch 5, Batch 897 / 1350, Loss: 0.00327731529250741\n",
            "Epoch 5, Batch 898 / 1350, Loss: 0.6620760560035706\n",
            "Epoch 5, Batch 899 / 1350, Loss: 1.8168730735778809\n",
            "Epoch 5, Batch 900 / 1350, Loss: 0.0034886752255260944\n",
            "Epoch 5, Batch 901 / 1350, Loss: 0.005126831121742725\n",
            "Epoch 5, Batch 902 / 1350, Loss: 0.0820193961262703\n",
            "Epoch 5, Batch 903 / 1350, Loss: 0.005625225603580475\n",
            "Epoch 5, Batch 904 / 1350, Loss: 0.006948140449821949\n",
            "Epoch 5, Batch 905 / 1350, Loss: 0.004700886085629463\n",
            "Epoch 5, Batch 906 / 1350, Loss: 0.0075400276109576225\n",
            "Epoch 5, Batch 907 / 1350, Loss: 0.45612993836402893\n",
            "Epoch 5, Batch 908 / 1350, Loss: 0.18810060620307922\n",
            "Epoch 5, Batch 909 / 1350, Loss: 0.025485040619969368\n",
            "Epoch 5, Batch 910 / 1350, Loss: 0.00330478698015213\n",
            "Epoch 5, Batch 911 / 1350, Loss: 0.03702622652053833\n",
            "Epoch 5, Batch 912 / 1350, Loss: 0.407552033662796\n",
            "Epoch 5, Batch 913 / 1350, Loss: 0.007965516299009323\n",
            "Epoch 5, Batch 914 / 1350, Loss: 0.0063585457392036915\n",
            "Epoch 5, Batch 915 / 1350, Loss: 0.029819097369909286\n",
            "Epoch 5, Batch 916 / 1350, Loss: 0.004231381230056286\n",
            "Epoch 5, Batch 917 / 1350, Loss: 0.011949008330702782\n",
            "Epoch 5, Batch 918 / 1350, Loss: 0.0038986257277429104\n",
            "Epoch 5, Batch 919 / 1350, Loss: 0.0711514949798584\n",
            "Epoch 5, Batch 920 / 1350, Loss: 0.0070711905136704445\n",
            "Epoch 5, Batch 921 / 1350, Loss: 0.30178070068359375\n",
            "Epoch 5, Batch 922 / 1350, Loss: 0.008841220289468765\n",
            "Epoch 5, Batch 923 / 1350, Loss: 0.27733439207077026\n",
            "Epoch 5, Batch 924 / 1350, Loss: 0.00558222271502018\n",
            "Epoch 5, Batch 925 / 1350, Loss: 0.0342131182551384\n",
            "Epoch 5, Batch 926 / 1350, Loss: 0.10516911745071411\n",
            "Epoch 5, Batch 927 / 1350, Loss: 0.12993338704109192\n",
            "Epoch 5, Batch 928 / 1350, Loss: 0.00792925339192152\n",
            "Epoch 5, Batch 929 / 1350, Loss: 0.005978249944746494\n",
            "Epoch 5, Batch 930 / 1350, Loss: 1.056455373764038\n",
            "Epoch 5, Batch 931 / 1350, Loss: 0.7956089973449707\n",
            "Epoch 5, Batch 932 / 1350, Loss: 0.1656343787908554\n",
            "Epoch 5, Batch 933 / 1350, Loss: 0.33905425667762756\n",
            "Epoch 5, Batch 934 / 1350, Loss: 0.01712915673851967\n",
            "Epoch 5, Batch 935 / 1350, Loss: 0.044382739812135696\n",
            "Epoch 5, Batch 936 / 1350, Loss: 0.01909393072128296\n",
            "Epoch 5, Batch 937 / 1350, Loss: 0.03165728971362114\n",
            "Epoch 5, Batch 938 / 1350, Loss: 0.17866617441177368\n",
            "Epoch 5, Batch 939 / 1350, Loss: 0.021048521623015404\n",
            "Epoch 5, Batch 940 / 1350, Loss: 0.027829257771372795\n",
            "Epoch 5, Batch 941 / 1350, Loss: 0.032199472188949585\n",
            "Epoch 5, Batch 942 / 1350, Loss: 0.41885906457901\n",
            "Epoch 5, Batch 943 / 1350, Loss: 0.059617482125759125\n",
            "Epoch 5, Batch 944 / 1350, Loss: 0.1428529918193817\n",
            "Epoch 5, Batch 945 / 1350, Loss: 0.0373227633535862\n",
            "Epoch 5, Batch 946 / 1350, Loss: 0.021280566230416298\n",
            "Epoch 5, Batch 947 / 1350, Loss: 0.8997477889060974\n",
            "Epoch 5, Batch 948 / 1350, Loss: 0.0047779991291463375\n",
            "Epoch 5, Batch 949 / 1350, Loss: 0.007718496955931187\n",
            "Epoch 5, Batch 950 / 1350, Loss: 0.022577576339244843\n",
            "Epoch 5, Batch 951 / 1350, Loss: 0.028619058430194855\n",
            "Epoch 5, Batch 952 / 1350, Loss: 0.00985809601843357\n",
            "Epoch 5, Batch 953 / 1350, Loss: 0.4207364618778229\n",
            "Epoch 5, Batch 954 / 1350, Loss: 0.07679498940706253\n",
            "Epoch 5, Batch 955 / 1350, Loss: 0.12577039003372192\n",
            "Epoch 5, Batch 956 / 1350, Loss: 0.012775340117514133\n",
            "Epoch 5, Batch 957 / 1350, Loss: 0.1038942039012909\n",
            "Epoch 5, Batch 958 / 1350, Loss: 0.040211133658885956\n",
            "Epoch 5, Batch 959 / 1350, Loss: 0.06806550920009613\n",
            "Epoch 5, Batch 960 / 1350, Loss: 0.18406623601913452\n",
            "Epoch 5, Batch 961 / 1350, Loss: 0.058582279831171036\n",
            "Epoch 5, Batch 962 / 1350, Loss: 0.021122939884662628\n",
            "Epoch 5, Batch 963 / 1350, Loss: 0.01583356410264969\n",
            "Epoch 5, Batch 964 / 1350, Loss: 0.014649060554802418\n",
            "Epoch 5, Batch 965 / 1350, Loss: 0.45611128211021423\n",
            "Epoch 5, Batch 966 / 1350, Loss: 0.038745202124118805\n",
            "Epoch 5, Batch 967 / 1350, Loss: 0.17426040768623352\n",
            "Epoch 5, Batch 968 / 1350, Loss: 0.05263563618063927\n",
            "Epoch 5, Batch 969 / 1350, Loss: 0.01335038710385561\n",
            "Epoch 5, Batch 970 / 1350, Loss: 0.009154717437922955\n",
            "Epoch 5, Batch 971 / 1350, Loss: 0.028600387275218964\n",
            "Epoch 5, Batch 972 / 1350, Loss: 0.4476095736026764\n",
            "Epoch 5, Batch 973 / 1350, Loss: 0.25431913137435913\n",
            "Epoch 5, Batch 974 / 1350, Loss: 0.020897576585412025\n",
            "Epoch 5, Batch 975 / 1350, Loss: 0.3358279764652252\n",
            "Epoch 5, Batch 976 / 1350, Loss: 0.018569400534033775\n",
            "Epoch 5, Batch 977 / 1350, Loss: 0.24145682156085968\n",
            "Epoch 5, Batch 978 / 1350, Loss: 0.0222000889480114\n",
            "Epoch 5, Batch 979 / 1350, Loss: 0.07936415076255798\n",
            "Epoch 5, Batch 980 / 1350, Loss: 0.004969777539372444\n",
            "Epoch 5, Batch 981 / 1350, Loss: 0.10941769182682037\n",
            "Epoch 5, Batch 982 / 1350, Loss: 0.19417913258075714\n",
            "Epoch 5, Batch 983 / 1350, Loss: 0.031581178307533264\n",
            "Epoch 5, Batch 984 / 1350, Loss: 0.006506589241325855\n",
            "Epoch 5, Batch 985 / 1350, Loss: 0.07819972932338715\n",
            "Epoch 5, Batch 986 / 1350, Loss: 0.0042957402765750885\n",
            "Epoch 5, Batch 987 / 1350, Loss: 0.021704746410250664\n",
            "Epoch 5, Batch 988 / 1350, Loss: 0.0035681435838341713\n",
            "Epoch 5, Batch 989 / 1350, Loss: 0.05134273320436478\n",
            "Epoch 5, Batch 990 / 1350, Loss: 0.027710484340786934\n",
            "Epoch 5, Batch 991 / 1350, Loss: 0.017676273360848427\n",
            "Epoch 5, Batch 992 / 1350, Loss: 0.005276788026094437\n",
            "Epoch 5, Batch 993 / 1350, Loss: 0.0082993283867836\n",
            "Epoch 5, Batch 994 / 1350, Loss: 0.009132527746260166\n",
            "Epoch 5, Batch 995 / 1350, Loss: 0.004683641716837883\n",
            "Epoch 5, Batch 996 / 1350, Loss: 0.008364774286746979\n",
            "Epoch 5, Batch 997 / 1350, Loss: 0.03945554420351982\n",
            "Epoch 5, Batch 998 / 1350, Loss: 0.0201053936034441\n",
            "Epoch 5, Batch 999 / 1350, Loss: 0.7294884920120239\n",
            "Epoch 5, Batch 1000 / 1350, Loss: 0.025360561907291412\n",
            "Epoch 5, Batch 1001 / 1350, Loss: 0.005357975140213966\n",
            "Epoch 5, Batch 1002 / 1350, Loss: 0.006603550165891647\n",
            "Epoch 5, Batch 1003 / 1350, Loss: 0.23878100514411926\n",
            "Epoch 5, Batch 1004 / 1350, Loss: 0.0472707599401474\n",
            "Epoch 5, Batch 1005 / 1350, Loss: 1.172992467880249\n",
            "Epoch 5, Batch 1006 / 1350, Loss: 0.003554217517375946\n",
            "Epoch 5, Batch 1007 / 1350, Loss: 0.014164706692099571\n",
            "Epoch 5, Batch 1008 / 1350, Loss: 0.36127933859825134\n",
            "Epoch 5, Batch 1009 / 1350, Loss: 0.05064012110233307\n",
            "Epoch 5, Batch 1010 / 1350, Loss: 0.13495516777038574\n",
            "Epoch 5, Batch 1011 / 1350, Loss: 0.034102488309144974\n",
            "Epoch 5, Batch 1012 / 1350, Loss: 0.013232477009296417\n",
            "Epoch 5, Batch 1013 / 1350, Loss: 0.014115756377577782\n",
            "Epoch 5, Batch 1014 / 1350, Loss: 0.004048717673867941\n",
            "Epoch 5, Batch 1015 / 1350, Loss: 0.07832954823970795\n",
            "Epoch 5, Batch 1016 / 1350, Loss: 0.043911851942539215\n",
            "Epoch 5, Batch 1017 / 1350, Loss: 0.02335885725915432\n",
            "Epoch 5, Batch 1018 / 1350, Loss: 0.011581286787986755\n",
            "Epoch 5, Batch 1019 / 1350, Loss: 0.11140985041856766\n",
            "Epoch 5, Batch 1020 / 1350, Loss: 0.003745460184291005\n",
            "Epoch 5, Batch 1021 / 1350, Loss: 0.619954526424408\n",
            "Epoch 5, Batch 1022 / 1350, Loss: 0.2867090404033661\n",
            "Epoch 5, Batch 1023 / 1350, Loss: 0.004171261563897133\n",
            "Epoch 5, Batch 1024 / 1350, Loss: 0.014767283573746681\n",
            "Epoch 5, Batch 1025 / 1350, Loss: 0.2105751931667328\n",
            "Epoch 5, Batch 1026 / 1350, Loss: 0.010114356875419617\n",
            "Epoch 5, Batch 1027 / 1350, Loss: 0.06758128851652145\n",
            "Epoch 5, Batch 1028 / 1350, Loss: 0.3452618420124054\n",
            "Epoch 5, Batch 1029 / 1350, Loss: 0.23330214619636536\n",
            "Epoch 5, Batch 1030 / 1350, Loss: 0.09756901860237122\n",
            "Epoch 5, Batch 1031 / 1350, Loss: 0.010458322241902351\n",
            "Epoch 5, Batch 1032 / 1350, Loss: 0.018237557262182236\n",
            "Epoch 5, Batch 1033 / 1350, Loss: 0.013554647564888\n",
            "Epoch 5, Batch 1034 / 1350, Loss: 0.08367877453565598\n",
            "Epoch 5, Batch 1035 / 1350, Loss: 0.023770097643136978\n",
            "Epoch 5, Batch 1036 / 1350, Loss: 0.033044733107089996\n",
            "Epoch 5, Batch 1037 / 1350, Loss: 0.011317997239530087\n",
            "Epoch 5, Batch 1038 / 1350, Loss: 0.018088161945343018\n",
            "Epoch 5, Batch 1039 / 1350, Loss: 0.005458038300275803\n",
            "Epoch 5, Batch 1040 / 1350, Loss: 0.22827154397964478\n",
            "Epoch 5, Batch 1041 / 1350, Loss: 0.007635554764419794\n",
            "Epoch 5, Batch 1042 / 1350, Loss: 0.3686795234680176\n",
            "Epoch 5, Batch 1043 / 1350, Loss: 0.209557443857193\n",
            "Epoch 5, Batch 1044 / 1350, Loss: 0.004981947597116232\n",
            "Epoch 5, Batch 1045 / 1350, Loss: 0.39901360869407654\n",
            "Epoch 5, Batch 1046 / 1350, Loss: 0.058912016451358795\n",
            "Epoch 5, Batch 1047 / 1350, Loss: 0.5029874444007874\n",
            "Epoch 5, Batch 1048 / 1350, Loss: 0.010375267826020718\n",
            "Epoch 5, Batch 1049 / 1350, Loss: 0.005395233165472746\n",
            "Epoch 5, Batch 1050 / 1350, Loss: 0.21554629504680634\n",
            "Epoch 5, Batch 1051 / 1350, Loss: 0.03431814908981323\n",
            "Epoch 5, Batch 1052 / 1350, Loss: 0.0032835411839187145\n",
            "Epoch 5, Batch 1053 / 1350, Loss: 0.007068573962897062\n",
            "Epoch 5, Batch 1054 / 1350, Loss: 0.016629204154014587\n",
            "Epoch 5, Batch 1055 / 1350, Loss: 0.35193920135498047\n",
            "Epoch 5, Batch 1056 / 1350, Loss: 0.45972180366516113\n",
            "Epoch 5, Batch 1057 / 1350, Loss: 0.023071829229593277\n",
            "Epoch 5, Batch 1058 / 1350, Loss: 0.022350165992975235\n",
            "Epoch 5, Batch 1059 / 1350, Loss: 0.39269202947616577\n",
            "Epoch 5, Batch 1060 / 1350, Loss: 0.06941872835159302\n",
            "Epoch 5, Batch 1061 / 1350, Loss: 0.009847459383308887\n",
            "Epoch 5, Batch 1062 / 1350, Loss: 0.004633063450455666\n",
            "Epoch 5, Batch 1063 / 1350, Loss: 0.06767783313989639\n",
            "Epoch 5, Batch 1064 / 1350, Loss: 0.010529836639761925\n",
            "Epoch 5, Batch 1065 / 1350, Loss: 0.005236462224274874\n",
            "Epoch 5, Batch 1066 / 1350, Loss: 0.19060246646404266\n",
            "Epoch 5, Batch 1067 / 1350, Loss: 0.05464955046772957\n",
            "Epoch 5, Batch 1068 / 1350, Loss: 0.06465096771717072\n",
            "Epoch 5, Batch 1069 / 1350, Loss: 0.00843396782875061\n",
            "Epoch 5, Batch 1070 / 1350, Loss: 0.591221272945404\n",
            "Epoch 5, Batch 1071 / 1350, Loss: 0.007600052747875452\n",
            "Epoch 5, Batch 1072 / 1350, Loss: 0.03137483820319176\n",
            "Epoch 5, Batch 1073 / 1350, Loss: 0.009945476427674294\n",
            "Epoch 5, Batch 1074 / 1350, Loss: 0.29680708050727844\n",
            "Epoch 5, Batch 1075 / 1350, Loss: 0.08488348871469498\n",
            "Epoch 5, Batch 1076 / 1350, Loss: 0.17022345960140228\n",
            "Epoch 5, Batch 1077 / 1350, Loss: 0.12557072937488556\n",
            "Epoch 5, Batch 1078 / 1350, Loss: 0.03967374935746193\n",
            "Epoch 5, Batch 1079 / 1350, Loss: 0.010516403242945671\n",
            "Epoch 5, Batch 1080 / 1350, Loss: 0.00901040993630886\n",
            "Epoch 5, Batch 1081 / 1350, Loss: 0.0272474754601717\n",
            "Epoch 5, Batch 1082 / 1350, Loss: 0.008014294318854809\n",
            "Epoch 5, Batch 1083 / 1350, Loss: 0.026626404374837875\n",
            "Epoch 5, Batch 1084 / 1350, Loss: 0.017118245363235474\n",
            "Epoch 5, Batch 1085 / 1350, Loss: 0.05147547274827957\n",
            "Epoch 5, Batch 1086 / 1350, Loss: 0.003616821952164173\n",
            "Epoch 5, Batch 1087 / 1350, Loss: 0.002838573884218931\n",
            "Epoch 5, Batch 1088 / 1350, Loss: 0.003099533263593912\n",
            "Epoch 5, Batch 1089 / 1350, Loss: 0.21428002417087555\n",
            "Epoch 5, Batch 1090 / 1350, Loss: 0.0666613057255745\n",
            "Epoch 5, Batch 1091 / 1350, Loss: 0.007230554707348347\n",
            "Epoch 5, Batch 1092 / 1350, Loss: 0.3714674711227417\n",
            "Epoch 5, Batch 1093 / 1350, Loss: 0.008185610175132751\n",
            "Epoch 5, Batch 1094 / 1350, Loss: 0.2243616133928299\n",
            "Epoch 5, Batch 1095 / 1350, Loss: 0.05809716135263443\n",
            "Epoch 5, Batch 1096 / 1350, Loss: 0.01830676570534706\n",
            "Epoch 5, Batch 1097 / 1350, Loss: 0.08924935758113861\n",
            "Epoch 5, Batch 1098 / 1350, Loss: 0.024537570774555206\n",
            "Epoch 5, Batch 1099 / 1350, Loss: 0.11417840421199799\n",
            "Epoch 5, Batch 1100 / 1350, Loss: 0.030673442408442497\n",
            "Epoch 5, Batch 1101 / 1350, Loss: 0.02876029536128044\n",
            "Epoch 5, Batch 1102 / 1350, Loss: 0.006078668870031834\n",
            "Epoch 5, Batch 1103 / 1350, Loss: 0.05360132455825806\n",
            "Epoch 5, Batch 1104 / 1350, Loss: 0.0627545639872551\n",
            "Epoch 5, Batch 1105 / 1350, Loss: 0.05090755224227905\n",
            "Epoch 5, Batch 1106 / 1350, Loss: 0.1268031746149063\n",
            "Epoch 5, Batch 1107 / 1350, Loss: 0.15065160393714905\n",
            "Epoch 5, Batch 1108 / 1350, Loss: 0.14023223519325256\n",
            "Epoch 5, Batch 1109 / 1350, Loss: 0.03624463453888893\n",
            "Epoch 5, Batch 1110 / 1350, Loss: 0.017032569274306297\n",
            "Epoch 5, Batch 1111 / 1350, Loss: 0.012053363025188446\n",
            "Epoch 5, Batch 1112 / 1350, Loss: 0.0028127250261604786\n",
            "Epoch 5, Batch 1113 / 1350, Loss: 0.0027552437968552113\n",
            "Epoch 5, Batch 1114 / 1350, Loss: 0.002984615508466959\n",
            "Epoch 5, Batch 1115 / 1350, Loss: 0.0034946417436003685\n",
            "Epoch 5, Batch 1116 / 1350, Loss: 0.015759482979774475\n",
            "Epoch 5, Batch 1117 / 1350, Loss: 0.0026779291220009327\n",
            "Epoch 5, Batch 1118 / 1350, Loss: 0.04488057643175125\n",
            "Epoch 5, Batch 1119 / 1350, Loss: 0.005011805333197117\n",
            "Epoch 5, Batch 1120 / 1350, Loss: 0.005956391803920269\n",
            "Epoch 5, Batch 1121 / 1350, Loss: 0.002838869346305728\n",
            "Epoch 5, Batch 1122 / 1350, Loss: 0.0037533948197960854\n",
            "Epoch 5, Batch 1123 / 1350, Loss: 0.031453751027584076\n",
            "Epoch 5, Batch 1124 / 1350, Loss: 0.03753184899687767\n",
            "Epoch 5, Batch 1125 / 1350, Loss: 0.0025444815400987864\n",
            "Epoch 5, Batch 1126 / 1350, Loss: 0.04932141304016113\n",
            "Epoch 5, Batch 1127 / 1350, Loss: 0.007796573918312788\n",
            "Epoch 5, Batch 1128 / 1350, Loss: 1.589534878730774\n",
            "Epoch 5, Batch 1129 / 1350, Loss: 0.004237857647240162\n",
            "Epoch 5, Batch 1130 / 1350, Loss: 0.24325153231620789\n",
            "Epoch 5, Batch 1131 / 1350, Loss: 0.003002389334142208\n",
            "Epoch 5, Batch 1132 / 1350, Loss: 1.5109343528747559\n",
            "Epoch 5, Batch 1133 / 1350, Loss: 0.5687142014503479\n",
            "Epoch 5, Batch 1134 / 1350, Loss: 0.003001246601343155\n",
            "Epoch 5, Batch 1135 / 1350, Loss: 0.018823161721229553\n",
            "Epoch 5, Batch 1136 / 1350, Loss: 0.015839843079447746\n",
            "Epoch 5, Batch 1137 / 1350, Loss: 0.4050954282283783\n",
            "Epoch 5, Batch 1138 / 1350, Loss: 0.022719569504261017\n",
            "Epoch 5, Batch 1139 / 1350, Loss: 0.0037321497220546007\n",
            "Epoch 5, Batch 1140 / 1350, Loss: 0.01801757514476776\n",
            "Epoch 5, Batch 1141 / 1350, Loss: 0.8917522430419922\n",
            "Epoch 5, Batch 1142 / 1350, Loss: 0.006244327407330275\n",
            "Epoch 5, Batch 1143 / 1350, Loss: 0.007415741682052612\n",
            "Epoch 5, Batch 1144 / 1350, Loss: 1.330012559890747\n",
            "Epoch 5, Batch 1145 / 1350, Loss: 0.008830730803310871\n",
            "Epoch 5, Batch 1146 / 1350, Loss: 0.11077018082141876\n",
            "Epoch 5, Batch 1147 / 1350, Loss: 0.029615432024002075\n",
            "Epoch 5, Batch 1148 / 1350, Loss: 0.010544480755925179\n",
            "Epoch 5, Batch 1149 / 1350, Loss: 0.01874452829360962\n",
            "Epoch 5, Batch 1150 / 1350, Loss: 0.033986594527959824\n",
            "Epoch 5, Batch 1151 / 1350, Loss: 0.022594507783651352\n",
            "Epoch 5, Batch 1152 / 1350, Loss: 0.012615730985999107\n",
            "Epoch 5, Batch 1153 / 1350, Loss: 0.09431810677051544\n",
            "Epoch 5, Batch 1154 / 1350, Loss: 0.01262369193136692\n",
            "Epoch 5, Batch 1155 / 1350, Loss: 0.022499198094010353\n",
            "Epoch 5, Batch 1156 / 1350, Loss: 0.019819941371679306\n",
            "Epoch 5, Batch 1157 / 1350, Loss: 0.018473230302333832\n",
            "Epoch 5, Batch 1158 / 1350, Loss: 0.012726420536637306\n",
            "Epoch 5, Batch 1159 / 1350, Loss: 0.06798471510410309\n",
            "Epoch 5, Batch 1160 / 1350, Loss: 0.010188553482294083\n",
            "Epoch 5, Batch 1161 / 1350, Loss: 0.01540151797235012\n",
            "Epoch 5, Batch 1162 / 1350, Loss: 0.09907989203929901\n",
            "Epoch 5, Batch 1163 / 1350, Loss: 0.1549333930015564\n",
            "Epoch 5, Batch 1164 / 1350, Loss: 2.129925012588501\n",
            "Epoch 5, Batch 1165 / 1350, Loss: 0.05310070887207985\n",
            "Epoch 5, Batch 1166 / 1350, Loss: 0.008343076333403587\n",
            "Epoch 5, Batch 1167 / 1350, Loss: 0.015904556959867477\n",
            "Epoch 5, Batch 1168 / 1350, Loss: 0.01042552012950182\n",
            "Epoch 5, Batch 1169 / 1350, Loss: 0.9217203259468079\n",
            "Epoch 5, Batch 1170 / 1350, Loss: 0.006967292167246342\n",
            "Epoch 5, Batch 1171 / 1350, Loss: 0.08065876364707947\n",
            "Epoch 5, Batch 1172 / 1350, Loss: 0.007780816871672869\n",
            "Epoch 5, Batch 1173 / 1350, Loss: 0.2011527270078659\n",
            "Epoch 5, Batch 1174 / 1350, Loss: 0.007769257761538029\n",
            "Epoch 5, Batch 1175 / 1350, Loss: 0.0827724039554596\n",
            "Epoch 5, Batch 1176 / 1350, Loss: 0.012373573146760464\n",
            "Epoch 5, Batch 1177 / 1350, Loss: 0.06009436398744583\n",
            "Epoch 5, Batch 1178 / 1350, Loss: 0.009213466197252274\n",
            "Epoch 5, Batch 1179 / 1350, Loss: 0.023591380566358566\n",
            "Epoch 5, Batch 1180 / 1350, Loss: 0.015932491049170494\n",
            "Epoch 5, Batch 1181 / 1350, Loss: 0.6891368627548218\n",
            "Epoch 5, Batch 1182 / 1350, Loss: 0.321296751499176\n",
            "Epoch 5, Batch 1183 / 1350, Loss: 0.008968750014901161\n",
            "Epoch 5, Batch 1184 / 1350, Loss: 0.01259421743452549\n",
            "Epoch 5, Batch 1185 / 1350, Loss: 0.08060988783836365\n",
            "Epoch 5, Batch 1186 / 1350, Loss: 0.007967254146933556\n",
            "Epoch 5, Batch 1187 / 1350, Loss: 0.33091267943382263\n",
            "Epoch 5, Batch 1188 / 1350, Loss: 0.027413945645093918\n",
            "Epoch 5, Batch 1189 / 1350, Loss: 0.019246956333518028\n",
            "Epoch 5, Batch 1190 / 1350, Loss: 0.7515925168991089\n",
            "Epoch 5, Batch 1191 / 1350, Loss: 0.3507464826107025\n",
            "Epoch 5, Batch 1192 / 1350, Loss: 0.04294537380337715\n",
            "Epoch 5, Batch 1193 / 1350, Loss: 0.009158402681350708\n",
            "Epoch 5, Batch 1194 / 1350, Loss: 0.29532721638679504\n",
            "Epoch 5, Batch 1195 / 1350, Loss: 0.008315523155033588\n",
            "Epoch 5, Batch 1196 / 1350, Loss: 0.014634374529123306\n",
            "Epoch 5, Batch 1197 / 1350, Loss: 0.008110038936138153\n",
            "Epoch 5, Batch 1198 / 1350, Loss: 0.007841082289814949\n",
            "Epoch 5, Batch 1199 / 1350, Loss: 0.015758506953716278\n",
            "Epoch 5, Batch 1200 / 1350, Loss: 0.15920431911945343\n",
            "Epoch 5, Batch 1201 / 1350, Loss: 0.06460251659154892\n",
            "Epoch 5, Batch 1202 / 1350, Loss: 0.22689944505691528\n",
            "Epoch 5, Batch 1203 / 1350, Loss: 0.17075824737548828\n",
            "Epoch 5, Batch 1204 / 1350, Loss: 0.6230855584144592\n",
            "Epoch 5, Batch 1205 / 1350, Loss: 0.7915026545524597\n",
            "Epoch 5, Batch 1206 / 1350, Loss: 0.00620496179908514\n",
            "Epoch 5, Batch 1207 / 1350, Loss: 0.01344638504087925\n",
            "Epoch 5, Batch 1208 / 1350, Loss: 0.3064354360103607\n",
            "Epoch 5, Batch 1209 / 1350, Loss: 0.06680100411176682\n",
            "Epoch 5, Batch 1210 / 1350, Loss: 0.013869097456336021\n",
            "Epoch 5, Batch 1211 / 1350, Loss: 0.024054881185293198\n",
            "Epoch 5, Batch 1212 / 1350, Loss: 0.16332189738750458\n",
            "Epoch 5, Batch 1213 / 1350, Loss: 0.14268599450588226\n",
            "Epoch 5, Batch 1214 / 1350, Loss: 0.07364508509635925\n",
            "Epoch 5, Batch 1215 / 1350, Loss: 0.020716717466711998\n",
            "Epoch 5, Batch 1216 / 1350, Loss: 0.12941396236419678\n",
            "Epoch 5, Batch 1217 / 1350, Loss: 0.04541078209877014\n",
            "Epoch 5, Batch 1218 / 1350, Loss: 0.006110896356403828\n",
            "Epoch 5, Batch 1219 / 1350, Loss: 0.03640395402908325\n",
            "Epoch 5, Batch 1220 / 1350, Loss: 0.009508542716503143\n",
            "Epoch 5, Batch 1221 / 1350, Loss: 0.005083932541310787\n",
            "Epoch 5, Batch 1222 / 1350, Loss: 0.1729736328125\n",
            "Epoch 5, Batch 1223 / 1350, Loss: 0.017863860353827477\n",
            "Epoch 5, Batch 1224 / 1350, Loss: 0.004932573065161705\n",
            "Epoch 5, Batch 1225 / 1350, Loss: 0.011048621498048306\n",
            "Epoch 5, Batch 1226 / 1350, Loss: 0.040160633623600006\n",
            "Epoch 5, Batch 1227 / 1350, Loss: 0.09598258882761002\n",
            "Epoch 5, Batch 1228 / 1350, Loss: 0.010548665188252926\n",
            "Epoch 5, Batch 1229 / 1350, Loss: 0.004691638983786106\n",
            "Epoch 5, Batch 1230 / 1350, Loss: 0.0054449052549898624\n",
            "Epoch 5, Batch 1231 / 1350, Loss: 0.5603260397911072\n",
            "Epoch 5, Batch 1232 / 1350, Loss: 0.05459791049361229\n",
            "Epoch 5, Batch 1233 / 1350, Loss: 0.04100446775555611\n",
            "Epoch 5, Batch 1234 / 1350, Loss: 0.06664887070655823\n",
            "Epoch 5, Batch 1235 / 1350, Loss: 0.007718789856880903\n",
            "Epoch 5, Batch 1236 / 1350, Loss: 0.006582321599125862\n",
            "Epoch 5, Batch 1237 / 1350, Loss: 0.04221872240304947\n",
            "Epoch 5, Batch 1238 / 1350, Loss: 0.011835511773824692\n",
            "Epoch 5, Batch 1239 / 1350, Loss: 0.1649065613746643\n",
            "Epoch 5, Batch 1240 / 1350, Loss: 0.007583680097013712\n",
            "Epoch 5, Batch 1241 / 1350, Loss: 0.07224661856889725\n",
            "Epoch 5, Batch 1242 / 1350, Loss: 0.017955483868718147\n",
            "Epoch 5, Batch 1243 / 1350, Loss: 0.013171114027500153\n",
            "Epoch 5, Batch 1244 / 1350, Loss: 0.004339932464063168\n",
            "Epoch 5, Batch 1245 / 1350, Loss: 0.15698780119419098\n",
            "Epoch 5, Batch 1246 / 1350, Loss: 0.013792550191283226\n",
            "Epoch 5, Batch 1247 / 1350, Loss: 0.0037917920853942633\n",
            "Epoch 5, Batch 1248 / 1350, Loss: 0.5291237831115723\n",
            "Epoch 5, Batch 1249 / 1350, Loss: 0.008440825156867504\n",
            "Epoch 5, Batch 1250 / 1350, Loss: 1.1981921195983887\n",
            "Epoch 5, Batch 1251 / 1350, Loss: 1.2690502405166626\n",
            "Epoch 5, Batch 1252 / 1350, Loss: 0.9049822092056274\n",
            "Epoch 5, Batch 1253 / 1350, Loss: 0.00520352553576231\n",
            "Epoch 5, Batch 1254 / 1350, Loss: 0.08291865885257721\n",
            "Epoch 5, Batch 1255 / 1350, Loss: 0.009328017011284828\n",
            "Epoch 5, Batch 1256 / 1350, Loss: 0.23610034584999084\n",
            "Epoch 5, Batch 1257 / 1350, Loss: 0.4015004634857178\n",
            "Epoch 5, Batch 1258 / 1350, Loss: 0.04920162633061409\n",
            "Epoch 5, Batch 1259 / 1350, Loss: 0.20973093807697296\n",
            "Epoch 5, Batch 1260 / 1350, Loss: 0.6700507998466492\n",
            "Epoch 5, Batch 1261 / 1350, Loss: 0.008762551471590996\n",
            "Epoch 5, Batch 1262 / 1350, Loss: 0.031878512352705\n",
            "Epoch 5, Batch 1263 / 1350, Loss: 0.28739288449287415\n",
            "Epoch 5, Batch 1264 / 1350, Loss: 0.015356464311480522\n",
            "Epoch 5, Batch 1265 / 1350, Loss: 0.010980643332004547\n",
            "Epoch 5, Batch 1266 / 1350, Loss: 0.009501958265900612\n",
            "Epoch 5, Batch 1267 / 1350, Loss: 0.09664497524499893\n",
            "Epoch 5, Batch 1268 / 1350, Loss: 0.1340121328830719\n",
            "Epoch 5, Batch 1269 / 1350, Loss: 0.02128862403333187\n",
            "Epoch 5, Batch 1270 / 1350, Loss: 0.017451211810112\n",
            "Epoch 5, Batch 1271 / 1350, Loss: 0.026817824691534042\n",
            "Epoch 5, Batch 1272 / 1350, Loss: 0.02661222033202648\n",
            "Epoch 5, Batch 1273 / 1350, Loss: 0.18475180864334106\n",
            "Epoch 5, Batch 1274 / 1350, Loss: 0.18211309611797333\n",
            "Epoch 5, Batch 1275 / 1350, Loss: 0.1232830286026001\n",
            "Epoch 5, Batch 1276 / 1350, Loss: 0.013879177160561085\n",
            "Epoch 5, Batch 1277 / 1350, Loss: 0.014659970998764038\n",
            "Epoch 5, Batch 1278 / 1350, Loss: 0.05010942369699478\n",
            "Epoch 5, Batch 1279 / 1350, Loss: 0.03836967423558235\n",
            "Epoch 5, Batch 1280 / 1350, Loss: 0.03427114710211754\n",
            "Epoch 5, Batch 1281 / 1350, Loss: 0.040031492710113525\n",
            "Epoch 5, Batch 1282 / 1350, Loss: 0.13451336324214935\n",
            "Epoch 5, Batch 1283 / 1350, Loss: 0.033520109951496124\n",
            "Epoch 5, Batch 1284 / 1350, Loss: 0.006432028021663427\n",
            "Epoch 5, Batch 1285 / 1350, Loss: 0.005708765238523483\n",
            "Epoch 5, Batch 1286 / 1350, Loss: 0.006872252095490694\n",
            "Epoch 5, Batch 1287 / 1350, Loss: 0.006250105798244476\n",
            "Epoch 5, Batch 1288 / 1350, Loss: 0.033872224390506744\n",
            "Epoch 5, Batch 1289 / 1350, Loss: 0.05637999624013901\n",
            "Epoch 5, Batch 1290 / 1350, Loss: 0.04943447560071945\n",
            "Epoch 5, Batch 1291 / 1350, Loss: 0.014454526826739311\n",
            "Epoch 5, Batch 1292 / 1350, Loss: 0.011544596403837204\n",
            "Epoch 5, Batch 1293 / 1350, Loss: 0.04410634562373161\n",
            "Epoch 5, Batch 1294 / 1350, Loss: 0.007358208764344454\n",
            "Epoch 5, Batch 1295 / 1350, Loss: 1.3436142206192017\n",
            "Epoch 5, Batch 1296 / 1350, Loss: 0.00564946886152029\n",
            "Epoch 5, Batch 1297 / 1350, Loss: 0.0063831922598183155\n",
            "Epoch 5, Batch 1298 / 1350, Loss: 0.13403961062431335\n",
            "Epoch 5, Batch 1299 / 1350, Loss: 0.008671393617987633\n",
            "Epoch 5, Batch 1300 / 1350, Loss: 0.004660441540181637\n",
            "Epoch 5, Batch 1301 / 1350, Loss: 0.008634723722934723\n",
            "Epoch 5, Batch 1302 / 1350, Loss: 0.13320334255695343\n",
            "Epoch 5, Batch 1303 / 1350, Loss: 0.3901750445365906\n",
            "Epoch 5, Batch 1304 / 1350, Loss: 0.007135906256735325\n",
            "Epoch 5, Batch 1305 / 1350, Loss: 0.07478378713130951\n",
            "Epoch 5, Batch 1306 / 1350, Loss: 0.005326476879417896\n",
            "Epoch 5, Batch 1307 / 1350, Loss: 0.008949615061283112\n",
            "Epoch 5, Batch 1308 / 1350, Loss: 0.0468810610473156\n",
            "Epoch 5, Batch 1309 / 1350, Loss: 0.014950399287045002\n",
            "Epoch 5, Batch 1310 / 1350, Loss: 0.007436742074787617\n",
            "Epoch 5, Batch 1311 / 1350, Loss: 0.012167146429419518\n",
            "Epoch 5, Batch 1312 / 1350, Loss: 0.407949835062027\n",
            "Epoch 5, Batch 1313 / 1350, Loss: 0.23913919925689697\n",
            "Epoch 5, Batch 1314 / 1350, Loss: 0.42395731806755066\n",
            "Epoch 5, Batch 1315 / 1350, Loss: 0.008517581038177013\n",
            "Epoch 5, Batch 1316 / 1350, Loss: 0.01139778457581997\n",
            "Epoch 5, Batch 1317 / 1350, Loss: 0.0060864826664328575\n",
            "Epoch 5, Batch 1318 / 1350, Loss: 0.01772901974618435\n",
            "Epoch 5, Batch 1319 / 1350, Loss: 0.1821664422750473\n",
            "Epoch 5, Batch 1320 / 1350, Loss: 0.006380131468176842\n",
            "Epoch 5, Batch 1321 / 1350, Loss: 0.024761132895946503\n",
            "Epoch 5, Batch 1322 / 1350, Loss: 0.007745767943561077\n",
            "Epoch 5, Batch 1323 / 1350, Loss: 0.20772747695446014\n",
            "Epoch 5, Batch 1324 / 1350, Loss: 0.02135518193244934\n",
            "Epoch 5, Batch 1325 / 1350, Loss: 0.006978541612625122\n",
            "Epoch 5, Batch 1326 / 1350, Loss: 0.02473665028810501\n",
            "Epoch 5, Batch 1327 / 1350, Loss: 0.014129472896456718\n",
            "Epoch 5, Batch 1328 / 1350, Loss: 0.05161662772297859\n",
            "Epoch 5, Batch 1329 / 1350, Loss: 0.04726190119981766\n",
            "Epoch 5, Batch 1330 / 1350, Loss: 0.021137595176696777\n",
            "Epoch 5, Batch 1331 / 1350, Loss: 0.008607597090303898\n",
            "Epoch 5, Batch 1332 / 1350, Loss: 0.009655177593231201\n",
            "Epoch 5, Batch 1333 / 1350, Loss: 0.09652066975831985\n",
            "Epoch 5, Batch 1334 / 1350, Loss: 0.08871004730463028\n",
            "Epoch 5, Batch 1335 / 1350, Loss: 0.018442640081048012\n",
            "Epoch 5, Batch 1336 / 1350, Loss: 0.2963314354419708\n",
            "Epoch 5, Batch 1337 / 1350, Loss: 0.1103849783539772\n",
            "Epoch 5, Batch 1338 / 1350, Loss: 0.7373424172401428\n",
            "Epoch 5, Batch 1339 / 1350, Loss: 0.0045998478308320045\n",
            "Epoch 5, Batch 1340 / 1350, Loss: 0.014698621816933155\n",
            "Epoch 5, Batch 1341 / 1350, Loss: 0.0482935905456543\n",
            "Epoch 5, Batch 1342 / 1350, Loss: 0.01696695387363434\n",
            "Epoch 5, Batch 1343 / 1350, Loss: 0.005127953365445137\n",
            "Epoch 5, Batch 1344 / 1350, Loss: 1.1992301940917969\n",
            "Epoch 5, Batch 1345 / 1350, Loss: 0.010118065401911736\n",
            "Epoch 5, Batch 1346 / 1350, Loss: 0.09940153360366821\n",
            "Epoch 5, Batch 1347 / 1350, Loss: 0.06540117412805557\n",
            "Epoch 5, Batch 1348 / 1350, Loss: 0.010017377324402332\n",
            "Epoch 5, Batch 1349 / 1350, Loss: 0.008086989633738995\n",
            "Epoch 5, Batch 1350 / 1350, Loss: 0.0032517435029149055\n",
            "Epoch 5, Loss: 0.11916764163826075, Accuracy: 0.984621085788401, Auc: 0.9846670827737953, f1: 0.9784247465557577\n",
            "Epoch 5, Train Loss: 2.265863608614817, Validation Accuracy: 0.7978723404255319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 저장\n",
        "model.save_pretrained(\"pretrained_model_directory\")  # type: ignore\n"
      ],
      "metadata": {
        "id": "iu5mh-a2pJII"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}